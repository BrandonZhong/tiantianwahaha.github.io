<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>BeautyGAN: Instance-level Facial Makeup Transfer with Deep | Voila</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">BeautyGAN: Instance-level Facial Makeup Transfer with Deep</h1><a id="logo" href="/.">Voila</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">BeautyGAN: Instance-level Facial Makeup Transfer with Deep</h1><div class="post-meta">Nov 14, 2018<span> | </span><span class="category"><a href="/categories/百篇论文阅读计划/">百篇论文阅读计划</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#贡献"><span class="toc-number">1.</span> <span class="toc-text">贡献</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#结构"><span class="toc-number">2.</span> <span class="toc-text">结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#损失函数"><span class="toc-number">3.</span> <span class="toc-text">损失函数</span></a></li></ol></div></div><div class="post-content"><p>BeautyGAN</p>
<p>基于生成对抗网络的实例级面部化妆转移</p>
<p>ECCV2018 刘思组一个学生做的</p>
<p>传统的化妆转换，需要用户事实的交互，只有固定的几个妆容，但是如果明星有一个很好看的妆容，想试试怎么办，这篇文章就做的在非对称网络上，实现实例级的化妆转换，输入一个素颜+目标化妆照片，输出化妆后的结果图片。</p>
<h2 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h2><p>1）我们通过双重输入/输出生成对抗网络实现自动化妆转移。 实验表明了转移策略的有效性，并且生成的结果比最先进的方法具有更高的质量。<br>（2）我们通过在局部区域成功应用像素级直方图损失来实现实例级样式转换。 这种实例级转移方法可以很容易地推广到其他图像转换任务，例如用于头像肖像的样式转移，图像属性转移等。<br>（3）建立了一个包含3834张图像的新化妆数据集</p>
<h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p><img src="/2018/11/14/BeautyGAN-Instance-level-Facial-Makeup-Transfer-with-Deep/structure.png" alt=""></p>
<p>如图所示</p>
<p>网络由一个生成器，两个鉴别器构成</p>
<p>$I_{src}$表示source image，是素颜图片，或者为A图片</p>
<p>$I_{ref}$表示reference image，是目标妆容图片，或者为B图片</p>
<p>两张图片一起输入生成器，先经过单独的几层CNN网络，然后经过共用的深度残差网络，最后再分别经过反卷积输出两张图片</p>
<p>$I_{src}^{B}$表示化了 B图片妆的A图片</p>
<p>$I_{ref}^{A}$表示去掉了妆，变成素颜的B图片</p>
<p>然后$I_{src}^{B}$和$I_{ref}$是化了相同妆的图片，放入鉴别器$D_{B}$中进行训练</p>
<p>$I_{ref}^{A}$和$I_{src}$都是素颜图片，放入鉴别器$D_{A}$中进行训练</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>1.鉴别器$D_{B}$和鉴别器$D_{A}$处是两个传统的GAN损失函数</p>
<p>2.生成器损失函数由四项构成</p>
<p>$L_{G} = αL_{adv} + βL_{cyc} +γL_{per} + L_{makeup}$</p>
<p><strong>$L_{cyc}$和$L_{per}$保证经过化妆，还是原来的人脸模样，同时图片背景不变</strong></p>
<p><strong><em>$L_{makeup}$损失保证妆容转移</em></strong></p>
<ol>
<li><p>$L_{adv}$第一项是鉴别器对应的生成器损失，使生成的图片逼真，鉴别器无法鉴别</p>
</li>
<li><p>$L_{cyc}$是循环重构损失，类似cycleGAN，$I_{src}^{B}$和$I_{ref}^{A}$再次输入生成器，得到$I_{src}^{rec}$和$I_{ref}^{rec}$，和原输入图片算重构损失，L1或者L2。</p>
</li>
</ol>
<p><img src="/2018/11/14/BeautyGAN-Instance-level-Facial-Makeup-Transfer-with-Deep/GG.png" alt=""></p>
<ol start="3">
<li><p>$L_{per}$是perceptual loss，其实就是李飞飞风格转换那篇文章中提到的内容损失content loss，提取VGG16网络中的relu_4_1层</p>
<p><img src="/2018/11/14/BeautyGAN-Instance-level-Facial-Makeup-Transfer-with-Deep/perceptual.png" alt=""></p>
</li>
<li><p>$L_{makeup}$是直方图损失Histogram loss，不能在全局算这个损失，因为妆容只包括 眼影，唇膏，粉底。跟头发背景等无关。所以用别人预训练好的网络，输入人脸图片，直接得到眼，嘴，皮肤三个位置的mask，分别计算三个位置的直方图损失，然后想加就是总直方图损失，如结构图所示。</p>
<p><strong>化妆在图像上其实可以看做是颜色的深浅等的变化，所以用直方图损失，直方图匹配就是，有时需要变换直方图使之成为某个特定的形状,从而有选择地增强某个灰度值范围内的对比度</strong></p>
</li>
</ol>
<p><img src="/2018/11/14/BeautyGAN-Instance-level-Facial-Makeup-Transfer-with-Deep/histogram.png" alt=""></p>
<p>直方图损失的理论理解参考：<a href="https://blog.csdn.net/majinlei121/article/details/46482615" target="_blank" rel="noopener">https://blog.csdn.net/majinlei121/article/details/46482615</a></p>
</div><div class="tags"><a href="/tags/GAN/">GAN</a></div><div class="post-nav"><a class="pre" href="/2018/12/20/cs231n-Lecture5-Convolutional-Neural-Networks/">cs231n Lecture5 Convolutional Neural Networks</a><a class="next" href="/2018/11/10/cs231n-Lecture3-Loss-Functions-and-Optimization/">cs231n Lecture3 Loss Functions and Optimization</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs231n/">cs231n</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/百篇论文阅读计划/">百篇论文阅读计划</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/image-caption/" style="font-size: 15px;">image caption</a> <a href="/tags/cs231n/" style="font-size: 15px;">cs231n</a> <a href="/tags/图像风格转换/" style="font-size: 15px;">图像风格转换</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/01/09/Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention/">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/09/Spectral-Normalization-for-Generative-Adversarial-Networks/">Spectral Normalization for Generative Adversarial Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/08/Self-Attention-Generative-Adversarial-Networks/">Self-Attention Generative Adversarial Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/07/cs231n-lecture11-Detection-and-Segmentation/">cs231n lecture11 Detection and Segmentation</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/03/Super-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS/">Super-FAN:Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with GANS</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/24/cs231n-Lecture-10-Recurrent-Neural-Networks/">cs231n Lecture 10 Recurrent Neural Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/">cs231n Lecture 9 CNN Architectures</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/22/cs231n-Lecture-7-Training-Neural-Networks-part-2/">cs231n Lecture 7 Training Neural Networks part 2</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/21/cs231n-Lecture-6-Training-Neural-Networks-part-I/">cs231n Lecture 6 Training Neural Networks, part I</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/20/cs231n-参数设置技巧/">cs231n 参数设置技巧</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/tiantianwahaha" title="github" target="_blank">github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Voila.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>