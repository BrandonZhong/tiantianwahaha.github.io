<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>cs231n Lecture 9 CNN Architectures | Voila</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">cs231n Lecture 9 CNN Architectures</h1><a id="logo" href="/.">Voila</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">cs231n Lecture 9 CNN Architectures</h1><div class="post-meta">Dec 22, 2018<span> | </span><span class="category"><a href="/categories/cs231n/">cs231n</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="post-content"><p>介绍几个重要的CNN模型(在imagenet比赛中获得冠军)</p>
<ul>
<li>AlexNet</li>
<li>VGG</li>
<li>GoogleNet</li>
<li>ResNet</li>
</ul>
<p><img src="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/1.png" alt=""></p>
<h2 id="1-AlexNet"><a href="#1-AlexNet" class="headerlink" title="1.AlexNet"></a>1.AlexNet</h2><p><strong>2012年冠imagenet比赛冠军，第一次使用ReLU，8layer</strong></p>
<p><img src="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/alexnet.png" alt=""></p>
<h2 id="2-VGG"><a href="#2-VGG" class="headerlink" title="2.VGG"></a>2.VGG</h2><p><strong>2014年亚军，只用小的卷积核filters(3*3)，更深的网络，16layer或者19layer</strong></p>
<p>19层只比16层效果好一点点，但是用了更多的参数和内存，看情况可以使用16层</p>
<p><img src="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/vgg.png" alt=""></p>
<p>学习一下怎么计算网络的参数大小(权重)和容量大小(输入的x在网络中传播占的大小)。可以看出平均一个图片就要占100M，如果一批32个图片，就要占用3G内存。</p>
<h2 id="3-GooLeNet（Inception！）"><a href="#3-GooLeNet（Inception！）" class="headerlink" title="3.GooLeNet（Inception！）"></a>3.GooLeNet（Inception！）</h2><p><strong>2014年冠军，Inception model和没有FC层。22layer</strong></p>
<p><img src="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/inception.png" alt=""></p>
<p>新提出的inception模型，并行进行1×1conv，3×3conv，5×5conv和3×3pool。但是非常耗费内存。</p>
<p>提出了“bottleneck”解决这个问题，就是加一些1×1conv，减少信道数</p>
<p><img src="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/bottleneck.png" alt=""></p>
<h2 id="4-ResNet-skip-connect"><a href="#4-ResNet-skip-connect" class="headerlink" title="4.ResNet(skip connect)"></a>4.ResNet(skip connect)</h2><p><strong>2015年冠军，残差网络，目前最好的网络结构，152层。</strong></p>
<p><img src="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/resnet.png" alt=""></p>
<p>残差网络同样加入了bottleneck，当网络层数大于50的时候</p>
<p><img src="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/resnet1.png" alt=""></p>
<p><img src="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/resnet2.png" alt=""></p>
<h2 id="5-其他的结构（对残差网络的后续改进）"><a href="#5-其他的结构（对残差网络的后续改进）" class="headerlink" title="5.其他的结构（对残差网络的后续改进）"></a>5.其他的结构（对残差网络的后续改进）</h2><h3 id="（1）残差网络的作者进行的改进"><a href="#（1）残差网络的作者进行的改进" class="headerlink" title="（1）残差网络的作者进行的改进"></a>（1）残差网络的作者进行的改进</h3><p><img src="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/2.png" alt=""></p>
<h3 id="（2）该作者认为残差的有效性在于宽度，不在于深度，加大中间3×3卷积的宽度-F×K"><a href="#（2）该作者认为残差的有效性在于宽度，不在于深度，加大中间3×3卷积的宽度-F×K" class="headerlink" title="（2）该作者认为残差的有效性在于宽度，不在于深度，加大中间3×3卷积的宽度(F×K)"></a>（2）该作者认为残差的有效性在于宽度，不在于深度，加大中间3×3卷积的宽度(F×K)</h3><p><img src="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/3.png" alt=""></p>
<h3 id="（3）残差网络作者的后续改进，增加了宽度"><a href="#（3）残差网络作者的后续改进，增加了宽度" class="headerlink" title="（3）残差网络作者的后续改进，增加了宽度"></a>（3）残差网络作者的后续改进，增加了宽度</h3><p><img src="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/4.png" alt=""></p>
</div><div class="tags"><a href="/tags/cs231n/">cs231n</a></div><div class="post-nav"><a class="pre" href="/2018/12/24/cs231n-Lecture-10-Recurrent-Neural-Networks/">cs231n Lecture 10 Recurrent Neural Networks</a><a class="next" href="/2018/12/22/cs231n-Lecture-7-Training-Neural-Networks-part-2/">cs231n Lecture 7 Training Neural Networks part 2</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs231n/">cs231n</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/百篇论文阅读计划/">百篇论文阅读计划</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/cs231n/" style="font-size: 15px;">cs231n</a> <a href="/tags/图像风格转换/" style="font-size: 15px;">图像风格转换</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/01/07/cs231n-lecture11-Detection-and-Segmentation/">cs231n lecture11 Detection and Segmentation</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/03/Super-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS/">Super-FAN:Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with GANS</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/24/cs231n-Lecture-10-Recurrent-Neural-Networks/">cs231n Lecture 10 Recurrent Neural Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/">cs231n Lecture 9 CNN Architectures</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/22/cs231n-Lecture-7-Training-Neural-Networks-part-2/">cs231n Lecture 7 Training Neural Networks part 2</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/21/cs231n-Lecture-6-Training-Neural-Networks-part-I/">cs231n Lecture 6 Training Neural Networks, part I</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/20/cs231n-参数设置技巧/">cs231n 参数设置技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/20/cs231n-Lecture5-Convolutional-Neural-Networks/">cs231n Lecture5 Convolutional Neural Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/14/BeautyGAN-Instance-level-Facial-Makeup-Transfer-with-Deep/">BeautyGAN: Instance-level Facial Makeup Transfer with Deep</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/10/cs231n-Lecture3-Loss-Functions-and-Optimization/">cs231n Lecture3 Loss Functions and Optimization</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/tiantianwahaha" title="github" target="_blank">github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Voila.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>