<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>图像风格转换(一):A Neural Algorithm of Artistic Style | Voila</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">图像风格转换(一):A Neural Algorithm of Artistic Style</h1><a id="logo" href="/.">Voila</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">图像风格转换(一):A Neural Algorithm of Artistic Style</h1><div class="post-meta">Oct 30, 2018<span> | </span><span class="category"><a href="/categories/百篇论文阅读计划/">百篇论文阅读计划</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a class="disqus-comment-count" href="/2018/10/30/风格转换-一-：A-Neural-Algorithm-of-Artistic-Style/#vcomment"><span class="valine-comment-count" data-xid="/2018/10/30/风格转换-一-：A-Neural-Algorithm-of-Artistic-Style/"></span><span> Comment</span></a><div class="post-content"><p>论文地址：<a href="http://cn.arxiv.org/abs/1508.06576" target="_blank" rel="noopener">A Neural Algorithm of Artistic Style</a><br>tensorflow代码实现：<a href="https://github.com/woodrush/neural-art-tf" target="_blank" rel="noopener">woodrush/neural-art-tf</a><br>本文介绍Leon Gatys在2016年初大热的Style Transfer算法，发表于CVPR16  </p>
<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>首次提出，使用预训练好的VGG19网络，提取图像不同层级的特征，分别作为图像的风格特征和内容特征，以高斯噪声为初始输入图像，多次执行前向/后向迭代使用L-BFGS方法优化，保持CNN的参数不变，根据风格损失和内容损失，反向传播更新图片。<br>保留内容图片的内容和全局布局的同时，由风格图片提供颜色和局部结构信息。</p>
<h2 id="2-VGG19"><a href="#2-VGG19" class="headerlink" title="2. VGG19"></a>2. VGG19</h2><p><img src="/2018/10/30/风格转换-一-：A-Neural-Algorithm-of-Artistic-Style/VGG19.jpg" alt="">  </p>
<p>如图所示为VGG19的网络结构，16个convolutional和5个pooling layer，本文不使用后面的全连接层。使用average pooling代替max pooling，得到更好的视觉效果。<br><img src="/2018/10/30/风格转换-一-：A-Neural-Algorithm-of-Artistic-Style/example1.jpg" alt=""><br>如图所示，输入内容图片和风格图片，在abcde五层处分别重构风格图片和内容图片。<br><strong>内容重构</strong><br>(a)conv1_1，(b) conv2_1，(c)conv3_1，(d)conv4_1，(e)conv5_1<br>可以看出，在高层(d，e)，细节像素信息丢失，但内容保留，所以内容特征一般用高层。</p>
<p><strong>风格重构</strong><br>(a)conv1_1，(b)conv1_1， conv2_1，(c)conv1_1， conv2_1，conv3_1，(d)conv1_1， conv2_1，conv3_1，conv4_1，(e)conv1_1， conv2_1，conv3_1，conv4_1，conv5_1<br>感受野大小和特征复杂程度随着网络层级增大，当风格表示匹配到网络的更高层时，局部图像结构在越来越大的范围内匹配，从而导致更平滑和更连接的视觉效果<br><strong>所以在最终的实验里</strong><br>内容层 - conv4_2<br>风格层 - conv1_1, conv2_1, conv3_1, conv4_1, conv5_1</p>
<h2 id="3-内容损失"><a href="#3-内容损失" class="headerlink" title="3. 内容损失"></a>3. 内容损失</h2><p>输入$x$，在网络中某一层的输出为，shape可以表示为 $$ N_{l}\times H \times W $$ ，reshape为 $N_{l}\times M_{l}$，写作矩阵$F^{l}$。其中$N_{l} $表示该层卷积核的个数，$ M_{l}$ 是该层feature的长度 $H $和宽度 $W$ 的乘积。$ F_{ij}^{l} $表示$ l $层第$ i $个filter的位置$ j$ 。<br>内容损失就是原始图像和生成图片，经过VGG19网络，在这一层的feature的SSE(和方差，误差平方和)<br>$$<br>L_{content} = \frac{1}{2} \sum_{i,j}({F_{ij}^{l}-P_{ij}^{l}})^{2}<br>$$</p>
<h2 id="4-风格损失"><a href="#4-风格损失" class="headerlink" title="4. 风格损失"></a>4. 风格损失</h2><p>先引入Gram matrix $G^{l}\in R^{ N_{l} \times N_{l}}$,由矩阵$F^{l}$和他转置矩阵的相乘得到。$ G_{ij}^{l}$ 是第$ l $层的feature$ i $向量和feature$ j $向量的内积。可以认为是一个未零均值化的协方差矩阵，捕获的是哪些feature是趋于一起激活的信息(如果无法理解为什么内积=协方差，可以看参考里的2和3两篇博文)。  </p>
<p>$$<br>E_{l} = \frac{1}{4N_{l}^{2}m_{l}^{2}}\sum_{i,j}{(G_{ij}^{l}-F_{ij}^{l})^{2}}<br>$$</p>
<p>$$<br>L_{style} = \sum_{l=0}^{L}{w_{l}E_{l}}<br>$$</p>
<p>5层的损失相加，乘以对应权重，通常为$ \frac{1}{5}  $</p>
<p>当风格图片和内容图片size不一样，这个风格损失函数也可以用，因为Gram矩阵shape一样</p>
<h2 id="5-总损失"><a href="#5-总损失" class="headerlink" title="5. 总损失"></a>5. 总损失</h2><p>$$<br>L_{total} = \alpha L_{content} + \beta L_{style}<br>$$</p>
<p>$\alpha$和$\beta$ 表示权重，不可能内容和风格完美匹配，需要调节。文章中使用 $\frac{\alpha}{\beta} = 10^{-3}$ (B,C,D)更加注重原图，或者$10^{-4} $(E,F)，更加艺术化。<br><img src="/2018/10/30/风格转换-一-：A-Neural-Algorithm-of-Artistic-Style/example2.jpg" alt="">  </p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="https://blog.csdn.net/shenxiaolu1984/article/details/52090012" target="_blank" rel="noopener">【深度学习】A neural algorithm of artistic style算法详解</a></li>
<li><a href="https://blog.csdn.net/jesszen/article/details/80970485" target="_blank" rel="noopener">【统计学习1】方差、协方差、相关系数与向量内积 - CSDN博客</a></li>
<li><a href="http://blog.codinglabs.org/articles/pca-tutorial.html" target="_blank" rel="noopener">CodingLabs - PCA的数学原理</a> </li>
</ol>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>最近对风格转换的文章比较感兴趣，看了一篇NVIDA最新的，然后有些地方不明白，就循着参考文献看过来，这片是最经典最早的一篇，后续看完其他几篇，也会做个笔记，坚持每周至少精读一篇文章并做个笔记。</p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>Author: </strong>whiup</li><li class="post-copyright-link"><strong>Blog Link: </strong><a href="/2018/10/30/风格转换-一-：A-Neural-Algorithm-of-Artistic-Style/">http://yoursite.com/2018/10/30/风格转换-一-：A-Neural-Algorithm-of-Artistic-Style/</a></li><li class="post-copyright-license"><strong>Copyright Declaration: </strong>The author owns the copyright, please indicate the source reproduced.</li></ul></div><br><div class="tags"><a href="/tags/图像风格转换/">图像风格转换</a></div><div class="post-nav"><a class="pre" href="/2018/10/31/风格转换-二-：Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution/">风格转换(二)：Perceptual Losses for Real-Time Style Transfer and Super-Resolution</a><a class="next" href="/2018/10/24/hello-world/">Hello World</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'true' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'ghsTdcg2fkGJS6ezqnysCLhl-gzGzoHsz',
  appKey:'TFWzwUO0GPWYSIzO5rlINGID',
  placeholder:'Just so so',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs231n/">cs231n</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/百篇论文阅读计划/">百篇论文阅读计划</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/image-caption/" style="font-size: 15px;">image caption</a> <a href="/tags/cs231n/" style="font-size: 15px;">cs231n</a> <a href="/tags/图像风格转换/" style="font-size: 15px;">图像风格转换</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/01/09/Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention/">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/09/Spectral-Normalization-for-Generative-Adversarial-Networks/">Spectral Normalization for Generative Adversarial Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/08/Self-Attention-Generative-Adversarial-Networks/">Self-Attention Generative Adversarial Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/07/cs231n-lecture11-Detection-and-Segmentation/">cs231n lecture11 Detection and Segmentation</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/03/Super-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS/">Super-FAN:Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with GANS</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/24/cs231n-Lecture-10-Recurrent-Neural-Networks/">cs231n Lecture 10 Recurrent Neural Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/22/cs231n-Lecture-9-CNN-Architectures/">cs231n Lecture 9 CNN Architectures</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/22/cs231n-Lecture-7-Training-Neural-Networks-part-2/">cs231n Lecture 7 Training Neural Networks part 2</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/21/cs231n-Lecture-6-Training-Neural-Networks-part-I/">cs231n Lecture 6 Training Neural Networks, part I</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/20/cs231n-参数设置技巧/">cs231n 参数设置技巧</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/tiantianwahaha" title="github" target="_blank">github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Voila.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>