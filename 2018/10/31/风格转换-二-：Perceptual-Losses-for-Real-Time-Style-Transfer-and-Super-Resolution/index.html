<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>风格转换(二)：Perceptual Losses for Real-Time Style Transfer and Super-Resolution | Voila</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">风格转换(二)：Perceptual Losses for Real-Time Style Transfer and Super-Resolution</h1><a id="logo" href="/.">Voila</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">风格转换(二)：Perceptual Losses for Real-Time Style Transfer and Super-Resolution</h1><div class="post-meta">Oct 31, 2018<span> | </span><span class="category"><a href="/categories/百篇论文阅读计划/">百篇论文阅读计划</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="post-content"><p><strong>基于感知损失函数的实时风格转换和超分辨率重建</strong><br>论文地址：<a href="https://arxiv.org/abs/1603.08155" target="_blank" rel="noopener">[1603.08155] Perceptual Losses for Real-Time Style Transfer and Super-Resolution</a><br>本文是李飞飞在2016年ECCV上发表的实时风格转换论文。提出了perceptual loss，风格转换分为单一图片单一风格，多图片单一风格，多图片多风格，任意图片任意风格。A Neural Algorithm of Artistic Style 这篇文章每次都要重新训练图片，属于单一图片单一风格。训练一个模型，每次输入图片实时的生成风格图片，也就是本篇文章，为多图片单一风格。  </p>
<h2 id="1-翻译文章摘要"><a href="#1-翻译文章摘要" class="headerlink" title="1. 翻译文章摘要"></a>1. 翻译文章摘要</h2><p>我们考虑的图像转换的问题，即将一个输入图像变换成一个输出图像。最近热门的图像转换的方法通常是训练前馈卷积神经网络，将输出图像与原本图像的逐像素差距作为损失函数。并行的工作表明，高质量的图像可以通过用预训练好的网络提取高级特征、定义并优化感知损失函数来产生。我们组合了一下这两种方法各自的优势，提出采用感知损失函数训练前馈网络进行图像转换的任务。本文给出了图像风格化的结果，训练一个前馈网络去解决实时优化问题（Gatys等人提出的），和基于有优化的方法对比，我们的网络产生质量相当的结果，却能做到三个数量级的提速。我们还实验了单图的超分辨率重建，同样采用感知损失函数来代替求逐像素差距的损失函数.</p>
<h2 id="2-概述"><a href="#2-概述" class="headerlink" title="2. 概述"></a>2. 概述</h2><p>如图，提出一个Image Transform Net，输入为 $x$ 输出为风格图片，输出为 $\widehat{y}$结果图片，后面紧跟一个与训练好的VGG-16网络作为Loss Network，输入为风格图片$ y_{s}$ (不变)和内容图片$ y_{c}$ (训练集中读个内容图片)，使用内容损失和风格损失的权重和作为总体损失，保持Loss Network参数不变，更新Image Transform Net网络的参数。  </p>
<p>最终训练成功后，取出Image Transform Net，输入任意内容图片，输出就是风格转换后的结果。多图片单一风格。</p>
<p><img src="/2018/10/31/风格转换-二-：Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution/structure.jpg" alt=""></p>
<h2 id="3-Image-Transform-Net"><a href="#3-Image-Transform-Net" class="headerlink" title="3. Image Transform Net"></a>3. Image Transform Net</h2><p>​        Image Transform Net的输入是要转换的图像，输出是转换好的图像，在模型训练好之后，用于生成风格迁移的只是这部分的网络。具体这部分的网络模型图如下。</p>
<p>​        图像变换网络总体也属于一个残差网络。一共是由3个卷积层、5个残差块、3个卷积层构成。这里没有用到池化等操作进行采用，在开始卷积层中（第二层、第三层）进行了下采样，在最后的3个卷积层中进行了上采样，这样最直接的就是减少了计算复杂度，另外还有一个好处是有效受区域变大，卷积下采样都会增大有效区域。5个残差块都是使用相同个数的（128）滤镜核，每个残差块中都有2个卷积层（3*3核），这里的卷积层中没有进行标准的0填充（padding），因为使用0填充会使生成出的图像的边界出现严重伪影。为了保证输入输出图像大小不改变，在图像初始输入部分加入了反射填充。</p>
<p>​       这里的残差网络不是使用何凯明的残差网络（卷积之后没有Relu），而是使用了Gross and Wilber的残差网络 。后面这种方法验证在图像分类算法上面效果比较好。</p>
<p><img src="/2018/10/31/风格转换-二-：Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution/detail.jpg" alt=""></p>
<h2 id="4-Perceptual-Loss"><a href="#4-Perceptual-Loss" class="headerlink" title="4. Perceptual Loss"></a>4. Perceptual Loss</h2><p><strong>(1)Feature Reconstruction Loss</strong></p>
<p><img src="/2018/10/31/风格转换-二-：Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution/equation1.jpg" alt=""></p>
<ul>
<li>使用 $\phi $来表示VGG网络</li>
<li>$j $表示网络的第j层。</li>
<li>$C_{j}H_{j}W_{j} $表示第$j$层的feature_map的size</li>
<li>就是VGG网络某一层的输出，结果图片和内容图片所有的feature相减求平方，然后求个平均</li>
</ul>
<p><img src="/2018/10/31/风格转换-二-：Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution/example1.jpg" alt=""></p>
<p><strong>（2）Style Reconstruction Loss</strong></p>
<p><img src="/2018/10/31/风格转换-二-：Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution/equation2.jpg" alt=""></p>
<p>同Gatys，先求Gram矩阵，就是把$\phi_{j}$reshpe为$C_{j} \times H_{j}W_{j}$的矩阵$ \psi$ ，然后得到</p>
<p><img src="/2018/10/31/风格转换-二-：Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution/equation3.jpg" alt=""></p>
<p>也就是该层特征的未零均值化的协方差，若样本均标准化为均值为0，那么内积=协方差。<br>这将获得哪些feature倾向于一起激活(相关性).</p>
<p><img src="/2018/10/31/风格转换-二-：Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution/equation4.jpg" alt=""></p>
<p>在loss网络的每一层都求出Gram矩阵，然后对应层之间计算欧式距离，最后将不同层的欧氏距离相加，得到最后的风格损失。</p>
<p><strong>当生成的图片和风格图片尺寸不一致，也能计算风格损失，因为Gram矩阵大小一样</strong></p>
<p><img src="/2018/10/31/风格转换-二-：Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution/example2.jpg" alt=""></p>
<p><strong>(3)Total Variation Regularization</strong><br><strong>保证输出图像的空间平滑性，避免高频噪声 $l_{TV} $，该损失多用于去噪和图片高清化。</strong><br>这个损失的相关解释可以参考<br><a href="https://en.wikipedia.org/wiki/Total_variation_denoising" target="_blank" rel="noopener">Total variation denoising wiki解释</a><br><a href="https://blog.csdn.net/afgh2587849/article/details/6401181" target="_blank" rel="noopener">Total Variation Denosing  一个博客中文的根据wiki的自己理解</a></p>
<h2 id="5-实验结果"><a href="#5-实验结果" class="headerlink" title="5.实验结果"></a>5.实验结果</h2><p><img src="/2018/10/31/风格转换-二-：Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution/line.jpg" alt=""></p>
<p>图像风格转换任务上，针对不同分辨率的图像，Loss值在Perceptual Loss(ours)和Gatys的对比。可以看到，使用Perceptual Loss相当于原始算法迭代50到100次。</p>
<p><img src="/2018/10/31/风格转换-二-：Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution/example3.jpg" alt=""></p>
<p>可以看到速度可以提升几百倍</p>
<p><img src="/2018/10/31/风格转换-二-：Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution/example5.jpg" alt=""></p>
<h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h2><p>感觉最大贡献就是图像风格转换的实用化，速度提升了很多个量级。然后这个模型可以做super-resolution，简单说来就是，输入$x$ 为模糊图片，$y_{c}$为ground-truth高清图片，$y_{s}​$不使用，loss要加一个Pixel Loss，就是输入输出图片的欧几里得距离，其余同理训练。</p>
<p><strong>参考</strong></p>
<ol>
<li><a href="https://blog.csdn.net/wyl1987527/article/details/56506653" target="_blank" rel="noopener">Perceptual Losses for Real-Time Style Transfer and Super-Resolution 论文 理解 </a></li>
<li><a href="https://www.jianshu.com/p/b728752a70e9" target="_blank" rel="noopener">[译] Perceptual Losses for Real-Time Style Transfer and Super-Resolution（Stanford University</a></li>
<li><a href="https://blog.csdn.net/stdcoutzyx/article/details/54025243" target="_blank" rel="noopener">感知损失(Perceptual Losses)</a></li>
</ol>
</div><div class="tags"><a href="/tags/图像风格转换/">图像风格转换</a></div><div class="post-nav"><a class="pre" href="/2018/11/07/cs231n-Lecture2-Image-Classification/">cs231n Lecture2 Image Classification</a><a class="next" href="/2018/10/30/风格转换-一-：A-Neural-Algorithm-of-Artistic-Style/">图像风格转换(一):A Neural Algorithm of Artistic Style</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs231n/">cs231n</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/百篇论文阅读计划/">百篇论文阅读计划</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/cs231n/" style="font-size: 15px;">cs231n</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/图像风格转换/" style="font-size: 15px;">图像风格转换</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/12/20/cs231n-参数设置技巧/">cs231n 参数设置技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/20/cs231n-Lecture5-Convolutional-Neural-Networks/">cs231n Lecture5 Convolutional Neural Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/14/BeautyGAN-Instance-level-Facial-Makeup-Transfer-with-Deep/">BeautyGAN: Instance-level Facial Makeup Transfer with Deep</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/10/cs231n-Lecture3-Loss-Functions-and-Optimization/">cs231n Lecture3 Loss Functions and Optimization</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/07/cs231n-Lecture2-Image-Classification/">cs231n Lecture2 Image Classification</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/31/风格转换-二-：Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution/">风格转换(二)：Perceptual Losses for Real-Time Style Transfer and Super-Resolution</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/30/风格转换-一-：A-Neural-Algorithm-of-Artistic-Style/">图像风格转换(一):A Neural Algorithm of Artistic Style</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/24/hello-world/">Hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/tiantianwahaha" title="github" target="_blank">github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Voila.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>