<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks]]></title>
    <url>%2F2019%2F03%2F19%2FStyleGAN-A-Style-Based-Generator-Architecture-for-Generative-Adversarial-Networks.html%2F</url>
    <content type="text"><![CDATA[Nvidia 2018.12 æå‡ºçš„æ–°çš„é«˜æ¸…äººè„¸ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨PGGANçš„åŸºç¡€ä¸Šè¿›è¡Œçš„æ”¹è¿›ã€‚ æ–‡ç« é“¾æ¥ ä¸»è¦æ€æƒ³è¿™é¡¹å·¥ä½œæå‡ºäº†å…³äºGANæ¡†æ¶çš„å¦ä¸€ä¸ªè§‚ç‚¹ï¼Œå…·ä½“æ¥è¯´ä»–ä»é£æ ¼è½¬æ¢ç½‘ç»œä¸­å¾—åˆ°çµæ„Ÿï¼Œæ”¹è¿›å¾—åˆ°æ–°çš„ç”Ÿæˆå™¨æ¶æ„ï¼Œåœ¨ç”Ÿæˆçš„å›¾åƒä¸­å¯ä»¥å­¦ä¹ é«˜çº§å±æ€§ï¼ˆå¦‚å¹´é¾„ã€åœ¨äººè„¸æˆ–èƒŒæ™¯ä¸Šè®­ç»ƒæ—¶çš„èº«ä»½ã€ç›¸æœºè§†è§’ï¼‰å’Œéšæœºå˜åŒ–ï¼ˆé›€æ–‘ã€å¤´å‘ç»†èŠ‚ï¼‰ã€‚å®ƒä¸ä»…å­¦ä¹ è‡ªåŠ¨åˆ†ç¦»è¿™äº›å±æ€§ï¼Œè€Œä¸”è¿˜å…è®¸æˆ‘ä»¬ä»¥éå¸¸ç›´è§‚çš„æ–¹å¼æ§åˆ¶åˆæˆã€‚ ç®€ä»‹ å·¦è¾¹æ˜¯ä¼ ç»Ÿçš„ç½‘ç»œæ¶æ„ï¼Œç”±å™ªå£°Zç”Ÿæˆå›¾ç‰‡ã€‚å³è¾¹æ˜¯æå‡ºçš„æ–°çš„ç”Ÿæˆæ¶æ„ï¼Œä¸»è¦æ˜¯æå‡ºäº†Aå’ŒBä¸¤ä¸ªæ¨¡å—ã€‚ åœ¨PGGAN(Progressive Growing of GANs)çš„åŸºç¡€ä¸Šåšçš„æ”¹è¿›ï¼Œç”Ÿæˆæ¨¡å‹ä»$4^2$åˆ°$1024^2$é€æ­¥ç”Ÿæˆé«˜æ¸…å›¾ç‰‡ï¼Œæ¯ä¸ªåˆ†è¾¨ç‡å¯¹åº”ä¸¤ä¸ªconvï¼Œä¹Ÿå°±æ˜¯æ€»å…±18å±‚ç½‘ç»œï¼Œæœ€åæ¥äº†ä¸€å±‚conv1Ã—1å°†ç‰¹å¾è½¬æ¢ä¸ºRGBå›¾ç‰‡ã€‚æ­£å¸¸çš„ç”Ÿæˆæ¨¡å‹ï¼Œæ˜¯è¾“å…¥å™ªå£°Zï¼Œç»è¿‡å·ç§¯ç½‘ç»œç”Ÿæˆå›¾ç‰‡ã€‚ è€Œstyleganè®¾è®¡äº†ä¸€ä¸ªMapping Networkï¼ŒåŒ…æ‹¬8å±‚å…¨è¿æ¥å±‚(åé¢åªæ¥äº†æ¿€æ´»å‡½æ•°lreluï¼Œæ²¡æœ‰æ­£åˆ™åŒ–)ï¼Œè¾“å…¥å™ªå£°Zï¼Œè¾“å‡ºä¸ºä¸­é—´éšå˜é‡â±³ï¼ŒZå’Œâ±³ä»¥åŠæ¯å±‚å…¨è¿æ¥ï¼Œå¤§å°éƒ½æ˜¯512Ã—1ã€‚ç„¶åâ±³ç»è¿‡Aæ¨¡å—(å…¶å®å°±æ˜¯å•ç‹¬çš„ä¸€å±‚å…¨è¿æ¥)ï¼Œé€šè¿‡AdaINæ“ä½œä¸ºå›¾ç‰‡è´¡çŒ®é£æ ¼æ§åˆ¶ã€‚åŠ å…¥Aï¼Œæ§åˆ¶äº†å›¾ç‰‡çš„styleï¼Œå§¿åŠ¿ï¼Œæ€§åˆ«ï¼Œå¹´çº§ç­‰ç­‰å¤§çš„ç‰¹å¾ã€‚ åœ¨AdaINæ¨¡å—ä¹‹å‰ï¼Œæ¯ä¸ªé€šé“éƒ½ä¼šæ·»åŠ ä¸€ä¸ªç¼©æ”¾çš„å™ªå£°Bã€‚åŠ å…¥Bï¼Œæ§åˆ¶é›€æ–‘ï¼Œçš±çº¹ç­‰ç»†å¾®ç‰¹å¾ï¼Œä½¿å›¾ç‰‡æ›´åŠ çœŸå®ï¼Œè¾“å‡ºæ›´åŠ å¤šæ ·æ€§ã€‚ å®éªŒä¸å†ä»éšå˜é‡ç”Ÿæˆä¸åŒçš„4*4åŸºç¡€å›¾ç‰‡ï¼Œè€Œæ˜¯å…¨éƒ½ä½¿ç”¨ constant valueså›ºå®šå€¼çš„4Ã—4ï¼Œæºç ä¸­å…¨éƒ¨è®¾ä¸º1ï¼Œä»¥æ­¤ä¸ºåŸºç¡€å­¦ä¹ ç”Ÿæˆé«˜æ¸…å›¾ç‰‡ã€‚ ä¸»è¦è´¡çŒ®1.Mapping Networkæ˜ å°„æ¨¡å—ç”Ÿæˆæ¨¡å‹æœ‰18å±‚ï¼Œæ‰€ä»¥Zè¾“å…¥Mapping Networkï¼Œä¹Ÿè¾“å‡ºå¯¹åº”çš„18ä¸ªâ±³ 2.Style Modules (AdaIN)è‡ªé€‚åº”å®ä¾‹å½’ä¸€åŒ–è¿™ä¸ªæ˜¯å¦ä¸€ç¯‡æ–‡ç« æå‡ºçš„ï¼Œæˆ‘çš„å¦ä¸€ç¯‡åšå®¢ä»‹ç»äº†ã€‚å°±æ˜¯æŠŠå†…å®¹å›¾ç‰‡çš„æ¯ä¸ªä¿¡é“çš„åˆ†å¸ƒï¼Œç»è¿‡å¹³ç§»å’Œå˜æ¢åˆ°é£æ ¼å›¾ç‰‡å¯¹åº”çš„ä¿¡é“åˆ†å¸ƒä¸Šã€‚ 3.Removing traditional inputå°±æ˜¯æŠŠç”Ÿæˆå™¨çš„è¾“å…¥å˜æˆå›ºå®šçš„4*4 The StyleGAN team found that the image features are controlled by â±³ and the AdaIN, and therefore the initial input can be omitted and replaced by constant values. æ–‡ç« å¹¶æ²¡æœ‰è§£é‡Šä¸ºä»€ä¹ˆï¼Œå¯èƒ½æ˜¯å‡å°‘äº†ç‰¹å¾çº ç¼ ï¼Œç½‘ç»œæ›´å®¹æ˜“é€šè¿‡ â±³æ¥å­¦ä¹ ï¼Œè€Œä¸ä¾èµ–äºçº ç¼ çš„è¾“å…¥å‘é‡ 4.Stochastic variation å™ªå£°Bå¼•å…¥äº†éšæœºå˜åŒ–The common method to insert these small features into GAN images is adding random noise to the input vector. However, in many cases itâ€™s tricky to control the noise effect due to the features entanglement phenomenon that was described above, which leads to other features of the image being affected. ä½¿å›¾åƒå¤šæ ·æ€§æœ€ç›´æ¥çš„æ–¹æ³•æ˜¯åŠ å…¥å°çš„éšæœºå™ªå£°ï¼Œä½†æ˜¯è¿™ä¼šå¸¦æ¥features entanglement phenomenonç‰¹å¾çº ç¼ ç°è±¡ï¼Œå°±æ˜¯åŠ äº†å™ªå£°ï¼Œä¼šå¯¼è‡´å…¶ä»–çš„å›¾åƒç‰¹å¾ä¹Ÿæ”¶å½±å“ï¼Œæœ¬æ–‡çš„åŠ å…¥Bçš„æ–¹æ³•ï¼Œè§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼ŒåŒæ—¶æå‡ºäº†ä¸¤ä¸ªæŒ‡æ ‡æ¥åº¦é‡features entanglementç°è±¡ 5.Style mixing é£æ ¼æ··åˆ å›¾ç‰‡å±•ç¤ºçš„æ˜¯é£æ ¼æ··åˆæ•ˆæœï¼Œæ“ä½œå¦‚ä¸‹ï¼š 5ä¸ªéšæœºçš„Zï¼Œé€šè¿‡Mapping Networkç”Ÿæˆå¯¹åº”çš„[5,18,512]çš„â±³ï¼Œç„¶åçš„åˆ°5ä¸ªsourceå›¾ç‰‡ åŒç†ï¼Œå¾—åˆ°5ä¸ªdestination å–sourceçš„18ä¸ªâ±³ä¸­å¯¹åº”ï¼ˆ$4^2$ â€“ $8^2$ï¼‰çš„4ä¸ªâ±³ï¼Œæ›¿æ¢destinationä¸­çš„å¯¹åº”ä½ç½®ï¼Œå¾—åˆ°æ–°çš„å›¾ç‰‡ï¼Œå±•ç¤ºåœ¨ç¬¬äºŒè¡Œ å¯¹ç©ºé—´åˆ†è¾¨ç‡è¾ƒä½ï¼ˆ$4^2$ â€“ $8^2$ï¼‰(1-4)çš„å±‚çš„é£æ ¼è¿›è¡Œå åŠ çš„æ•ˆæœè§ã€ŒCoarse styles copiedã€éƒ¨åˆ†ï¼šç”Ÿæˆå›¾åƒä» source ä¸­å¤åˆ¶äº†å§¿åŠ¿ã€å¤§è‡´å‘å‹ã€è„¸å½¢å’Œçœ¼é•œç­‰é«˜çº§å±æ€§ï¼Œä½†ä¿ç•™äº† destination å›¾åƒçš„æ‰€æœ‰é¢œè‰²ï¼ˆçœ¼ç›ã€å¤´å‘ã€å…‰çº¿ï¼‰å’Œç»†èŠ‚è„¸éƒ¨ç‰¹å¾ã€‚ å¯¹ç©ºé—´åˆ†è¾¨ç‡ä¸º ($16^2$ â€“ $32^2$) (4-8)çš„å±‚çš„é£æ ¼è¿›è¡Œå åŠ çš„æ•ˆæœè§ã€ŒMiddle styles copiedã€éƒ¨åˆ†ï¼šå¤åˆ¶äº† source å›¾åƒçš„ç»†å¾®é¢éƒ¨ç‰¹å¾ã€å‘å‹ã€çœ¼ç›çå¼€çš„çŠ¶æ€ï¼ŒåŒæ—¶ä¿ç•™äº† destination å›¾åƒçš„å§¿åŠ¿ã€è„¸å½¢å’Œçœ¼é•œã€‚ å¯¹é«˜åˆ†è¾¨ç‡ ($64^2$ â€“ $1024^2$) (8-18)çš„å±‚çš„é£æ ¼è¿›è¡Œå åŠ çš„æ•ˆæœè§ã€ŒFine stylesã€ï¼šä¸»è¦ä¿ç•™äº† source å›¾åƒçš„é¢œè‰²å’Œå¾®å°ç‰¹å¾ã€‚ 6.Truncation trick in W One of the challenges in generative models is dealing with areas that are poorly represented in the training data. The generator isnâ€™t able to learn them and create images that resemble them (and instead creates bad-looking images). To avoid generating poor images, StyleGAN truncates the intermediate vector â±³, forcing it to stay close to the â€œaverageâ€ intermediate vector. After training the model, an â€œaverageâ€ â±³avg is produced by selecting many random inputs; generating their intermediate vectors with the mapping network; and calculating the mean of these vectors. When generating new images, instead of using Mapping Network output directly, â±³ is transformed into â±³_new=â±³_avg+ğ§(â±³ -â±³_avg), where the value of ğ§ defines how far the image can be from the â€œaverageâ€ image (and how diverse the output can be). Interestingly, by using a different ğ§ for each level, before the affine transformation block, the model can control how far from average each set of features is, as shown in the video below. 7.Fine-tuningæ”¹è¿›äº†PGGANçš„å‡ ä¸ªè¶…å‚æ•°ï¼Œæ¯”å¦‚è®­ç»ƒæ—¶é—´å’ŒæŸå¤±å‡½æ•°ã€‚and replacing the up/downscaling from nearest neighbors to bilinear samplingï¼Œå¯¹æ¨¡å‹æ•ˆæœçš„æå‡æŒºé‡è¦ã€‚ 8.Results å±•ç¤ºäº†åœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„FrÃ¨chet inception distance (FID) score 9.FlickrFaces-HQï¼ˆFFHQï¼‰åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„é«˜æ¸…äººè„¸æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å« 70000 å¼ åˆ†è¾¨ç‡ä¸º 1024^2 çš„é«˜è´¨é‡å›¾åƒï¼Œå…¶ä¸­çš„å›¾åƒåœ¨å¹´é¾„ã€ç§æ—ã€å›¾åƒèƒŒæ™¯ç­‰æ–¹é¢æ¯” CelebA-HQå…·å¤‡æ›´å®½æ³›çš„å˜åŒ–ï¼Œä¸”æ¶µç›–æ›´å¤šé…é¥°ï¼Œå¦‚çœ¼é•œã€å¤ªé˜³é•œã€å¸½å­ç­‰ å¤§è‡´ç®—æ³•æµç¨‹ï¼ï¼ï¼ åŒPGGAN(Progressive Growing of GANs)ä»$4^2$åˆ°$1024^2$ï¼Œæ¯ä¸ªåˆ†è¾¨ç‡å¯¹åº”ä¸¤ä¸ªconvï¼Œä¹Ÿå°±æ˜¯æ€»å…±18å±‚ç½‘ç»œã€‚æ­£å¸¸çš„ç”Ÿæˆæ¨¡å‹ï¼Œæ˜¯è¾“å…¥å™ªå£°Zï¼Œç»è¿‡å·ç§¯ç½‘ç»œç”Ÿæˆå›¾ç‰‡ã€‚ styleganè®¾è®¡äº†ä¸€ä¸ªMapping Networkï¼ŒåŒ…æ‹¬8å±‚å…¨è¿æ¥å±‚(åé¢åªæ¥äº†æ¿€æ´»å‡½æ•°lreluï¼Œæ²¡æœ‰æ­£åˆ™åŒ–)ï¼Œè¾“å‡ºä¸ºä¸­é—´éšå˜é‡â±³ï¼ŒZå’Œâ±³ä»¥åŠæ¯å±‚å…¨è¿æ¥ï¼Œå¤§å°éƒ½æ˜¯512Ã—1 å‡è®¾åœ¨resolutionåˆ†è¾¨ç‡ä¸º8çš„æ—¶å€™ï¼Œä¹Ÿå°±æ˜¯x.shape=[bs,channel,8,8] å…ˆä¸ºxåŠ å…¥å™ªå£°ï¼Œå™ªå£°noiseå°±æ˜¯ä¸€ä¸ª[1,1,8,8]çš„éšæœºé«˜æ–¯ï¼Œä¼šç°ä¹˜ä»¥ä¸€ä¸ªæƒé‡W[1,1,1,1]ï¼Œç„¶åç›´æ¥ä¸xç›¸åŠ  x+noiseï¼Œä¹Ÿå°±æ˜¯Xçš„æ¯ä¸ªä¿¡é“éƒ½åŠ äº†ç›¸åŒçš„å™ªå£° ç„¶ååº”ç”¨åå·®apply_biasï¼Œå°±æ˜¯åœ¨xçš„æ¯ä¸€ä¸ªä¿¡é“åŠ ä¸Šä¸åŒçš„åå·® xä¸Šåº”ç”¨æ¿€æ´»å‡½æ•°lrelu xçš„æ¯ä¸ªä¿¡é“è¿›è¡Œinstance_normï¼Œç¡®ä¿AdaINæ¨¡å—çš„ç¼©æ”¾å’Œå¹³ç§»(scaling and shifting)è¾¾åˆ°é¢„æœŸçš„æ•ˆæœ æ¥ä¸‹æ¥å°±æ˜¯AdaINæ“ä½œã€‚ç»è¿‡Mapping Networkå­¦ä¹ åˆ°18ä¸ªâ±³ï¼Œæ‰¾åˆ°å¯¹åº”8åˆ†è¾¨ç‡çš„è¿™ä¸ªâ±³ï¼Œå†ç»è¿‡Aä»¿å°„ã€‚å…¶å®å°±æ˜¯åˆç»è¿‡ä¸€ä¸ªå•ç‹¬çš„å…¨è¿æ¥å±‚ï¼Œè¾“å…¥æ˜¯512ï¼Œè¾“å‡ºæ˜¯2*channelï¼Œåˆ†åˆ«è¡¨ç¤º$y_s$å’Œ$y_b$,å°±æ˜¯ç”¨äºAdaINçš„scaleå’Œbiaseã€‚ X = XÃ—($y_s$+1) + $y_b$,æ€»å…±bathsizeä¸ªï¼Œæ¯ä¸ªå›¾ç‰‡çš„ä¸åŒã€‚ å‚è€ƒä½œè€…å…¬å¸ƒçš„tensorflowæºç  ä½œè€…å…¬å¸ƒçš„è§†é¢‘ï¼Œå¾ˆå€¼å¾—çœ‹,ä»‹ç»äº†æ¨¡å‹çš„ä¸‰ä¸ªè´¡çŒ® å‚è€ƒçš„åšå®¢1ï¼Œéå¸¸è¯¦ç»†çš„ä»‹ç»å’Œæ¨¡å‹å›¾ç‰‡ï¼Œæœ¬æ–‡ä¸»è¦å‚è€ƒç¿»è¯‘äº†è¿™ä¸ªåšå®¢çš„éƒ¨åˆ†è®²è§£.Explained: A Style-Based Generator Architecture for GANs - Generating and Tuning Realistic Artificial Faces å‚è€ƒçš„åšå®¢2 https://dtransposed.github.io/blog/Best-of-GANs-2018-(Part-1-out-of-2).html å‚è€ƒçš„ä¸­æ–‡åšå®¢3ï¼Œç®€å•ä»‹ç»äº†è®ºæ–‡ä¸­æ’å›¾è®²çš„ä»€ä¹ˆ]]></content>
      <categories>
        <category>ç™¾ç¯‡è®ºæ–‡é˜…è¯»è®¡åˆ’</category>
      </categories>
      <tags>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization]]></title>
    <url>%2F2019%2F03%2F19%2FArbitrary-Style-Transfer-in-Real-time-with-Adaptive-Instance-Normalization.html%2F</url>
    <content type="text"><![CDATA[Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization è®ºæ–‡åœ°å€ ä½œè€…æºç å®ç°Torch è¾ƒæ—©çš„ä¸€ç¯‡æ•ˆæœä¸é”™çš„ä»»æ„é£æ ¼ä»»æ„å†…å®¹çš„é£æ ¼è½¬æ¢æ¨¡å‹ã€‚ ä¸»è¦è´¡çŒ®å°±æ˜¯æå‡ºäº†AdaINï¼ˆAdaptive Instance Normalizationï¼‰è‡ªé€‚åº”å®ä¾‹å½’ä¸€åŒ–ï¼Œnvidiaçš„stylegané‡Œç”¨äº†è¿™ä¸ªç»“æ„ æ²¡ä»”ç»†è¯»è®ºæ–‡ï¼Œç®€å•çœ‹äº†ä¸¤ç¯‡åšå®¢ã€‚ æ¨¡å‹ç»“æ„æ¨¡å‹åŒ…æ‹¬ä¸‰éƒ¨åˆ†Encoder-AdaIN-Decoderã€‚ Encoder éƒ¨åˆ†æ˜¯é‡‡ç”¨é¢„è®­ç»ƒå¥½çš„VGGç½‘ç»œï¼Œåªä½¿ç”¨åˆ°äº†Relu4_1éƒ¨åˆ†ï¼Œå°†é£æ ¼å’Œå†…å®¹å›¾çš„å›¾åƒéƒ½ä»å›¾åƒç©ºé—´è½¬åˆ°ç‰¹å¾ç©ºé—´ã€‚ AdaINå±‚æ˜¯å¯¹å†…å®¹å›¾è¿›è¡Œå½’ä¸€åŒ–ï¼Œè¿™é‡Œæ˜¯é€šè¿‡å¯¹é½Relu4_1å±‚è¾“å‡ºçš„å†…å®¹å›¾å¯¹åº”çš„æ¯é€šé“çš„feature mapçš„å‡å€¼å’Œæ–¹å·®æ¥åŒ¹é…é£æ ¼å›¾æ¯é€šé“feature mapçš„å‡å€¼å’Œæ–¹å·®ã€‚å°±æ˜¯æŠŠå†…å®¹å›¾æ¯ä¸ªé€šé“çš„æ‰€æœ‰å…ƒç´ å½’ä¸€åŒ–åˆ°é£æ ¼å›¾å¯¹åº”é€šé“ä¸Šã€‚ Decoderéƒ¨åˆ†æ˜¯ä¸€ä¸ªå°†feature ç©ºé—´è½¬æˆå›¾åƒç©ºé—´çš„ç½‘ç»œï¼Œè¿™éƒ¨åˆ†ç½‘ç»œä¸€èˆ¬æ˜¯é‡‡ç”¨å’Œencoderå¯¹ç§°çš„ç½‘ç»œç»“æ„ï¼Œæ•´ä¸ªç½‘ç»œä¸­éœ€è¦è®­ç»ƒçš„å°±æ˜¯è¿™éƒ¨åˆ†ç½‘ç»œçš„æƒé‡å‚æ•°ä¿¡æ¯ï¼Œåˆå§‹å¯ä»¥éšæœºä¸€äº›åˆå§‹åŒ–å‚æ•°ï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™å¯ä»¥ä¸æ–­è¿›è¡Œæ›´æ–°å‚æ•°ä»¥ä½¿æ•´ä¸ªæŸå¤±å‡½æ•°ä¸‹é™ã€ç½‘ç»œé€æ¸æ”¶æ•›ã€‚æ± åŒ–å±‚ä¸€èˆ¬æ˜¯æ›¿æ¢æˆé‡‡ç”¨æœ€è¿‘é‚»ä¸Šé‡‡æ ·çš„æ–¹å¼æ¥é˜²æ­¢æ£‹ç›˜æ•ˆåº”ï¼Œåœ¨encoder å’Œ decoderéƒ¨åˆ†çš„paddingä¸€èˆ¬éƒ½æ˜¯é‡‡ç”¨åå°„å¡«å……é¿å…è¾¹ç•Œartifactsã€‚decoderä¸­æ²¡æœ‰ä½¿ç”¨å½’ä¸€åŒ–å±‚ï¼Œå› ä¸ºIN/BNè¿™äº›å®ä¾‹å½’ä¸€åŒ–å’Œæ‰¹å½’ä¸€åŒ–éƒ½æ˜¯é’ˆå¯¹å•ä¸ªé£æ ¼çš„ æŸå¤±å‡½æ•°å°±æ˜¯å†…å®¹æŸå¤±+é£æ ¼æŸå¤± é£æ ¼æŸå¤±æ˜¯è½¬æ¢åå›¾åƒåœ¨vggç½‘ç»œä¸­Relu4_1çš„ç‰¹å¾å’ŒadaINè¾“å‡ºfeature mapsçš„æ¬§å¼è·ç¦» å†…å®¹æŸå¤±ï¼Œæ²¡ç”¨ä½¿ç”¨GramçŸ©é˜µï¼Œç®€å•çš„é‡‡ç”¨äº†relu1_1,relu2_1,relu3_1,relu4_1å››å±‚çš„feature mapsï¼Œæ±‚å¯¹åº”çš„ç‰¹å¾è·ç¦»æŸå¤±ã€‚ ç»“æœå›¾åƒè´¨é‡è¶…è¿‡åŸæ¥çš„æ–‡ç« æˆ–è€…å·®ä¸å¤šï¼Œä½†æ˜¯é€Ÿåº¦å¿«äº†1-2ä¸ªé‡çº§ å‚è€ƒåšå®¢1.Arbitrary Style Transfer in Real-time with Adaptive Instance Normalizationè®ºæ–‡ç†è§£ 2.è®ºæ–‡Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization]]></content>
      <categories>
        <category>ç™¾ç¯‡è®ºæ–‡é˜…è¯»è®¡åˆ’</category>
      </categories>
      <tags>
        <tag>å›¾åƒé£æ ¼è½¬æ¢</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PatchGAN Discriminator]]></title>
    <url>%2F2019%2F03%2F18%2FPatchGAN-Discriminator.html%2F</url>
    <content type="text"><![CDATA[PatchGANç”±æœ±ä¿Šå½¦çš„pix2pixä¸€æ–‡ä¸­æå‡ºä½¿ç”¨ï¼ŒImage-to-Image Translation with Conditional Adversarial Networks ä¹‹å‰çš„GANé‰´åˆ«å™¨ï¼Œæ˜¯è¾“å…¥å›¾ç‰‡ï¼Œè¾“å‡ºä¸€ä¸ªç¥ç»å…ƒï¼Œåˆ¤åˆ«å›¾ç‰‡æ˜¯çœŸè¿˜æ˜¯å‡ï¼Œæˆ‘ä»¬å¯ä»¥ç§°ä¸ºImage GAN å¦‚æœé‰´åˆ«å™¨è¾“å…¥å›¾ç‰‡ï¼Œè¾“å‡ºçš„æ˜¯wÃ—HÃ—1ï¼Œé’ˆå¯¹æ¯ä¸ªåƒç´ çš„çœŸå‡è¿›è¡Œäº†é¢„æµ‹ï¼Œæˆ‘ä»¬ç§°ä¸ºPixel GAN patchGANæ˜¯åœ¨ä¸¤è€…ä¹‹é—´ï¼Œè¾“å‡ºä¸€ä¸ª30Ã—30Ã—1ï¼Œæ¯ä¸ªç¥ç»å…ƒå¯¹åº”çš„æ„Ÿå—é‡å¤§å°æ˜¯70Ã—70ï¼Œæˆ‘ä»¬ç§°ä¸ºPatch GAN(70x70)ã€‚æ–‡ç« ä¸­é»˜è®¤ç»è¿‡ä¸‰æ¬¡å·ç§¯ç½‘ç»œå¾—åˆ°è¾“å‡ºã€‚æ–‡ç« ä¸­è¯´æµ‹è¯•äº†70åœ¨ä»–çš„å®éªŒä¸­è¡¨ç°çš„å¥½ï¼Œæ€§èƒ½è¶…è¿‡Image GANå’ŒPixel GAN åœ¨æ–‡ç«  ä½œè€…çš„æºç é‡Œæœ€åä¸€å±‚çš„output_channel=1ï¼Œfilter=4ï¼Œstride=1ï¼Œpadding=1 åœ¨å¦ä¸€ç¯‡æ–‡ç« çš„patchganå®ç°ä¸­æœ€åä¸€å±‚ç”¨ä¸€ä¸ª filter=1 stride=1ï¼Œoutput_channel=1 åœ¨è‡ªå·±çš„ä»»åŠ¡ä¸­å¯ä»¥çœ‹å›¾ç‰‡å¤§å°çš„å…·ä½“æƒ…å†µè¿›è¡Œè®¾è®¡ï¼ï¼ æ³¨æ„ï¼Œæ–‡ç« ä¸­é‰´åˆ«å™¨é»˜è®¤ä½¿ç”¨äº†ä¸‰æ¬¡å·ç§¯ç½‘ç»œï¼ŒåŒæ—¶ä»–æ˜¯ä¸€ä¸ªåŸŸè½¬æ¢çš„æ¡ä»¶GANï¼Œéœ€è¦åŒæ—¶feedè¿›å»inputå’Œoutputçš„å›¾ç‰‡ï¼Œä¹Ÿå°±æ˜¯concateåˆ°ä¸€èµ·è¾“å…¥D. å…·ä½“ç»“æ„å’Œå®ç°ä»£ç å¯ä»¥å‚è€ƒgithubæŸè®ºæ–‡çš„æºç è¿›è¡Œå­¦ä¹ åˆ†æï¼Œçœ‹ä»–çš„readmeé‡Œçš„ç½‘ç»œç»“æ„å›¾ï¼Œçœ‹codes/modelé‡ŒæŸå¤±å‡½æ•°æ€ä¹ˆå†™ æ¨¡å‹ç»“æ„ï¼Œä¾›å‚è€ƒï¼Œä»–é‡Œé¢ç”¨äº†ä¸‹é‡‡æ · def discriminator_patch2(self, data, name=&apos;d_&apos;, is_reuse=False): with tf.variable_scope(name) as scope: if is_reuse is True: scope.reuse_variables() # conv1: (N, 640, 640, 4) -&gt; (N,, 160, 160, 32) conv1 = tf_utils.conv2d(data, self.dis_c, k_h=3, k_w=3, d_h=2, d_w=2, name=&apos;conv1_conv1&apos;) conv1 = tf_utils.batch_norm(conv1, name=&apos;conv1_batch1&apos;, _ops=self._dis_train_ops) conv1 = tf.nn.relu(conv1, name=&apos;conv1_relu1&apos;) conv1 = tf_utils.conv2d(conv1, self.dis_c, k_h=3, k_w=3, d_h=1, d_w=1, name=&apos;conv1_conv2&apos;) conv1 = tf_utils.batch_norm(conv1, name=&apos;conv1_batch2&apos;, _ops=self._dis_train_ops) conv1 = tf.nn.relu(conv1, name=&apos;conv1_relu2&apos;) pool1 = tf_utils.max_pool_2x2(conv1, name=&apos;maxpool1&apos;) # conv2: (N, 160, 160, 32) -&gt; (N, 80, 80, 64) conv2 = tf_utils.conv2d(pool1, 2*self.dis_c, k_h=3, k_w=3, d_h=1, d_w=1, name=&apos;conv2_conv1&apos;) conv2 = tf_utils.batch_norm(conv2, name=&apos;conv2_batch1&apos;, _ops=self._dis_train_ops) conv2 = tf.nn.relu(conv2, name=&apos;conv2_relu1&apos;) conv2 = tf_utils.conv2d(conv2, 2*self.dis_c, k_h=3, k_w=3, d_h=1, d_w=1, name=&apos;conv2_conv2&apos;) conv2 = tf_utils.batch_norm(conv2, name=&apos;conv2_batch2&apos;, _ops=self._dis_train_ops) conv2 = tf.nn.relu(conv2, name=&apos;conv2_relu2&apos;) pool2 = tf_utils.max_pool_2x2(conv2, name=&apos;maxpool2&apos;) # conv3: (N, 80, 80, 64) -&gt; (N, 80, 80, 128) conv3 = tf_utils.conv2d(pool2, 4*self.dis_c, k_h=3, k_w=3, d_h=1, d_w=1, name=&apos;conv3_conv1&apos;) conv3 = tf_utils.batch_norm(conv3, name=&apos;conv3_batch1&apos;, _ops=self._dis_train_ops) conv3 = tf.nn.relu(conv3, name=&apos;conv3_relu1&apos;) conv3 = tf_utils.conv2d(conv3, 4*self.dis_c, k_h=3, k_w=3, d_h=1, d_w=1, name=&apos;conv3_conv2&apos;) conv3 = tf_utils.batch_norm(conv3, name=&apos;conv3_batch2&apos;, _ops=self._dis_train_ops) conv3 = tf.nn.relu(conv3, name=&apos;conv3_relu2&apos;) # æœ€åä¸€å±‚ç”¨ä¸€ä¸ª filter=1 stride=1ï¼Œoutput_channel=1 # output layer: (N, 80, 80, 128) -&gt; (N, 80, 80, 1) output = tf_utils.conv2d(conv3, 1, k_h=1, k_w=1, d_h=1, d_w=1, name=&apos;conv_output&apos;) return tf.nn.sigmoid(output), output æŸå¤±å‡½æ•° # å‰é¢å‡ è¡Œæ„æ€æ˜¯ï¼Œå¦‚æœæ˜¯æˆå¯¹çš„åŸŸè½¬æ¢ï¼Œè¦æŠŠè¾“å…¥åŸŸå›¾ç‰‡å’Œè¾“å‡ºåŸŸå›¾ç‰‡concateåˆ°ä¸€èµ·ï¼Œè¾“å…¥åˆ°é‰´åˆ«å™¨ä¸­é‰´åˆ« self.g_samples = self.generator(self.X) self.real_pair = tf.concat([self.X, self.Y], axis=3) self.fake_pair = tf.concat([self.X, self.g_samples], axis=3) d_real, d_logit_real = self.discriminator(self.real_pair) d_fake, d_logit_fake = self.discriminator(self.fake_pair, is_reuse=True) # discrminator loss self.d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits( logits=d_logit_real, labels=tf.ones_like(d_real))) self.d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits( logits=d_logit_fake, labels=tf.zeros_like(d_logit_fake))) self.d_loss = self.d_loss_real + self.d_loss_fake è®ºæ–‡åŸæ–‡ä¸€ç¯‡åšå®¢å¯¹è®ºæ–‡åŸæ–‡ç¿»è¯‘å¦‚ä¸‹ 3.2.2 Markovian discriminiator (PatchGAN) L2å’ŒL1æŸå¤±å‡½æ•°æœ‰å¯èƒ½åœ¨å›¾åƒç”Ÿæˆä¸­é€ æˆæ¨¡ç³Šç»“æœã€‚å°½ç®¡è¿™äº›å¯¹é«˜é¢‘æ¸…æ™°åº¦è€Œè¨€æ•ˆæœè¾ƒå·®ï¼Œä½†åœ¨è®¸å¤šæƒ…å†µä¸‹ä»èƒ½å‡†ç¡®åœ°æ•è·ä½é¢‘ã€‚å¯¹äºè¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬ä¸éœ€è¦ä¸€ä¸ªå…¨æ–°çš„ç½‘ç»œåœ¨ä½é¢‘éƒ¨åˆ†è¿›è¡Œçº æ­£ã€‚L1å·²ç»å¯ä»¥å®Œæˆäº†ã€‚ è¿™ä½¿å¾—GANçš„åˆ¤åˆ«å™¨ä»…æ¨¡æ‹Ÿé«˜é¢‘ç»“æ„ï¼Œä¾é L1æ¥å¼ºåˆ¶ä½é¢‘éƒ¨åˆ†çš„æ­£ç¡®æ€§ã€‚å¯¹äºæ¨¡æ‹Ÿé«˜é¢‘ï¼Œåªè¦å°†æ³¨æ„åŠ›é™åˆ¶åœ¨å±€éƒ¨å›¾åƒå—ä¸­ç»“æ„å°±å¯ä»¥äº†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªåˆ¤åˆ«å™¨ç»“æ„â€”æˆ‘ä»¬å«å®ƒPatchGANï¼Œåªåœ¨è¡¥ä¸ï¼ˆpatchï¼‰èŒƒå›´å†…å¯¹ç»“æ„è¿›è¡Œæƒ©ç½šã€‚è¿™ä¸ªåˆ¤åˆ«å™¨å°è¯•åœ¨ä¸€å¹…å›¾çš„æ¯ä¸ªNÃ—Nå¤§å°çš„è¡¥ä¸ä¸Šè¿›è¡Œreal or fakeçš„åˆ¤æ–­ã€‚æˆ‘ä»¬åœ¨æ•´ä¸ªå›¾ç‰‡ä¸Šè¿è¡Œè¿™ä¸ªåˆ¤åˆ«å™¨ï¼Œå¹¶å¯¹æ‰€æœ‰çš„ç»“æœå–å‡å€¼ï¼Œä»¥é¿å…åˆ¤åˆ«å™¨çš„æç«¯è¾“å‡ºã€‚ åœ¨4.4éƒ¨åˆ†ï¼Œæˆ‘ä»¬è¯´æ˜äº†Nå¯ä»¥æ¯”imageçš„å°ºå¯¸å°å¾ˆå¤šå¹¶ä¸”ä»æ—§å¯ä»¥äº§ç”Ÿé«˜è´¨é‡çš„ç»“æœã€‚è¿™æ˜¯æœ‰åˆ©çš„ï¼Œå› ä¸ºä¸€ä¸ªæ›´å°çš„PatchGANæœ‰æ›´å°‘çš„å‚æ•°ï¼Œè¿è¡Œæ›´å¿«ï¼Œå¹¶ä¸”å¯ä»¥åœ¨ä»»æ„å¤§å°çš„å›¾ç‰‡ä¸Šè¿è¡Œã€‚ è¿™ç§åˆ¤åˆ«å™¨å°†æœ‰æ•ˆçš„å°†å›¾åƒå»ºç«‹ä¸ºä¸€ä¸ªé©¬å°”ç§‘å¤«éšæœºåœºï¼Œå¹¶å‡å®šåƒç´ é—´çš„ç‹¬ç«‹æ€§å¤§äºè¡¥ä¸çš„ç›´å¾„ã€‚[35]ä»¥å‰æ¢è®¨è¿‡è¿™ç§è”ç³»ï¼Œä¹Ÿæ˜¯çº¹ç†å’Œé£æ ¼æ¨¡å‹çš„å¸¸è§å‡è®¾[15,19,14,23,20,34]ã€‚å› æ­¤æˆ‘ä»¬çš„PatchGANä¹Ÿå¯ä»¥ç†è§£ä¸ºä¸€ç§é£æ ¼/çº¹ç†æŸå¤±ã€‚ é™„å½•ï¼šä½œè€…åœ¨githubå¯¹æŸä¸ªæé—®çš„å›ç­”ï¼Œè§£é‡Špatchgan è®ºæ–‡ä½œè€…çš„pytorchå®ç°patchgan In fact, a â€œPatchGANâ€ is just a convnet! Or you could say all convnets are patchnets: the power of convnets is that they process each image patch identically and independently, which makes things very cheap (# params, time, memory), and, amazingly, turns out to work. The difference between a PatchGAN and regular GAN discriminator is that rather the regular GAN maps from a 256x256 image to a single scalar output, which signifies â€œrealâ€ or â€œfakeâ€, whereas the PatchGAN maps from 256x256 to an NxN array of outputs X, where each X_ij signifies whether the patch ij in the image is real or fake. Which is patch ij in the input? Well, output X_ij is just a neuron in a convnet, and we can trace back its receptive field to see which input pixels it is sensitive to. In the CycleGAN architecture, the receptive fields of the discriminator turn out to be 70x70 patches in the input image! This is all mathematically equivalent to if we had manually chopped up the image into 70x70 overlapping patches, run a regular discriminator over each patch, and averaged the results. Maybe it would have been better if we called it a â€œFully Convolutional GANâ€ like in FCNsâ€¦ itâ€™s the same idea :)]]></content>
      <categories>
        <category>ç™¾ç¯‡è®ºæ–‡é˜…è¯»è®¡åˆ’</category>
      </categories>
      <tags>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Reset TeamViewer ID]]></title>
    <url>%2F2019%2F02%2F12%2FReset-TeamViewer-ID.html%2F</url>
    <content type="text"><![CDATA[TeamViewerç–‘ä¼¼å•†ä¸šåº”ç”¨ 5åˆ†é’Ÿé™åˆ¶ï¼Œè§£å†³åŠæ³• æ–¹æ³•ä¸€å»å®˜ç½‘å¡«è¡¨æ ¼ç”³è¯‰ï¼Œè¿™ä¸ªæ¯”è¾ƒæ…¢ï¼Œè‡³å°‘ä¸€å‘¨ï¼Œå…¶å®å°±æ˜¯ä»–é‚£è¾¹å¸®ä½ é‡ç½®ä¸€ä¸ªIDå· æ–¹æ³•äºŒ éœ€è¦è£…å¸TeamViewerï¼Œç”¨360æ¸…ç©ºä¸‹æ³¨å†Œè¡¨ï¼Œæˆ–è€…æ‰‹åŠ¨æ¸…ç©ºï¼Œæ¸…ç©ºæ­¥éª¤å‚è€ƒè¿™ä¸ªåšå®¢ã€‚ ç„¶ååœ¨è®¾å¤‡ç®¡ç†å™¨ä¸­æ›´æ”¹æœ‰çº¿ç½‘å¡å’Œæ— çº¿ç½‘å¡çš„MACåœ°å€ï¼Œæ— çº¿ç½‘å¡ä¿®æ”¹æ¯”è¾ƒéº»çƒ¦ï¼Œå‚è€ƒè¿™ä¸ªåšå®¢ã€‚ é‡æ–°å®‰è£…TeamVieweråï¼Œå‘ç°IDå·è¾¹äº†ï¼Œä¹‹åå°†ç½‘å¡åœ°å€å‹¾é€‰ä¸ºä¸å­˜åœ¨ï¼Œå› ä¸ºæ¯ä¸ªäººçš„ç½‘å¡åœ°å€æ˜¯å…¨çƒå”¯ä¸€çš„ï¼Œç½‘å¡åœ°å€æ”¹ä¸ºä¸å­˜åœ¨åï¼ŒIDæ­£å¸¸ä½¿ç”¨ã€‚]]></content>
      <categories>
        <category>å…¶ä»–</category>
      </categories>
      <tags>
        <tag>TeamViewer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cs231n lecture13 Generative Models]]></title>
    <url>%2F2019%2F01%2F21%2Fcs231n-lecture13-Generative-Models.html%2F</url>
    <content type="text"><![CDATA[PixelRNN/CNN Variational Autoencoders Generative Adversarial Networks ç”Ÿæˆæ¨¡å‹ç”Ÿæˆæ¨¡å‹åˆ†ä¸ºæ˜¾å¼å’Œéšå¼ æ˜¾å¼å¯†åº¦ä¼°è®¡ï¼šæ˜¾å¼åœ°å®šä¹‰å’Œæ±‚è§£åˆ†å¸ƒï¼ŒPixelRNN/CNNï¼ŒVariational Autoencoder(å·®åˆ†ç¼–ç å™¨VAE) éšå¼å¯†åº¦ä¼°è®¡ï¼šå­¦ä¹ ä»æ¨¡å‹ä¸­ç›´æ¥é‡‡æ ·ï¼Œæ¯”å¦‚GAN PixelRNN and PixelCNNGenerate image pixels starting from corner. Dependency on previous pixels modeled using an RNN (LSTM) Dependency on previous pixels now modeled using a CNN over context region Drawback: sequential generation is slow! Variational Autoencoders (VAE)è‡ªåŠ¨ç¼–ç å™¨ï¼Œæ˜¯encoder+decoderï¼Œè¾“å…¥å›¾ç‰‡ï¼Œå­¦ä¹ éšå˜é‡zã€‚ å·®åˆ†ç¼–ç å™¨VAEï¼Œå­¦ä¹ ä»éšå˜é‡zç”Ÿæˆå›¾ç‰‡ã€‚ ç”Ÿæˆå›¾ç‰‡æ—¶ï¼Œéšæœºå–zï¼Œè¾“å…¥decoderï¼Œç”Ÿæˆå›¾ç‰‡ Generative Adversarial Networks GANçœç•¥ ç”Ÿæˆå™¨çš„æŸå¤±å‡½æ•°å¦‚æœç›´æ¥å–é‰´åˆ«å™¨çš„å³è¾¹ï¼Œä¼šæœ‰é—®é¢˜ï¼Œå¦‚å›¾ï¼Œçœ‹è“è‰²æ›²çº¿ï¼Œå½“é‰´åˆ«å™¨èƒ½å¾ˆå¥½çš„é‰´åˆ«å‡ºå‡æ ·æœ¬ï¼Œæ¢¯åº¦å¹³æ»‘ä¸å¥½æ›´æ–°ï¼Œæ²¡åŠæ³•æ›´æ–°ç”Ÿæˆå™¨ã€‚æ‰€ä»¥æŸå¤±å‡½æ•°è¦åè¿‡æ¥ï¼Œå˜æˆç»¿è‰²æ›²çº¿ï¼Œæ¢¯åº¦å°±å¥½æ±‚äº†ã€‚]]></content>
      <categories>
        <category>cs231n</category>
      </categories>
      <tags>
        <tag>cs231n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cs231n lecture12 Visualizing and Understanding]]></title>
    <url>%2F2019%2F01%2F15%2Fcs231n-lecture12-Visualizing-and-Understanding.html%2F</url>
    <content type="text"><![CDATA[Feature visualization and inversionAdversarial examplesDeepDream and style transfer ç‰¹å¾å¯è§†åŒ–ç¬¬ä¸€å±‚å¯¹ç¥ç»ç½‘ç»œç¬¬ä¸€å±‚å¯è§†åŒ–ï¼Œæ¯”å¦‚ç¬¬ä¸€å±‚çš„çš„è¾“å…¥æ˜¯3Ã—256Ã—256çš„å›¾ç‰‡ï¼Œç»è¿‡11Ã—11çš„64ä¸ªå·ç§¯æ ¸ã€‚é‚£ä¹ˆæ¯ä¸ª3Ã—11Ã—11çœ‹åšä¸€ä¸ªå½©è‰²å›¾ç‰‡ï¼Œå…±64ä¸ªï¼Œåšå¯è§†åŒ–ï¼Œçœ‹ç¥ç»ç½‘ç»œæ˜¯å¦è®­ç»ƒçš„å¥½ï¼Œå­¦åˆ°äº†è¾¹è§’ç­‰ç‰¹å¾ã€‚ æœ€åä¸€å±‚Nearest Neighborsåˆ†ç±»ç¥ç»ç½‘ç»œï¼Œæœ€åä¸€å±‚æ˜¯å…¨è¿æ¥å±‚ï¼Œ4096åˆ°1000ç±»çš„æ˜ å°„ã€‚å–4096è¿™å±‚åšç‰¹å¾ï¼Œç„¶åæ±‚åŸºäºåƒç´ å€¼çš„L2å›¾åƒç´§é‚»ï¼Œä¸€ä¸ªå¤´æœå·¦çš„å¤§è±¡å’Œä¸€ä¸ªå¤´æœå³çš„å¤§è±¡ï¼Œç«Ÿç„¶æœ€ç›¸ä¼¼ï¼Œå¯è§å­¦åˆ°äº†è¯­ä¹‰ç‰¹å¾ã€‚ Dimensionality Reductionç”¨t-SNEé™ç»´ï¼ŒæŠŠ4096é™ç»´åˆ°ä¸¤ç»´ï¼Œå¯¹åº”ä¸ºäºŒç»´åæ ‡è½´ä¸Šçš„xå’Œyåæ ‡ï¼Œå¯¹åº”çš„å›¾ç‰‡æ”¾åœ¨å¯¹åº”çš„ä½ç½®ï¼Œç»„æˆä¸€ä¸ªå¯†å¯†éº»éº»çš„å¤§å›¾ ä¸­é—´å±‚Visualizing Activationsconv5 feature mapæ˜¯ä¸€ä¸ª128Ã—13Ã—13çš„ï¼Œå¯è§†åŒ–128ä¸ª13Ã—13çš„ç°åº¦å›¾ç‰‡ï¼Œå¯ä»¥çœ‹åˆ°æŸå¼ å›¾ç‰‡æ­£å¯¹åº”äººè„¸çš„æ¿€æ´»ä½ç½® Maximally Activating Patchesæ‰¾åˆ°ä¸­é—´æŸå±‚çš„ä¸€ä¸ªé€šé“ï¼Œæ¯”å¦‚conv5æ˜¯128Ã—13Ã—13ï¼Œå–å‡º128ä¸ªä¸­çš„ç¬¬17ä¸ªé€šé“ï¼Œç½‘ç»œä¸­è¾“å…¥å›¾ç‰‡ï¼Œè®°å½•é€šé“å€¼ï¼Œæ‰¾åˆ°æœ€å¤§æ¿€æ´»å¯¹åº”çš„å›¾åƒä¸Šçš„ä½ç½®ã€‚ Occlusion Experimentsé®æŒ¡ä¸€éƒ¨åˆ†å›¾ç‰‡ï¼Œç„¶åæ»‘åŠ¨è¿™ä¸ªé®æŒ¡ï¼Œè¾“å…¥é®æŒ¡åçš„å›¾ç‰‡è¿›ç½‘ç»œï¼Œè¾“å‡ºçš„é¢„æµ‹æ¦‚ç‡å€¼åšä¸€ä¸ªçƒ­åŠ›å›¾ï¼Œå˜åŒ–è·ç¦»çš„åœ°æ–¹å°±æ˜¯åˆ†ç±»èµ·ä½œç”¨çš„åœ°æ–¹ã€‚ Saliency Maps æ˜¾è‘—å›¾ï¼Œæ ¹æ®åˆ†ç±»å¾—åˆ†ï¼Œåå‘æ±‚å›¾åƒåƒç´ ç›¸å…³çš„æ¢¯åº¦å€¼ï¼Œå¯¹åº”çš„æ˜¯3Ã—256Ã—256ï¼Œä¿ç•™ä¸‰ä¸ªé€šé“ä¸­çš„æœ€å¤§å€¼ï¼Œå¾—åˆ°ä¸€ä¸ªç°åº¦å›¾ã€‚è¿™ä¸ªå¯ä»¥ç”¨æ¥åšè¯­ä¹‰åˆ†å‰²ï¼Œä½†æ˜¯æ•ˆæœä¸æ˜¯é‚£ä¹ˆå¥½ã€‚ Intermediate features via (guided) backpropæ‰¾åˆ°ä¸­é—´æŸå±‚çš„ä¸€ä¸ªç¥ç»å…ƒï¼Œè®¡ç®—å…³äºè¿™ä¸ªç¥ç»å…ƒå¯¹åº”å›¾åƒæ„Ÿå—é‡ä½ç½®çš„æ¢¯åº¦ã€‚ä½†æ˜¯æ¢¯åº¦è¦ç»è¿‡Reluæ¿€æ´»ï¼Œä¹Ÿå°±æ˜¯åªå–æ­£æ¢¯åº¦ã€‚ Visualizing CNN features: Gradient Ascentåˆå§‹åŒ–å›¾åƒä¸º0ï¼Œæ­£å‘è¾“å…¥å›¾ç‰‡å¾—åˆ°ç›®å‰çš„å¾—åˆ†ï¼Œåå‘æ±‚å›¾åƒåƒç´ å¯¹åº”çš„æ¢¯åº¦ï¼Œç„¶åé€æ¸æ›´æ–°å›¾ç‰‡ã€‚$I^2$æ˜¯å¯¹åº”çš„å›¾åƒåƒç´ çš„L2æ­£åˆ™åŒ–ã€‚ Better regularizer: Penalize L2 norm of image; also during optimization periodically(1) Gaussian blur image(2) Clip pixels with small values to 0(3) Clip pixels with small gradients to 0 å¯¹æŠ—æ ·æœ¬éšæ„å®£ä¸€ä¸ªå›¾ç‰‡ï¼Œéšæ„é€‰ä¸€ä¸ªç±»åˆ«ï¼Œé€šè¿‡ä¿®æ”¹å›¾ç‰‡ï¼Œä½¿è¿™ä¸ªå›¾ç‰‡æœ€ç»ˆè¢«é”™è¯¯åˆ†ç±»ä¸ºè¿™ä¸ªéšæ„é€‰çš„ç±»åˆ«ã€‚ æ·±æ¢¦å’Œé£æ ¼è½¬æ¢googleå†™çš„ä¸€ä¸ªåšå®¢ï¼Œæ­£å‘ä¼ æ’­ï¼Œè®¡ç®—è¢«é€‰å±‚çš„æ¢¯åº¦å½“åšæ¿€æ´»ï¼Œåå‘è®¡ç®—å›¾ç‰‡ç›¸å…³çš„æ¢¯åº¦ï¼Œæ›´æ–°å›¾ç‰‡ã€‚åœ¨åˆ†ç±»ç½‘ç»œä¸Šåšçš„ï¼Œåº”ä¸º1000ç±»å…¶ä¸­æœ‰200ç±»ç‹—ï¼Œæ‰€ä»¥ä¼šæœ‰å¾ˆå¤šç‹—å¤´ï¼Œè™«å­ç­‰ä¹±ä¸ƒå…«ç³Ÿçš„ç¥å¥‡å›¾åƒã€‚ çº¹ç†ç”Ÿæˆï¼Œæå‡ºGramçŸ©é˜µ Gatys, Ecker, and Bethge, â€œTexture Synthesis Using Convolutional Neural Networksâ€, NIPS 2015 GramçŸ©é˜µç”¨äºé£æ ¼è½¬æ¢ï¼Œå•ä¸€å†…å®¹å•ä¸€é£æ ¼ Gatys, Ecker, and Bethge, â€œImage style transfer using convolutional neural networksâ€, CVPR 2016 å¤šå†…å®¹å•ä¸€é£æ ¼è½¬æ¢ã€‚ Johnson, Alahi, and Fei-Fei, â€œPerceptual Losses for Real-Time Style Transfer and Super-Resolutionâ€, ECCV 2016. Replacing batch normalization with Instance Normalization improves results Ulyanov et al, â€œTexture Networks: Feed-forward Synthesis of Textures and Stylized Imagesâ€, ICML 2016 Ulyanov et al, â€œInstance Normalization: The Missing Ingredient for Fast Stylizationâ€, arXiv 2016 å¤šå†…å®¹å¤šé£æ ¼è½¬æ¢ Dumoulin, Shlens, and Kudlur, â€œA Learned Representation for Artistic Styleâ€, ICLR 2017 æ€»ç»“Many methods for understanding CNN representationsActivations: Nearest neighbors, Dimensionality reduction,maximal patches, occlusionGradients: Saliency maps, class visualization, fooling, images, feature inversionFun: DeepDream, Style Transfer.]]></content>
      <categories>
        <category>cs231n</category>
      </categories>
      <tags>
        <tag>cs231n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å¦‚ä½•è®¡ç®—å·ç§¯å±‚çš„å‚æ•°ä¸ªæ•°]]></title>
    <url>%2F2019%2F01%2F12%2F%E5%A6%82%E4%BD%95%E8%AE%A1%E7%AE%97%E5%8D%B7%E7%A7%AF%E5%B1%82%E7%9A%84%E5%8F%82%E6%95%B0%E4%B8%AA%E6%95%B0.html%2F</url>
    <content type="text"><![CDATA[å¦‚ä½•è®¡ç®—å·ç§¯å±‚çš„å‚æ•°ä¸ªæ•° ä¸è€ƒè™‘batchsizeï¼Œè¾“å…¥64Ã—64Ã—16ï¼Œç»è¿‡conv3Ã—3ï¼Œè¾“å‡º64Ã—64Ã—32ï¼Œä¹Ÿå°±æ˜¯Hå’ŒWæ˜¯64ï¼Œé€šé“æ•°æˆ–è€…è¯´feature mapæ•°ä»16åˆ°32. å·ç§¯æ ¸ä¸ªæ•°ã€‚ä¸ºè¾“å‡ºçš„feature mapæ•°ï¼Œä¹Ÿå°±æ˜¯32 å·ç§¯æ ¸çš„å¤§å°ã€‚16ä¸ªé€šé“ä¸Šæ¯ä¸ªé€šé“å¯¹åº”ä¸€ä¸ª3Ã—3çš„å·ç§¯æ ¸ï¼Œä¸”è¿™16ä¸ªå·ç§¯æ ¸ä¸Šçš„å‚æ•°æ—¶ä¸ä¸€æ ·çš„ï¼Œä½†æ˜¯è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå·ç§¯æ ¸ï¼Œå› ä¸ºè®¤ä¸ºå·ç§¯æ ¸çš„å¤§å°ä¸º 3Ã—3Ã—16 å‚æ•°çš„ä¸ªæ•°ã€‚å·ç§¯æ ¸çš„ä¸ªæ•°+åç½®ã€‚ 3Ã—3Ã—16Ã—32 + 32. åœ¨è¾“å‡ºçš„æŸä¸ªé€šé“ä¸Šçš„å€¼ï¼Œæ˜¯è¾“å…¥çš„16ä¸ªé€šé“å¤„çš„å·ç§¯ç»“æœç›¸åŠ ï¼Œå†åŠ ä¸Šä¸€ä¸ªåç½®ï¼Œç„¶åå†å–æ¿€æ´»å‡½æ•°å€¼å¾—åˆ°çš„ã€‚ æ€»ç»“ å·ç§¯æ ¸çš„ä¸ªæ•°=æœ€ç»ˆçš„featuremapçš„ä¸ªæ•° å·ç§¯æ ¸çš„å¤§å°=å¼€å§‹è¿›è¡Œå·ç§¯çš„é€šé“æ•°Ã—æ¯ä¸ªé€šé“ä¸Šè¿›è¡Œå·ç§¯çš„äºŒç»´å·ç§¯æ ¸çš„å°ºå¯¸ å‚æ•°çš„ä¸ªæ•°=å·ç§¯æ ¸ä¸ªæ•°Ã—ï¼ˆå·ç§¯æ ¸å¤§å°+1ï¼‰ è¯¦ç»†çš„è§£é‡Šå’Œå›¾å‚è€ƒåˆ«äººçš„åšå®¢]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fully Convolutional Network (FCN) and Global Average Pooling (GAP)]]></title>
    <url>%2F2019%2F01%2F12%2FFully-Convolutional-Network-FCN-and-Global-Average-Pooling-GAP.html%2F</url>
    <content type="text"><![CDATA[ä½¿ç”¨å·ç§¯å±‚æ›¿ä»£CNNæœ«å°¾çš„å…¨è¿æ¥å±‚ å…¨å·ç§¯ç¥ç»ç½‘ç»œFully Convolutional Network (FCN) åˆ«äººçš„åšå®¢ä»‹ç» å…¨å±€å¹³å‡æ± åŒ–Global Average Pooling éå¸¸å¥½çš„ä¸€ç¯‡åšå®¢ï¼Œè¿˜æœ‰å®éªŒå¯¹æ¯”ã€‚ è¯æ˜å…¨å±€æœ€å¤§æ± åŒ–æ•ˆæœéå¸¸å·®ï¼Œå…¨å±€å¹³å‡æ± åŒ–æ¯”å…¨è¿æ¥æ•ˆæœè¦å¥½ï¼Œä¸å®¹æ˜“è¿‡æ‹Ÿåˆ]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[inception network]]></title>
    <url>%2F2019%2F01%2F12%2Finception-network.html%2F</url>
    <content type="text"><![CDATA[Inception V1-V4 ä»‹ç»4ä¸ªç‰ˆæœ¬çš„inceptionæ¨¡å‹ ä»Inception v1åˆ°Inception-ResNetï¼Œä¸€æ–‡æ¦‚è§ˆInceptionå®¶æ—çš„ã€Œå¥‹æ–—å²ã€ inception v4çš„tensorflow api slimä»£ç å®ç° InceptionV4 ä»‹ç»inceptionæ¨¡å‹ä»¥åŠä¹‹åçš„æ”¹å˜ ä»Inception v1,v2,v3,v4,RexNeXtåˆ°Xceptionå†åˆ°MobileNets,ShuffleNet,MobileNetV2,ShuffleNetV2]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Show, Attend and Tell: Neural Image Caption Generation with Visual Attention]]></title>
    <url>%2F2019%2F01%2F09%2FShow-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention.html%2F</url>
    <content type="text"><![CDATA[æœ¬æ–‡æ˜¯2015å¹´çš„ä¸€ç¯‡æ ¹æ®å›¾ç‰‡ç”Ÿæˆæ–‡å­—æè¿°çš„æ–‡ç« ã€‚ ä¸»è¦æ˜¯å› ä¸ºæ–‡ç« é‡Œç”¨äº†soft attentionå’Œhard attention è¯¦ç»†å†…å®¹å¯ä»¥å‚è€ƒåšå®¢!!(éœ€è¦ç¿»å¢™ï¼) å›¾ç‰‡å…ˆç»è¿‡ä¸€ä¸ªVGGç½‘ç»œï¼Œå­¦ä¹ åˆ°ä¸€ä¸ªå¯¹å›¾ç‰‡çš„ç‰¹å¾å›¾å‘é‡è¡¨ç¤ºã€‚ç„¶åè¾“å…¥åˆ°åé¢çš„LSTMä¸­å­¦ä¹ å¾—åˆ°å¯¹åº”çš„æ–‡å­—ã€‚ è¿™ä¸ªç‰¹å¾å›¾è¦å‡åŒ€çš„åˆ’åˆ†Lä¸ªåŒºåŸŸï¼Œæ¯ä¸ªåŒºåŸŸæœ‰å¤§å°ä¸º14Ã—14ï¼ŒD=196 $a={a_1,â€¦,a_L}, a_iâˆˆR^D$ é¢„æµ‹è¾“å‡ºçš„ä¸€å¥è¯è¡¨ç¤ºä¸ºï¼ŒCæ˜¯å¥å­é•¿åº¦ï¼ŒKæ˜¯å­—å…¸å¤§å°(å•è¯ä¸ªæ•°) $y={y_1,â€¦,y_C},y_iâˆˆR^K$ æ–‡å­—ç»“æœè·Ÿå›¾ç‰‡æœ‰å…³ç³»ï¼ŒLSTMä¸ä¼ ç»Ÿçš„ç›¸æ¯”ï¼Œåœ¨æ¯ä¸ªä½ç½®é™¤äº†è¾“å…¥$x_t$,$h_{t-1}$ï¼Œè¿˜éœ€è¦è¾“å…¥å¯¹åº”çš„å›¾åƒè¡¨è¾¾ä¿¡æ¯$z_t$ï¼Œä½†æ˜¯è¿™ä¸ªå•è¯ä¸å¯èƒ½è·Ÿå…¨å±€çš„å›¾åƒä¿¡æ¯æœ‰å…³ï¼Œæ‰€ä»¥è¦åŠ ä¸Šattentionæœºåˆ¶ã€‚ä¹Ÿå°±æ˜¯ä¼ ç»Ÿçš„LSTM4ä¸ªé—¨çš„è®¡ç®—åªè·Ÿè¾“å…¥æ–‡å­—xï¼Œä¸Šä¸€çŠ¶æ€hæœ‰å…³ç³»ï¼Œåœ¨image captionä»»åŠ¡ä¸­è¿˜è¦åŠ å…¥zã€‚ zæ˜¯æ€ä¹ˆæ±‚çš„å‘¢ã€‚ $z_t=âˆ‘\alpha_ia_i$ hard attention: åªæœ‰ä¸€ä¸ªalphaä¸º1ï¼Œå…¶ä»–çš„å…¨ä¸º0ï¼Œæ³¨æ„åŠ›ä¸€ä¸ªæ—¶åˆ»åªå…³æ³¨ä¸€ä¸ªåŒºåŸŸã€‚ä¸å¯å¾®ï¼Œè¿‘ä¼¼ä¸€ä¸ªä¸‹ç•Œï¼Œç•¥ soft attention:æ¯ä¸ªåŒºåŸŸéƒ½æœ‰ä¸€å®šçš„æƒé‡ï¼Œå’Œä¸º1ã€‚è¿ç»­å¯å¾®çš„ã€‚ ç”¨å¤šå±‚æ„ŸçŸ¥å™¨è¾“å…¥aå’Œhæ¥æ±‚alphaï¼Œå…·ä½“æ²¡çœ‹ï¼Œç•¥]]></content>
      <categories>
        <category>ç™¾ç¯‡è®ºæ–‡é˜…è¯»è®¡åˆ’</category>
      </categories>
      <tags>
        <tag>image caption</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spectral Normalization for Generative Adversarial Networks]]></title>
    <url>%2F2019%2F01%2F09%2FSpectral-Normalization-for-Generative-Adversarial-Networks.html%2F</url>
    <content type="text"><![CDATA[è°±å½’ä¸€åŒ– GANè®­ç»ƒä¸ç¨³å®šï¼Œé€šè¿‡åœ¨å¯¹æŠ—å™¨åŠ å…¥è°±å½’ä¸€åŒ–ï¼Œåœ¨æ¯å±‚å¯¹æƒé‡è¿›è¡Œå½’ä¸€åŒ–æ“ä½œï¼Œç¨³å®šè®­ç»ƒï¼ŒåŒæ—¶è¿˜èµ·åˆ°äº†æƒé‡æ­£åˆ™åŒ–çš„ä½œç”¨ã€‚æœ€ç»ˆå¾—åˆ°äº†æ›´å¥½çš„å›¾åƒæ•ˆæœï¼Œä¸€ä¸ªæ¨¡å‹åœ¨å¤šç±»åˆ«å›¾åƒä¸Šéƒ½è¡¨ç°çš„å¾ˆå¥½ã€‚ è¿›è¿‡æ¨è®ºè¯æ˜ï¼Œåœ¨æ¯å±‚å¯¹æƒé‡å½’ä¸€åŒ–ï¼Œå°±ç›¸å½“äºè®©æƒé‡é™¤ä»¥ä»–çš„å¯¹åº”çŸ©é˜µèŒƒæ•°ï¼Œæ±‚çŸ©é˜µèŒƒæ•°éœ€è¦è®¡ç®—è¿™ä¸ªçŸ©é˜µçš„ç‰¹å¾å€¼ï¼Œå¯ä»¥é€šè¿‡å¹‚è¿­ä»£æ³•æ¥è¿‘ä¼¼æ±‚å–ã€‚ å‚è€ƒåšå®¢ 1234567891011121314151617181920212223242526272829def _l2normalize(v, eps=1e-12): return v / (tf.reduce_sum(v ** 2) ** 0.5 + eps)def spectral_norm(w, u=None, iteration=1, update_collection=None): w_shape = w.get_shape().as_list() w_reshaped = tf.reshape(w, [-1, w_shape[-1]]) if u is None: u = tf.get_variable("u", shape=[1, w_shape[-1]], initializer=tf.truncated_normal_initializer(), trainable=False) u_ = u v_ = None for i in range(iteration): """ power iteration Usually iteration = 1 will be enough """ v_ = _l2normalize(tf.matmul(u_, tf.transpose(w_reshaped))) u_ = _l2normalize(tf.matmul(v_, w_reshaped)) u_ = tf.stop_gradient(u_) v_ = tf.stop_gradient(v_) sigma = tf.matmul(tf.matmul(v_, w_reshaped), tf.transpose(u_)) """ assignç»™uèµ‹å€¼u_hat tf.control_dependenciesï¼Œæ§åˆ¶ä¾èµ–çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œuèµ‹å€¼ä¹‹åï¼Œæ‰èƒ½æ‰§è¡Œwithä¸­çš„è¯­å¥ï¼Œä¸”å¿…é¡»å†™åœ¨withä¸‹ï¼Œç›´æ¥åœ¨å¤–é¢å®šä¹‰çš„å˜é‡ç›´æ¥è¿”å›ä¸è¡Œ """ with tf.control_dependencies([u.assign(u_)]): sigma = tf.identity(sigma) return w / sigma]]></content>
      <categories>
        <category>ç™¾ç¯‡è®ºæ–‡é˜…è¯»è®¡åˆ’</category>
      </categories>
      <tags>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Self-Attention Generative Adversarial Networks]]></title>
    <url>%2F2019%2F01%2F08%2FSelf-Attention-Generative-Adversarial-Networks.html%2F</url>
    <content type="text"><![CDATA[è‡ªæ³¨æ„åŠ›ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œé¦–æ¬¡æŠŠè‡ªæ³¨æ„åŠ›å¼•å…¥ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå›¾åƒç”Ÿæˆä¸­ï¼Œç»“åˆä½¿ç”¨è°±å½’ä¸€åŒ–ï¼Œå¾—åˆ°äº†æ›´å¥½çš„å›¾åƒè´¨é‡ã€‚ Self-Attention Generative Adversarial Network(SAGAN)æ˜¯ä¸€ä¸ªæ³¨æ„åŠ›é©±åŠ¨ï¼Œé•¿èŒƒå›´ï¼Œå…³è”æ¨¡å‹(attention-driven, long-range dependency modeling )ã€‚ è§£å†³çš„é—®é¢˜åˆ©ç”¨GANè¿›è¡Œå›¾åƒåˆæˆï¼Œå¯¹äºå«æœ‰è¾ƒå°‘ç»“æ„çº¦æŸçš„ç±»åˆ«ï¼ˆæ¯”å¦‚æµ·æ´‹ã€å¤©ç©ºå’Œåœ°é¢ç­‰é‡çº¹ç†ä¸é‡ç»“æ„çš„ï¼‰æ¯”è¾ƒæˆåŠŸï¼Œè€Œå¯¹äºå«æœ‰å‡ ä½•æˆ–ç»“æ„æ¨¡å¼çš„åˆ™å®¹æ˜“å¤±è´¥ï¼Œæ¯”å¦‚åˆæˆçš„ç‹—çš„å›¾åƒå…·æœ‰çœŸå®çš„æ¯›ä½†æ˜¯å¾ˆéš¾è®¤å‡ºè„šã€‚å¯èƒ½çš„åŸå› ï¼šCNNçš„å·ç§¯å±‚å…·æœ‰æ„Ÿå—é‡ï¼Œå› æ­¤åˆ©ç”¨CNNå»ºæ¨¡å¿…é¡»å…·æœ‰è¶³å¤Ÿçš„æ·±åº¦æ‰èƒ½åœ¨è¾ƒå¤§ç©ºé—´èŒƒå›´å†…å»ºç«‹å›¾åƒä¸åŒåŒºåŸŸçš„ç›¸å…³æ€§ï¼Œä½†è¿™ä¼šå¯¼è‡´æ›´å¤§çš„è®¡ç®—ä»£ä»·ã€‚ å› æ­¤æœ¬æ–‡æå‡ºSelf-attention GANä»¥å¹³è¡¡long range dependency modelingå’Œè®¡ç®—ä»£ä»·çš„é—®é¢˜ã€‚ ä¼ ç»Ÿgançš„é—®é¢˜: ä½¿ç”¨å°çš„å·ç§¯æ ¸å¾ˆéš¾å‘ç°å›¾åƒä¸­çš„ä¾èµ–å…³ç³» ä½¿ç”¨å¤§çš„å·ç§¯æ ¸å°±ä¸§å¤±äº†å·ç§¯ç½‘ç»œå‚æ•°ä¸è®¡ç®—çš„æ•ˆç‡ ä¼ ç»Ÿçš„GANåœ¨ç”Ÿæˆé«˜åˆ†è¾¨ç‡çš„ç»†èŠ‚æ—¶ï¼Œæ˜¯åŸºäºä½åˆ†è¾¨ç‡çš„feature mapä¸­çš„æŸä¸€ä¸ªå°éƒ¨åˆ†çš„(å·ç§¯ç½‘ç»œçš„ç‰¹æ€§)ã€‚è€ŒSAGANæ˜¯åŸºäºæ‰€æœ‰çš„ç‰¹å¾ç‚¹(all feature locations). è®©æ¯ä¸ªåƒç´ ç‚¹è·Ÿå…¨å±€çš„æ‰€æœ‰åƒç´ ç‚¹éƒ½æœ‰å…³ç³»ã€‚ æ³¨æ„åŠ›æ¨¡å‹ 123456789101112131415161718192021def hw_flatten(x) : return tf.reshape(x, shape=[x.shape[0], -1, x.shape[-1]])def attention(self, x, ch, sn=False, scope='attention', reuse=False): with tf.variable_scope(scope, reuse=reuse): f = conv(x, ch // 8, kernel=1, stride=1, sn=sn, scope='f_conv') # [bs, h, w, c'] g = conv(x, ch // 8, kernel=1, stride=1, sn=sn, scope='g_conv') # [bs, h, w, c'] h = conv(x, ch, kernel=1, stride=1, sn=sn, scope='h_conv') # [bs, h, w, c] # N = h * w s = tf.matmul(hw_flatten(g), hw_flatten(f), transpose_b=True) # # [bs, N, N] beta = tf.nn.softmax(s, axis=-1) # attention map o = tf.matmul(beta, hw_flatten(h)) # [bs, N, C] gamma = tf.get_variable("gamma", [1], initializer=tf.constant_initializer(0.0)) o = tf.reshape(o, shape=x.shape) # [bs, h, w, C] x = gamma * o + x return x æ–‡ç« åœ¨ç”Ÿæˆå™¨å’Œé‰´åˆ«å™¨ä¸­éƒ½ä½¿ç”¨äº†è¿™ä¸ªattention moduleï¼ŒåŒæ—¶è®¨è®ºå¾—å‡ºç»“è®ºï¼Œåœ¨ä¸€äº›ä¸­å±‚æ¬¡æˆ–è€…é«˜å±‚æ¬¡ç‰¹å¾ä¸­ä½¿ç”¨attentionå±‚èƒ½å¤Ÿå¾—åˆ°æ›´å¥½çš„æ•ˆæœã€‚ æ–‡ç« ä½¿ç”¨äº†è°±å½’ä¸€åŒ–å’Œhinge lossæ¥æå‡æ•ˆæœæ€§èƒ½ æ•ˆæœä¸ACGANå’ŒSNGANåšæ¯”è¾ƒ]]></content>
      <categories>
        <category>ç™¾ç¯‡è®ºæ–‡é˜…è¯»è®¡åˆ’</category>
      </categories>
      <tags>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cs231n lecture11 Detection and Segmentation]]></title>
    <url>%2F2019%2F01%2F07%2Fcs231n-lecture11-Detection-and-Segmentation.html%2F</url>
    <content type="text"><![CDATA[è¯­ä¹‰åˆ†å‰² (é‡ç‚¹æœ‰ï¼šTranspose convolutionåå·ç§¯) åˆ†ç±»+å®šä½ ç›®æ ‡æ£€æµ‹ (RNN, Faster RNN, YOLO) ç‰©ä½“åˆ†å‰² 1.è¯­ä¹‰åˆ†å‰²ç»™å›¾ç‰‡çš„æ¯ä¸ªåƒç´ éƒ½åˆ†ç±»ï¼Œä¸ç‰©ä½“åˆ†å‰²ä¸åŒï¼Œåªå…³å¿ƒåƒç´ ï¼Œè€Œä¸”å¦‚æœæœ‰ä¸¤ä¸ªç‰›åœ¨å›¾ç‰‡é‡Œï¼Œä¹Ÿä¸åŒºåˆ†åˆ’åˆ†åœ¨ä¸€èµ·ã€‚ (1) åœ¨å›¾ç‰‡ä¸­æ»‘åŠ¨é€‰æ‹©æ— æ•°ä¸ªå°åŒºåŸŸï¼Œæ¯ä¸ªå°åŒºåŸŸè¿›è¡Œåˆ†ç±»ï¼Œè¡¨ç¤ºä¸­å¿ƒåƒç´ ç‚¹æ‰€å±çš„åˆ†ç±»ï¼Œé—®é¢˜æ˜¯æ•ˆç‡å¤ªä½ã€‚ (2) ç›´æ¥æŠŠå›¾ç‰‡è¾“å…¥è¿›å…¨å·ç§¯ç½‘ç»œï¼Œè¾“å‡ºä¸€ä¸ªscores : CÃ—HÃ—Wçš„ç»“æœï¼ŒCè¡¨ç¤ºä¸€å…±å‡ ç±»ï¼Œç„¶åargmaxå¾—å‡ºé¢„æµ‹ç»“æœHÃ—Wã€‚åœ¨åŸå§‹å›¾ç‰‡çš„å¤§å°å·ç§¯èŠ±è´¹å¤ªå¤šå†…å­˜å’Œæ—¶é—´ã€‚ (3) æ‰€ä»¥åœ¨å·ç§¯ä¸­é—´ï¼ŒåŠ å…¥ä¸‹é‡‡æ ·å’Œä¸Šé‡‡æ ·ã€‚ ä¸‹é‡‡æ ·æœ‰Pooling, strided convolution ä¸Šé‡‡æ ·æœ‰Unpooling or strided, transpose convolution ä¸Šé‡‡æ ·æœ‰â€Unpoolingâ€ : Unpooling or strided transpose convolution Input 2Ã—2 out put 4Ã—4 (1)Nearest Neighboræ˜¯æŒ‡æŠŠä¸€ä¸ªåƒç´ å¤åˆ¶4ä»½ï¼Œè¿›è¡Œä¸Šé‡‡æ · (2)Bed of Nailsæ˜¯æŒ‡é™¤äº†å·¦ä¸Šè§’åƒç´ ç›´æ¥å¤åˆ¶ï¼Œå…¶ä»–ä½ç½®çš„ä¸‰ä¸ªåƒç´ è¡¥0 (3)â€œMax Unpoolingâ€ åœ¨æ•´ä¸ªå·ç§¯ç½‘ç»œçš„å·¥ç¨‹ä¸­ï¼Œå‰é¢çš„ä¸‹é‡‡æ ·å’Œåé¢çš„ä¸Šé‡‡æ ·æ˜¯ä¸€ä¸€å¯¹åº”çš„ã€‚è®°ä½å‰é¢åšmax poolingçš„å¯¹åº”å…ƒç´ ä½ç½®ï¼Œåœ¨åšä¸Šé‡‡æ ·çš„æ—¶å€™ï¼ŒæŠŠå…ƒç´ æ”¾åœ¨å¯¹åº”çš„ä½ç½®ï¼Œå…¶ä»–çš„å…ƒç´ ä½ç½®è¡¥0 (4)é‡ç‚¹ï¼šTranspose Convolutionåå·ç§¯å‰é¢æåˆ°çš„éƒ½æ˜¯å›ºå®šè§„åˆ™çš„ä¸Šé‡‡æ ·ï¼Œä¸éœ€è¦è®­ç»ƒå‚æ•°ï¼Œè¿˜æœ‰å¯å­¦ä¹ çš„ä¸Šé‡‡æ ·:Transpose Convolution, åœ¨å…¶ä»–åœ°æ–¹ä¹Ÿç§°ä½œï¼šDeconvolution (bad), Upconvolution, Fractionally strided convolution, Backward strided convolutionã€‚éƒ½æ˜¯ä¸€ä¸ªæ„æ€ã€‚ä½†æ˜¯æ¨èå«Transpose Convolutionã€‚ 3Ã—3çš„å·ç§¯æ ¸ï¼Œæ­¥é•¿ä¸º2ï¼Œpadä¸º1. input 2Ã—2ï¼Œçœ‹åšæ˜¯å·ç§¯æ ¸çš„æƒé‡ï¼Œåƒç´ ä¹˜ä»¥å·ç§¯æ ¸ï¼Œç„¶åå€¼ä½œä¸ºä¸Šé‡‡æ ·çš„åƒç´ ã€‚å¦‚æœå’Œä¹‹å‰çš„ç»“æœæœ‰é‡å éƒ¨åˆ†ï¼Œé‚£ä¹ˆç›´æ¥ç›¸åŠ ã€‚ æœ‰äººæå‡ºï¼Œç”¨3Ã—3æ­¥é•¿ä¸º2çš„Transpose Convolutionå­˜åœ¨checkerboard artifactæ£‹ç›˜æ•ˆåº”çš„é—®é¢˜ã€‚æ‰€ä»¥æœ€æ–°çš„æ–‡ç« ï¼Œæœ‰äººä½¿ç”¨conv4Ã—4æ­¥é•¿ä¸º2ï¼Œæˆ–è€…conv2Ã—2æ­¥é•¿ä¸º2 2.åˆ†ç±»åŠ å®šä½åˆ†ç±»åŠ å®šä½å°±æ˜¯åˆ†ç±»+è¾¹æ¡†bounding boxes ä¸€ä¸ªå›¾ç‰‡ï¼Œè¾“å…¥å·ç§¯ç½‘ç»œä¸­ï¼Œ4096ä¸ªç¥ç»å…ƒç»è¿‡FCï¼Œè¾“å‡ºClass Scoresï¼Œæœ‰å‡ ç±»å°±è¾“å‡ºå‡ ä¸ªå¾—åˆ†ã€‚åŒæ—¶è¿˜è¦è¾“å‡ºBox coordinateæ¡†åæ ‡(x,y,w,h)ï¼Œåˆ†åˆ«æ˜¯æƒ³xå’Œyåæ ‡ï¼Œæ¡†çš„å®½å’Œé«˜ï¼Œè¿ç»­å€¼ï¼Œè¿™æ˜¯ä¸ªå›å½’é—®é¢˜ã€‚ å­˜åœ¨ä¸€ä¸ªé—®é¢˜ï¼Œå¦‚æœå›¾ç‰‡é‡Œæœ‰å¾ˆå¤šä¸ªç‰©ä½“ï¼Œè¦æ±‚å¾ˆå¤šä¸ªBox coordinate 3.ç›®æ ‡æ£€æµ‹å¤šç‰©ä½“çš„è¯å°±æ˜¯ç›®æ ‡æ£€æµ‹ã€‚è¦ç”¨åˆ°æ»‘åŠ¨çª—å£ï¼ å°†CNNç½‘ç»œåº”ç”¨åœ¨ä¸€ä¸ªå›¾ç‰‡çš„å„ç§ä¸åŒåˆ†å‰²ï¼Œç„¶åCNNç»™æ¯ä¸ªåˆ†å‰²åˆ†ç±»æ˜¯ç›®æ ‡æˆ–è€…èƒŒæ™¯ã€‚å­˜åœ¨é—®é¢˜ï¼Œè®¡ç®—èŠ±è´¹å¤ªé«˜ã€‚ ä½¿ç”¨Region proposalså€™é€‰åŒºåŸŸ/ Selective Search éå†æ‰€æœ‰åŒºåŸŸèŠ±è´¹å¤ªé«˜ï¼Œå…ˆç”¨ç®—æ³•æ‰¾åˆ°2000ä¸ªå€™é€‰åŒºåŸŸï¼Œç„¶åå¯¹å€™é€‰åŒºåŸŸåˆ†ç±»ã€‚ R-CNNå…ˆæ‰¾åˆ°2Kä¸ªå€™é€‰åŒºåŸŸ æ‰¾åˆ°çš„åŒºåŸŸå¤§å°ä¸ä¸€ï¼Œå…ˆä½¿ç”¨æŸç§æ–¹æ³•warpå›¾ç‰‡ï¼Œåˆ‡åˆ†ä¸ºä¸€æ ·å¤§å° ç„¶åæŠŠæ¯ä¸ªå¤„ç†è¿‡çš„åŒºåŸŸç»è¿‡convNet è¾“å‡ºLinear regression for bounding box offesets + classify regions with SVMs å­˜åœ¨é—®é¢˜ï¼Œè®­ç»ƒå¤ªæ…¢ Fast R-CNNæ•´ä¸ªå›¾ç‰‡è¾“å…¥convNetç½‘ç»œ åœ¨å­¦ä¹ åˆ°çš„ç‰¹å¾æ˜ å°„ä¸­æ‰¾åˆ°å€™é€‰åŒºåŸŸ ç„¶åç»è¿‡â€Rol Poolingâ€ layer å°†ä¸åŒçš„å¤§å°å¤„ç† å‰©ä¸‹çš„åŒR-CNN Faster R-CNNæ’å…¥RPNç½‘ç»œï¼Œä»ç‰¹å¾ä¸­å»é¢„æµ‹å€™é€‰åŒºåŸŸ Insert Region Proposal Network (RPN) to predict proposals from features YOLO/SSD Detection without ProposalsæŠŠå›¾ç‰‡åˆ’åˆ†æˆgrid cellç½‘æ ¼å•å…ƒã€‚è®¾ç½®ä¸€ç³»åˆ—çš„base boxesä»¥å„ä¸ªgird cellä¸ºä¸­å¿ƒï¼Œå‡è®¾ä¸ºB=3ï¼Œä¸€ä¸ªå®½çš„ï¼Œä¸€ä¸ªé•¿çš„ï¼Œä¸€ä¸ªæ­£æ–¹å½¢çš„ã€‚ å¯¹æ¯ä¸ªbase boxeså»æ‰¾åˆ°æœ€ç»ˆçš„ä¸€ä¸ªbase boxesï¼Œæ±‚5ä¸ªå€¼(x,y,h,w,confidence) è™½ç„¶å‡†ç¡®ç‡æ²¡æœ‰ä¹‹å‰çš„æ¨¡å‹é«˜ï¼Œä½†æ˜¯æœ€å¿« 4.ç‰©ä½“åˆ†å‰²Mask R-CNN(æ²¡ä»”ç»†è®²ï¼Œæ²¡æ˜ç™½) Predict a mask for each of C classes C Ã—14 Ã—14]]></content>
      <categories>
        <category>cs231n</category>
      </categories>
      <tags>
        <tag>cs231n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Super-FAN:Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with GANS]]></title>
    <url>%2F2019%2F01%2F03%2FSuper-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS.html%2F</url>
    <content type="text"><![CDATA[ä½¿ç”¨GANå°†ç°å®ä¸–ç•Œä¸­ä»»æ„å§¿æ€ä¸‹ä½åˆ†è¾¨ç‡äººè„¸çš„äººè„¸å…³é”®ç‚¹å®šä½å’Œè¶…åˆ†è¾¨ç‡ç»“åˆèµ·æ¥ã€‚ CVPR2018 spotlignt ä½œè€…ä¸»é¡µ 1.æ–‡ç« 5ç‚¹è´¡çŒ®1.æå‡ºSuper-FANï¼šä¸€ä¸ªåŒæ—¶æé«˜äººè„¸åˆ†è¾¨ç‡å¹¶è¿›è¡Œäººè„¸å¯¹é½çš„ç«¯åˆ°ç«¯ç³»ç»Ÿï¼Œä¸»è¦é€šè¿‡çƒ­å›¾å›å½’(Heatmap Regression)æ•´åˆå­ç½‘ç»œè¿›è¡Œäººè„¸å…³é”®ç‚¹å®šä½ï¼Œç„¶åè¿›å…¥åŸºäºGANçš„è¶…åˆ†è¾¨ç‡å¤„ç†ç½‘ç»œï¼Œå¹¶å°†å…¶å¹¶å…¥åˆ°ä¸€ä¸ªæ–°çš„çƒ­å›¾æŸå¤±ä¸­ã€‚2.å±•ç¤ºäº†è”åˆè®­ç»ƒä¸¤ä¸ªç½‘ç»œåœ¨å¤„ç†ä»»æ„äººè„¸å§¿åŠ¿çš„ç”Ÿæˆå›¾åƒï¼ˆä»¥å‰åªèƒ½æ­£é¢äººè„¸å›¾åƒï¼‰ä»¥åŠçœŸå®ä¸–ç•Œçš„ä½åˆ†è¾¨ç‡å›¾åƒä¸Šï¼ˆåˆæˆçš„ä½æ¸…å›¾ç‰‡ï¼‰çš„ä¼˜åŠ¿3.æå‡ºäº†ä¸€ä¸ªæ”¹è¿›çš„æ®‹å·®ç½‘ç»œç»“æ„æ¥å¾—åˆ°è¾ƒå¥½çš„è¶…åˆ†è¾¨ç‡å›¾åƒ4.é¦–æ¬¡æäº¤äº†å¤„ç†LS3D-Wæ•°æ®é›†å„ç§äººè„¸å§¿åŠ¿çš„ç»“æœï¼Œå¹¶åœ¨è¶…åˆ†è¾¨ç‡å’Œäººè„¸å¯¹é½æ–¹é¢åšå‡ºäº†é¢†å…ˆçš„ç»“æœã€‚ 5.é¦–æ¬¡åœ¨çœŸå®ä¸–ç•Œçš„ä½åˆ†è¾¨ç‡äººè„¸å›¾åƒ(WiderFaceæ•°æ®é›†)ä¸Šåšåˆ°äº†è‰¯å¥½çš„è§†è§‰æ•ˆæœ 2.æ•´ä½“æ¨¡å‹æ¶æ„ ç”Ÿæˆå™¨å¯¹åº”çš„æ˜¯-è¶…åˆ†è¾¨ç‡ç½‘ç»œ FANæ˜¯-äººè„¸å¯¹é½ç½‘ç»œ é‰´åˆ«å™¨å°±æ˜¯ä¼ ç»Ÿçš„é‰´åˆ«å™¨ 3.è¶…åˆ†è¾¨ç‡ç½‘ç»œ(Super-resolution network) åœ¨Photo-realistic single image super-resolution using a generative adversarialçš„åŸºç¡€ä¸Šï¼Œæ”¹è¿›äº†ç½‘ç»œæœºæ„ã€‚ å¦‚å›¾å³ä¾§æ˜¯SRGANï¼Œä»ä¸Šåˆ°ä¸‹ä¸ºç½‘ç»œé¡ºåºï¼Œè¾“å…¥ä¸º16Ã—16ï¼Œè¾“å‡ºä¸º64Ã—64. SRGANçš„æ®‹å·®å—ç”±conv-batchnorm-prelu-conv-batchnorm-preluç»„æˆã€‚å…ˆç»è¿‡16ä¸ªè¿™æ ·çš„æ®‹å·®å—ä½œç”¨åœ¨16Ã—16åˆ†è¾¨ç‡ä¸Šï¼Œå†ç»è¿‡1ä¸ªdeconv-pixel shuffle-preluä½œç”¨åœ¨32Ã—32ä¸Šï¼Œä¸€ä¸ªdeconv-pixel shuffle-preluä½œç”¨åœ¨64Ã—64ä¸Šã€‚è®°è¯¥ç»“æ„ä¸º16-1-1. æœ¬æ–‡çš„æ”¹è¿›ä¸ºï¼ŒæŠŠpreluæ”¹æˆreluï¼Œå› ä¸ºä»–å®éªŒè¯æ˜preluå¯¹ç»“æœæ²¡æœ‰æ˜æ˜¾çš„æå‡ä½œç”¨ã€‚å»é™¤äº†é•¿è¿æ¥ï¼Œå› ä¸ºå¯¹æ•´ä½“æ•ˆç›Šæ²¡æœ‰ä»€ä¹ˆç‰¹åˆ«å½±å“ã€‚åŒæ—¶æŠŠç½‘ç»œç»“æ„æ”¹ä¸º12-3-2ï¼Œå› ä¸ºä½œè€…å¸Œæœ›é€šè¿‡å¢åŠ æ®‹å·®å—æ¥å¤„ç†è¾ƒé«˜ç»´ç‰¹å¾ï¼Œä»è€Œå¢å¼ºé«˜åˆ†è¾¨ç‡å›¾åƒä¸Šçš„ç»†èŠ‚ï¼Œå°¤å…¶æ˜¯å¤„ç†åœºæ™¯å¤æ‚çš„å›¾åƒã€‚ 4.äººè„¸å¯¹é½ç½‘ç»œ(Face Alignment Network)å’ŒHeapmap lossä¸ºäº†è·å¾—æ›´å¥½çš„ç»†èŠ‚ï¼Œä½œè€…é€šè¿‡çƒ­å›¾å›å½’(heatmap regression)å°†äººè„¸å…³é”®ç‚¹å®šä½(facial landmark localization)é›†æˆåˆ°è¶…åˆ†è¾¨ç‡è¿‡ç¨‹å¹¶ä¸”ä¼˜åŒ–ä¸€ä¸ªé€‚å½“çš„çƒ­å›¾æŸå¤±ï¼Œä»è€Œå¢å¼ºè¶…åˆ†è¾¨ç‡å›¾åƒå’ŒåŸå§‹å›¾åƒçš„ç»“æ„ä¸€è‡´æ€§ã€‚ ä½¿ç”¨çš„æ˜¯FAN with 2 Hourglass modulesæ¨¡å‹ã€‚ FANæ˜¯ä½œè€…çš„ä¸Šä¸€ç¯‡æ–‡ç« ä¸­æå‡ºçš„ç»“æ„ï¼Œç”¨æ¥åš2Däººè„¸å¯¹é½ï¼Œè¾“å…¥ä¸€å¼ å›¾ç‰‡ï¼Œè¾“å‡ºä¸€ä¸ª63*2çš„å‘é‡ï¼Œè¡¨ç¤º(x,y)çš„åæ ‡ï¼Œå°±æ˜¯äººè„¸å…³é”®ç‚¹ã€‚ç”¨çš„æ˜¯ä¸¤å±‚hourglass modulesï¼Œä¸è¿‡åœ¨æ­¤åŸºç¡€ä¸ŠæŠŠbottleneck blockæ”¹æˆäº†å¤šå±‚æ¬¡å¹³è¡Œçš„å¤šè§„æ¨¡å—ã€‚å…·ä½“ä»‹ç»è§æ­¤åšå®¢ã€‚ åœ¨æœ¬æ–‡ä¸­ï¼ŒFANä¸å†å›å½’ä¸€ä¸ªxï¼Œyçš„åæ ‡ï¼Œè€Œæ˜¯ä½¿ç”¨çƒ­å›¾å›å½’çš„å†…å®¹å®šä½äººè„¸ã€‚ç”¨é¢„å…ˆè®­ç»ƒå¥½çš„ä¸¤ä¸ªFANç½‘ç»œï¼Œä¸€ä¸ªè¾“å…¥ç”Ÿæˆå™¨ç”Ÿæˆçš„é«˜æ¸…å›¾ç‰‡ï¼Œä¸€ä¸ªè¾“å…¥ground trueé«˜æ¸…å›¾ç‰‡ï¼Œå¾—åˆ°çš„ç»“æœåšå‡æ–¹è¯¯å·®(é€åƒç´ ç›¸å‡çš„å¹³æ–¹æ±‚å¹³å‡) $l_{heatmap}=\frac{1}{N}\sum_{n=1}^N\sum_{ij}(\widetilde M_{i,j}^n-\widehat M_{i,j}^n)$ å¦ä¸€ä¸ªå…³äºçƒ­å›¾æŸå¤±çš„å…³é”®ç‰¹å¾æ˜¯å®ƒçš„ä¼˜åŒ–ä¸éœ€è¦è®¿é—®æ ‡è®°å¥½çš„çœŸå®æ•°æ®ï¼Œè€Œåªéœ€è¦é¢„è®­ç»ƒå¥½çš„FANã€‚è¿™å°±å…è®¸ä»¥å¼±ç›‘ç£æ–¹å¼è®­ç»ƒæ•´ä¸ªè¶…åˆ†è¾¨ç‡ç½‘ç»œã€‚ 5.æ•´ä½“æŸå¤±å‡½æ•°$l^{SR}=\alpha l_{pixel}+\beta l_{feature} + \gamma l_{heatmap} + \zeta l_{WGAN}$ ç”Ÿæˆå™¨çš„æ•´ä½“æŸå¤±å‡½æ•° pixel lossæ˜¯ç”Ÿæˆçš„é«˜æ¸…å›¾å’Œground trueçš„å‡æ–¹è¯¯å·®MSE(å°±æ˜¯é€å…ƒç´ ç›¸å‡ï¼Œç„¶åå¹³æ–¹ï¼Œç„¶åæ±‚å‡å€¼) perceptual lossæ˜¯æé£é£é£æ ¼è½¬æ¢é‡Œçªå‡ºçš„æŸå¤±å‡½æ•°ï¼Œè¿™é‡Œç”¨çš„vgg_19çš„layer5_4 heatmapæŸå¤±ä¸Šé¢æåˆ°äº† wganæŸå¤±ï¼Œè¿™ç¯‡æ–‡ç« ç”¨çš„wgan-gp æ•´ä½“çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¤§è‡´æ˜¯å…ˆè®­ç»ƒäº†60epochçš„FAN GANæ¨¡å‹æ˜¯åŸºäºä¹‹å‰çš„è®­ç»ƒæ¨¡å‹ï¼Œå¾®è°ƒ5epoch ç„¶åæŠŠæ‰€æœ‰æ¨¡å‹åˆå¹¶åœ¨ä¸€èµ·ï¼Œè®­ç»ƒ5epoch æ•´åˆäº†å¤šä¸ªæ•°æ®é›†ï¼Œè‡ªå·±æ„é€ äº†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ŒåŒ…æ‹¬300W-LP, AFLW, Celeb-Aï¼ŒLS3D-W balanced.]]></content>
      <categories>
        <category>ç™¾ç¯‡è®ºæ–‡é˜…è¯»è®¡åˆ’</category>
      </categories>
      <tags>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cs231n Lecture 10 Recurrent Neural Networks]]></title>
    <url>%2F2018%2F12%2F24%2Fcs231n-Lecture-10-Recurrent-Neural-Networks.html%2F</url>
    <content type="text"><![CDATA[RNN Language modeling(RNN) Image captioning, Soft attention, visual question answering(CNN+RNN) LSTM, GRU 1.RNNå¾ªç¯ç¥ç»ç½‘ç»œ: $x_t$è¡¨ç¤ºtæ—¶åˆ»çš„è¾“å…¥ $h_{t-1}$è¡¨ç¤ºä¸Šä¸€æ—¶åˆ»çš„çŠ¶æ€ $f_w$æ˜¯æƒé‡ï¼Œåœ¨æ¯ä¸€ä¸ªæ—¶é—´æ­¥ä¸­ä½¿ç”¨çš„W(Notice: the same function and the same setof parameters are used at every time step.) $h_t$æ˜¯å½“å‰çš„æœ€æ–°çŠ¶æ€ $y$æ˜¯è¾“å‡º RNNåºåˆ—ç¤ºä¾‹ å¯ä»¥ç”¨æ¥åšè‡ªç„¶è¯­è¨€ç¿»è¯‘ï¼Œåºåˆ—åˆ°åºåˆ—ï¼Œå¤šåˆ°ä¸€ + ä¸€åˆ°å¤šçš„encodeå’Œdecodeæ¨¡å‹ã€‚ 2.Language modeling(RNN)ä½¿ç”¨RNNçš„ä¸€ä¸ªç®€å•å­—ç¬¦é›†è¯­è¨€æ¨¡å‹å®ä¾‹ã€‚è®­ç»ƒè¾“å‡ºhelloï¼Œç›´æ¥ç”¨ä¸€ä¸ª4*1çš„one hotå‘é‡è¡¨ç¤ºhï¼Œeï¼Œlï¼Œo 4ä¸ªè‹±æ–‡å­—æ¯ã€‚æµ‹è¯•çš„æ—¶å€™ï¼Œè¾“å‡ºå±‚æ¥ä¸€ä¸ªsoftmaxå‡½æ•°ï¼Œç„¶ååœ¨å¾—åˆ°çš„ç»“æœä¸­é‡‡æ ·è¾“å‡ºä¸‹ä¸€ä¸ªå­—ç¬¦ã€‚ ç”¨ä¸Šä¸€é˜¶æ®µçš„çŠ¶æ€å’Œæœ¬é˜¶æ®µè¾“å…¥åˆ†åˆ«ä¹˜ä»¥æƒé‡wï¼Œç„¶åç»è¿‡tanhç­‰åˆ°æœ¬é˜¶æ®µçŠ¶æ€ $h_t = tanh(W_{hh}h_{t-1}+W_{xh}x_t)$ å½“å°è¯•è®­ç»ƒwikiç½‘é¡µæ–‡æœ¬çš„æ—¶å€™ï¼Œè®­ç»ƒä¸€æ¬¡æ­£å‘åŠ åå‘ä¼ æ’­éœ€è¦éå†wikiä¸­æ‰€æœ‰æ–‡æœ¬ï¼Œå¤ªè€—æ—¶äº†ï¼Œç”¨è¿‘ä¼¼æ–¹æ³•ï¼Œæˆªæ–­æ•´ä¸ªåºåˆ—ï¼Œåˆ†æˆä¸€éƒ¨åˆ†ä¸€éƒ¨åˆ†çš„ï¼Œæ¯æ¬¡è®­ç»ƒåªåå‘ä¼ æ’­è¯¥éƒ¨åˆ†ã€‚min-char-rnn.pyä»£ç  è¿˜è®­ç»ƒäº†èå£«æ¯”äºšçš„æ–‡ç« ï¼Œæ‹“æ‰‘å­¦çš„ä¸€æœ¬ä¹¦ï¼Œlinux Cæºç ã€‚éƒ½å–å¾—äº†æœ‰è¶£çš„ç»“æœã€‚ å¹¶ä¸”æ ¹æ®ç”Ÿæˆçš„ç»“æœï¼Œè§‚å¯ŸæŸä¸ªç¥ç»å…ƒçš„å€¼ï¼Œå‘ç°æŸäº›ç¥ç»å…ƒèµ·åˆ°äº†å¥å­å¼€å¤´ï¼Œç¼©è¿›ç­‰åŠŸèƒ½ã€‚ 3.Image captioning, Soft attention, visual question answering(CNN+RNN)ï¼ˆ1ï¼‰image caption image captionè¿˜å¯ä»¥ç”¨åˆ°è½¯æ³¨æ„åŠ›soft attentionå’Œç¡¬æ³¨æ„åŠ›hard attention è½¯æ³¨æ„åŠ›ï¼šåŠ æƒç»„åˆæ‰€æœ‰å›¾åƒä½ç½®ä¸­çš„æ‰€æœ‰ç‰¹å¾ ç¡¬æ³¨æ„åŠ›ï¼šé™åˆ¶æ¯æ¬¡åªé€‰æ‹©ä¸€ä¸ªå›¾åƒä½ç½®ï¼Œä¸å¯å¾®ï¼Œä¸å¥½è®­ç»ƒï¼Œè¦ç”¨åˆ°å¢å¼ºå­¦ä¹ çš„ä¸€äº›ä¸œè¥¿ã€‚ ï¼ˆ2ï¼‰è§†è§‰é—®ç­” 4.LSTMVanila RNNåå‘ä¼ æ’­çš„æ—¶å€™ï¼Œå¦‚æœæ±‚$h_0$ï¼Œä¼šä¹˜ä»¥å¾ˆå¤šWï¼Œå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸æˆ–è€…æ¢¯åº¦æ¶ˆå¤± æ¢¯åº¦çˆ†ç‚¸å¯ä»¥ç”¨æ¢¯åº¦æˆªæ–­çš„æ–¹æ³•è§£å†³ï¼Œå°±æ˜¯è®¾ç½®ä¸€ä¸ªé˜ˆå€¼ï¼Œå¦‚æœæ¢¯åº¦çš„L2å€¼å¤§äºè¿™ä¸ªé˜ˆå€¼ï¼Œæ¢¯åº¦å°±è¿›è¡Œç¼©å‡ã€‚ æ¢¯åº¦æ¶ˆå¤±ï¼Œä½¿ç”¨æ–°çš„RNNæ¨¡å‹ï¼Œå¦‚LSTMè¿›è¡Œè§£å†³ LSTMæ¨¡å‹æœ‰ä¸¤ä¸ªéšçŠ¶æ€ï¼Œ$h_t$ï¼ˆRNNæœ¬æ¥å°±æœ‰çš„ï¼‰å’Œ$C_t$ï¼ˆç§°ä¸ºå•å…ƒçŠ¶æ€ï¼‰ iï¼Œè¾“å…¥é—¨ã€‚fï¼Œé—å¿˜é—¨ã€‚oï¼Œè¾“å‡ºé—¨ã€‚gï¼Œé—¨ä¹‹é—¨ åŒæ ·æ˜¯ç”¨ä¸Šä¸€é˜¶æ®µçš„çŠ¶æ€å’Œæœ¬é˜¶æ®µè¾“å…¥åˆ†åˆ«ä¹˜ä»¥æƒé‡wï¼Œä½†æ˜¯åˆ†åˆ«å¾—åˆ°iï¼Œfï¼Œoï¼Œgå››ä¸ªå€¼ã€‚3ä¸ªsigmoidå€¼åœ¨[0,1]ï¼Œä¸€ä¸ªtanhå€¼åœ¨[-1,1]ã€‚å‰ä¸€æ—¶åˆ»çš„å•å…ƒçŠ¶æ€$c_{t-1}$é€å…ƒç´ ä¹˜ä»¥é—å¿˜é—¨fï¼Œè¡¨ç¤ºä¹‹å‰çš„è®°å¿†å“ªäº›éœ€è¦é—å¿˜ï¼ˆä¹˜ä»¥0ï¼‰ï¼Œå“ªäº›éœ€è¦ä¿ç•™ã€‚è¾“å…¥é—¨ié€å…ƒç´ ä¹˜ä»¥é—¨gï¼ˆè¯¾ä¸Šçš„è§£é‡Šæ˜¯ï¼Œè¿™ä¸ªgç›¸å½“äºä¸€ä¸ªè®¡æ•°å™¨ï¼Œåªèƒ½è¿›è¡ŒåŠ ä¸€æˆ–è€…å‡ä¸€ï¼‰ã€‚ä¸¤è€…ç›¸åŠ å¾—åˆ°æœ¬æ—¶åˆ»çš„å•å…ƒçŠ¶æ€$C_t$ï¼Œç»è¿‡tanhå‹ç¼©åˆ°[0,1]ä¹‹é—´ï¼Œç„¶åä¹˜ä»¥è¾“å‡ºé—¨oï¼Œå¾—åˆ°$h_t$ ä¸vanila rnnç›¸æ¯”ã€‚åå‘ä¼ æ’­çš„æ—¶å€™ï¼Œé—å¿˜é—¨è¿›è¡Œçš„æ˜¯é€å…ƒç´ ç›¸ä¹˜æ“ä½œï¼Œæ¯”çŸ©é˜µç›¸ä¹˜å¥½ç®—ã€‚åŒæ—¶æ¯ä¸ªæ—¶åˆ»å•å…ƒé‡Œçš„é—å¿˜é—¨éƒ½å‘ç”Ÿå˜åŒ–ï¼Œå’Œä»¥å‰ä¹˜ä»¥ç›¸åŒçš„æƒé‡wä¸ä¸€æ ·äº†ã€‚æ¢¯åº¦ç›´æ¥é€šè¿‡$c_t$åƒä¸€æ¡é«˜é€Ÿå…¬è·¯ä¸€æ ·ä¼ æ’­ã€‚ 5.GRUæ²¡è®² 6.æ€»ç»“ RNNs allow a lot of flexibility in architecture design Vanilla RNNs are simple but donâ€™t work very well é€šå¸¸ä½¿ç”¨LSTMæˆ–è€…GRUä»–ä»¬çš„ç›¸äº’ä½œç”¨æ”¹è¿›äº†æ¢¯åº¦æµ Common to use LSTM or GRU: their additive interactionsimprove gradient flow RNNæ¢¯åº¦çš„åå‘æµåŠ¨å¯èƒ½å‘ç”Ÿçˆ†ç‚¸æˆ–æ¶ˆå¤±ã€‚çˆ†ç‚¸æ˜¯ç”±æ¢¯åº¦å‰ªåˆ‡æ§åˆ¶çš„ã€‚æ¶ˆå¤±çš„æ˜¯åŠ æ€§ç›¸äº’ä½œç”¨(LSTM)æ§åˆ¶ Backward flow of gradients in RNN can explode or vanish.Exploding is controlled with gradient clipping. Vanishing iscontrolled with additive interactions (LSTM) Better/simpler architectures are a hot topic of current research Better understanding (both theoretical and empirical) is needed.]]></content>
      <categories>
        <category>cs231n</category>
      </categories>
      <tags>
        <tag>cs231n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cs231n Lecture 9 CNN Architectures]]></title>
    <url>%2F2018%2F12%2F22%2Fcs231n-Lecture-9-CNN-Architectures.html%2F</url>
    <content type="text"><![CDATA[ä»‹ç»å‡ ä¸ªé‡è¦çš„CNNæ¨¡å‹(åœ¨imagenetæ¯”èµ›ä¸­è·å¾—å† å†›) AlexNet VGG GoogleNet ResNet 1.AlexNet2012å¹´å† imagenetæ¯”èµ›å† å†›ï¼Œç¬¬ä¸€æ¬¡ä½¿ç”¨ReLUï¼Œ8layer 2.VGG2014å¹´äºšå†›ï¼Œåªç”¨å°çš„å·ç§¯æ ¸filters(3*3)ï¼Œæ›´æ·±çš„ç½‘ç»œï¼Œ16layeræˆ–è€…19layer 19å±‚åªæ¯”16å±‚æ•ˆæœå¥½ä¸€ç‚¹ç‚¹ï¼Œä½†æ˜¯ç”¨äº†æ›´å¤šçš„å‚æ•°å’Œå†…å­˜ï¼Œçœ‹æƒ…å†µå¯ä»¥ä½¿ç”¨16å±‚ å­¦ä¹ ä¸€ä¸‹æ€ä¹ˆè®¡ç®—ç½‘ç»œçš„å‚æ•°å¤§å°(æƒé‡)å’Œå®¹é‡å¤§å°(è¾“å…¥çš„xåœ¨ç½‘ç»œä¸­ä¼ æ’­å çš„å¤§å°)ã€‚å¯ä»¥çœ‹å‡ºå¹³å‡ä¸€ä¸ªå›¾ç‰‡å°±è¦å 100Mï¼Œå¦‚æœä¸€æ‰¹32ä¸ªå›¾ç‰‡ï¼Œå°±è¦å ç”¨3Gå†…å­˜ã€‚ 3.GooLeNetï¼ˆInceptionï¼ï¼‰2014å¹´å† å†›ï¼ŒInception modelå’Œæ²¡æœ‰FCå±‚ã€‚22layer æ–°æå‡ºçš„inceptionæ¨¡å‹ï¼Œå¹¶è¡Œè¿›è¡Œ1Ã—1convï¼Œ3Ã—3convï¼Œ5Ã—5convå’Œ3Ã—3poolã€‚ä½†æ˜¯éå¸¸è€—è´¹å†…å­˜ã€‚ æå‡ºäº†â€œbottleneckâ€è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åŠ ä¸€äº›1Ã—1convï¼Œå‡å°‘ä¿¡é“æ•° 4.ResNet(skip connect)2015å¹´å† å†›ï¼Œæ®‹å·®ç½‘ç»œï¼Œç›®å‰æœ€å¥½çš„ç½‘ç»œç»“æ„ï¼Œ152å±‚ã€‚ æ®‹å·®ç½‘ç»œåŒæ ·åŠ å…¥äº†bottleneckï¼Œå½“ç½‘ç»œå±‚æ•°å¤§äº50çš„æ—¶å€™ 5.å…¶ä»–çš„ç»“æ„ï¼ˆå¯¹æ®‹å·®ç½‘ç»œçš„åç»­æ”¹è¿›ï¼‰ï¼ˆ1ï¼‰æ®‹å·®ç½‘ç»œçš„ä½œè€…è¿›è¡Œçš„æ”¹è¿› ï¼ˆ2ï¼‰è¯¥ä½œè€…è®¤ä¸ºæ®‹å·®çš„æœ‰æ•ˆæ€§åœ¨äºå®½åº¦ï¼Œä¸åœ¨äºæ·±åº¦ï¼ŒåŠ å¤§ä¸­é—´3Ã—3å·ç§¯çš„å®½åº¦(FÃ—K) ï¼ˆ3ï¼‰æ®‹å·®ç½‘ç»œä½œè€…çš„åç»­æ”¹è¿›ï¼Œå¢åŠ äº†å®½åº¦]]></content>
      <categories>
        <category>cs231n</category>
      </categories>
      <tags>
        <tag>cs231n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cs231n Lecture 7 Training Neural Networks part 2]]></title>
    <url>%2F2018%2F12%2F22%2Fcs231n-Lecture-7-Training-Neural-Networks-part-2.html%2F</url>
    <content type="text"><![CDATA[æ¨¡å‹é›†æˆ æ­£åˆ™åŒ– è¿ç§»å­¦ä¹  è¯¾ç¨‹å®˜æ–¹é“¾æ¥ è¯¾ç¨‹ç¬”è®°ç¿»è¯‘ 1.æ±‚æ¢¯åº¦ä¸‹é™çš„æ–¹æ³•æ¯”è¾ƒ Adam åœ¨å¤§å¤šæ•°æƒ…å†µæ˜¯ä¸é”™çš„é»˜è®¤é€‰æ‹© å¦‚æœä½ èƒ½å¤Ÿæ‰¿å—æ•´ä¸ªæ‰¹æ¬¡çš„æ›´æ–°ï¼Œä½ çš„é—®é¢˜æ²¡æœ‰å¾ˆå¤§çš„éšæœºæ€§ï¼Œå¯ä»¥ä½¿ç”¨L-BFGS ï¼ˆåœ¨é£æ ¼è¿ç§»ä¸­ä¼šç”¨åˆ°ï¼Ÿï¼Ÿï¼‰ If you can afford to do full batch updates then try out L-BFGS (and donâ€™t forget to disable all sources of noise) 2.Model Ensemblesæ¨¡å‹é›†æˆå‡å°‘è®­ç»ƒè¯¯å·®å’Œæµ‹è¯•è¯¯å·®ä¹‹é—´çš„å·®è· è®­ç»ƒå¤šä¸ªç‹¬ç«‹æ¨¡å‹ï¼Œåœ¨æµ‹è¯•çš„æ—¶å€™æ±‚å¹³å‡ç»“æœï¼Œä¸€èˆ¬èƒ½å¤Ÿæå‡2%çš„æ€§èƒ½ å¯ä»¥ä¸ç”¨è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼Œåœ¨ä¸€ä¸ªæ¨¡å‹çš„ä¸åŒè®­ç»ƒé˜¶æ®µä¿å­˜å¤šä¸ªå¿«ç…§ 3.æ­£åˆ™åŒ–æå‡å•ä¸€æ¨¡å‹æ•ˆæœï¼Œé™ä½è¿‡æ‹Ÿåˆã€‚æœ€ç®€å•çš„L1ï¼ŒL2ï¼Œ Elastic net (L1 + L2) æ­£åˆ™åŒ–å…¶å®å°±æ˜¯åœ¨è®­ç»ƒé›†åŠ éšæœºå™ªå£°ï¼Œåœ¨æµ‹è¯•é›†å¿½è§†è¿™äº›å™ªå£°ã€‚å¯ä»¥ä½¿ç”¨Dropoutï¼ŒBatch Normalizationå’ŒData Augmentationè¿™ä¸‰ä¸ªæ–¹æ³•ï¼š Dropoutéšæœºå¤±æ´»ï¼Œä»¥0.5çš„æ¦‚ç‡ï¼Œéšæœºé€‰æ‹©ä¸€äº›ç¥ç»å•å…ƒä¸º0 Data Augmentationæ•°æ®æ‰©å¼ ï¼šå›¾ç‰‡çš„æ—‹è½¬ï¼Œæ‹‰ä¼¸ï¼Œå‰ªåˆ‡ï¼Œæ”¹å˜å¯¹æ¯”åº¦å’Œäº®åº¦ç­‰ã€‚ batch normalizationå·²ç»ä¸ºç½‘ç»œå¢åŠ äº†éšæœºæ€§ï¼Œå› ä¸ºæ¯æ¬¡çš„æ•°æ®è¿›è¡Œæ€æ ·çš„å½’ä¸€åŒ–æœ‰éšæœºæ€§ï¼Œè¿›è¡Œäº†æ­£åˆ™åŒ–ï¼ŒåŸºæœ¬ä¸å†åŠ dropoutäº† 4.è¿ç§»å­¦ä¹ Transfer learningæ¨¡å‹ç°åœ¨Imagenetè®­ç»ƒå¥½ï¼Œä½ è¦åœ¨å¦ä¸€ä¸ªç›¸ä¼¼çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ã€‚ å¦‚æœä½ æœ‰å¾ˆå°‘çš„æ•°æ®ï¼Œé‚£å°±åœ¨æœ€åçš„FCçº¿æ€§åˆ†ç±»å±‚ï¼Œé‡æ–°åˆå§‹åŒ–è®­ç»ƒï¼Œå…¶ä»–å±‚å›ºå®šä¸å˜ã€‚ å¦‚æœä½ æœ‰è¾ƒå¤šçš„æ•°æ®ï¼Œé‚£å°±å¤šè®­ç»ƒå‡ å±‚ã€‚æœ€ä¼šå¯ä»¥ä½¿ç”¨åŸå­¦ä¹ ç‡çš„ååˆ†ä¹‹ä¸€è¿›è¡Œå¾®è°ƒæ•´ä¸ªç½‘ç»œï¼ˆfinetuningï¼‰ åœ¨ç›®æ ‡æ£€æµ‹å’Œimage captionä¸­ï¼Œéƒ½ä¼šç”¨åˆ°å·²ç»è®­ç»ƒå¥½çš„CNNæ¨¡å‹ï¼Œè¿ç§»å­¦ä¹ ã€‚]]></content>
      <categories>
        <category>cs231n</category>
      </categories>
      <tags>
        <tag>cs231n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cs231n Lecture 6 Training Neural Networks, part I]]></title>
    <url>%2F2018%2F12%2F21%2Fcs231n-Lecture-6-Training-Neural-Networks-part-I.html%2F</url>
    <content type="text"><![CDATA[æ¿€æ´»å‡½æ•° æ•°æ®é¢„å¤„ç† æƒé‡åˆå§‹åŒ– æ‰¹é‡å½’ä¸€åŒ– è¶…å‚æ•°ä¼˜åŒ– è¯¾ç¨‹å®˜æ–¹é“¾æ¥ è¯¾ç¨‹ç¬”è®°ç¿»è¯‘ 1.æ¿€æ´»å‡½æ•° (1)Sigmoid sigmoidè®²è¾“å…¥å‹ç¼©åˆ°0åˆ°1çš„èŒƒå›´å†…ï¼Œæ›¾ç»éå¸¸å¸¸ç”¨ï¼Œç°åœ¨å·²ç»å¾ˆå°‘ä½¿ç”¨äº†ã€‚ä¸»è¦æœ‰ä¸¤ä¸ªç¼ºç‚¹ï¼Œï¼ˆ1ï¼‰Sigmoidå‡½æ•°é¥±å’Œä½¿æ¢¯åº¦æ¶ˆå¤±ã€‚å½“ç¥ç»å…ƒçš„æ¿€æ´»åœ¨æ¥è¿‘0æˆ–1å¤„æ—¶ä¼šé¥±å’Œï¼šåœ¨è¿™äº›åŒºåŸŸï¼Œæ¢¯åº¦å‡ ä¹ä¸º0ã€‚ï¼ˆ2ï¼‰Sigmoidå‡½æ•°çš„è¾“å‡ºä¸æ˜¯é›¶ä¸­å¿ƒçš„ã€‚å› ä¸ºå¦‚æœè¾“å…¥ç¥ç»å…ƒçš„æ•°æ®æ€»æ˜¯æ­£æ•°ï¼ˆæ¯”å¦‚åœ¨$f=w^Tx+b$ä¸­æ¯ä¸ªå…ƒç´ éƒ½x&gt;0ï¼‰ï¼Œé‚£ä¹ˆå…³äºwçš„æ¢¯åº¦åœ¨åå‘ä¼ æ’­çš„è¿‡ç¨‹ä¸­ï¼Œå°†ä¼šè¦ä¹ˆå…¨éƒ¨æ˜¯æ­£æ•°ï¼Œè¦ä¹ˆå…¨éƒ¨æ˜¯è´Ÿæ•°ï¼ˆå…·ä½“ä¾æ•´ä¸ªè¡¨è¾¾å¼fè€Œå®šï¼‰ã€‚è¿™å°†ä¼šå¯¼è‡´æ¢¯åº¦ä¸‹é™æƒé‡æ›´æ–°æ—¶å‡ºç°zå­—å‹çš„ä¸‹é™ã€‚ç„¶è€Œï¼Œå¯ä»¥çœ‹åˆ°æ•´ä¸ªæ‰¹é‡çš„æ•°æ®çš„æ¢¯åº¦è¢«åŠ èµ·æ¥åï¼Œå¯¹äºæƒé‡çš„æœ€ç»ˆæ›´æ–°å°†ä¼šæœ‰ä¸åŒçš„æ­£è´Ÿï¼Œè¿™æ ·å°±ä»ä¸€å®šç¨‹åº¦ä¸Šå‡è½»äº†è¿™ä¸ªé—®é¢˜ã€‚å› æ­¤ï¼Œè¯¥é—®é¢˜ç›¸å¯¹äºä¸Šé¢çš„ç¥ç»å…ƒé¥±å’Œé—®é¢˜æ¥è¯´åªæ˜¯ä¸ªå°éº»çƒ¦ï¼Œæ²¡æœ‰é‚£ä¹ˆä¸¥é‡ã€‚ ï¼ˆ2ï¼‰tanh å°†å®æ•°å€¼å‹ç¼©åˆ°[-1,1]ä¹‹é—´,å®ƒä¹Ÿå­˜åœ¨é¥±å’Œé—®é¢˜ï¼Œä½†æ˜¯å’Œsigmoidç¥ç»å…ƒä¸åŒçš„æ˜¯ï¼Œå®ƒçš„è¾“å‡ºæ˜¯é›¶ä¸­å¿ƒçš„.æ³¨æ„tanhç¥ç»å…ƒæ˜¯ä¸€ä¸ªç®€å•æ”¾å¤§çš„sigmoidç¥ç»å…ƒ ï¼ˆ3ï¼‰ReLU x&gt;0,æ–œç‡ä¸º1ï¼Œx&lt;=0æ—¶ï¼Œæ–œç‡ä¸º0.è®ºæ–‡è¯æ˜ä½¿ç”¨ReLUæ¯”ä½¿ç”¨tanhçš„æ”¶æ•›å¿«6å€ã€‚sigmoidå’Œtanhç¥ç»å…ƒå«æœ‰æŒ‡æ•°è¿ç®—ç­‰è€—è´¹è®¡ç®—èµ„æºçš„æ“ä½œï¼Œè€ŒReLUå¯ä»¥ç®€å•åœ°é€šè¿‡å¯¹ä¸€ä¸ªçŸ©é˜µè¿›è¡Œé˜ˆå€¼è®¡ç®—å¾—åˆ°ã€‚ ç¼ºç‚¹æ˜¯ï¼ŒReLUçš„å•å…ƒå®¹æ˜“æ­»æ‰ï¼Œå¦‚æœå­¦ä¹ ç‡è®¾ç½®çš„å¤ªé«˜ï¼Œç½‘ç»œæ±‡æ€»40%çš„ç¥ç»å…ƒéƒ½ä¼šæ­»æ‰ ï¼ˆ4ï¼‰Leaky ReLU Leaky ReLUè§£å†³å•å…ƒæ­»äº¡é—®é¢˜ï¼Œx&lt;0çš„æ—¶å€™ç»™ä¸€ä¸ªå°å°çš„æ¢¯åº¦å€¼ ï¼ˆ5ï¼‰å…¶ä»–Exponential Linear Units (ELU) Maxout â€œNeuronâ€ ï¼ˆ6ï¼‰æ€»ç»“ ç”¨ReLUéçº¿æ€§å‡½æ•°ï¼Œæ³¨æ„è®¾ç½®å¥½å­¦ä¹ ç‡ å¦‚æœå•å…ƒæ­»äº¡é—®é¢˜å›°æ‰°ä½ ï¼Œå°±è¯•è¯•Leaky ReLU / Maxout / ELU ä¹Ÿå¯ä»¥è¯•è¯•tanhï¼Œä½†æ˜¯å…¶æ•ˆæœåº”è¯¥ä¸å¦‚ReLUæˆ–è€…Maxout ä¸è¦ä½¿ç”¨sigmoid 2.æ•°æ®é¢„å¤„ç† ä¸­å¿ƒåŒ–(é›¶å‡å€¼) å½’ä¸€åŒ–ï¼Œä¸€ç§æ˜¯å…ˆé›¶ä¸­å¿ƒåŒ–ï¼Œç„¶åé™¤ä»¥æ ‡å‡†å·®ã€‚ä¸€ç§æ˜¯å…¨éƒ½å½’ä¸€åŒ–åˆ°[-1,1]ä¹‹é—´ã€‚ æŒ‰ç…§ä¸Šé¢æ•°æ®é¢„å¤„ç†ä¹‹åï¼Œå¯¹æƒé‡å°çš„æ‰°åŠ¨ä¸æ•æ„Ÿï¼Œè®­ç»ƒç¨³å®š 3.æƒé‡åˆå§‹åŒ–gaussian with zero mean and 1e-2 standard deviation $W = 0.01 * np.random.randn(D,H)â€‹$ æƒé‡å¤ªå°ï¼Œä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ã€‚å› ä¸ºåå‘ä¼ æ’­çš„æ—¶å€™ä¼šä¹˜ä»¥å½“å‰æ¢¯åº¦ æƒé‡å¤ªå¤šï¼Œä¼šå¯¼è‡´é¥±å’Œ ã€‚æ¯”å¦‚tanhã€‚ æ€»ç»“ï¼šå½“å‰çš„æ¨èæ˜¯ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°ï¼Œå¹¶ä¸”ä½¿ç”¨$w = np.random.randn(n) * sqrt(2.0/n)$æ¥è¿›è¡Œæƒé‡åˆå§‹åŒ–ï¼Œæ¥è‡ªè®ºæ–‡. 4.Batch Normalizationæ‰¹é‡å½’ä¸€åŒ– åœ¨å…¨è¿æ¥å±‚æˆ–è€…å·ç§¯å±‚ ä¸ æ¿€æ´»å‡½æ•°ä¹‹é—´æ·»åŠ ä¸€ä¸ªBatchNormå±‚ã€‚å¯ä»¥ç†è§£ä¸ºåœ¨ç½‘ç»œçš„æ¯ä¸€å±‚ä¹‹å‰éƒ½åšæ•°æ®é¢„å¤„ç†ï¼Œæ·»åŠ äº†ä¹‹åä¸ç”¨å°å¿ƒçš„è¿›è¡Œæƒé‡åˆå§‹åŒ–äº†ã€‚ 5.Babysitting the Learning Process1.é¢„å¤„ç†æ•°æ® 2.é€‰æ‹©ç½‘ç»œç»“æ„ 3.ç¡®å®šæŸå¤±å‡½æ•°æ˜¯åˆç†çš„ï¼šçœ‹ä½ çš„æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿè¿‡æ‹Ÿåˆå°æ•°æ®é›† 6.è¶…å‚æ•°ä¼˜åŒ–äº¤å‰éªŒè¯ï¼Œæ¯ä¸ªè·‘5epochï¼Œå­¦ä¹ ç‡åœ¨æŸä¸ªå–å€¼èŒƒå›´å†…æµ‹è¯•ï¼ˆbest to optimize in log spaceï¼‰ æŸå¤±å‡½æ•°ä¸å˜ï¼Œå­¦ä¹ ç‡å¤ªå°ã€‚æŸå¤±å‡½æ•°NANï¼Œå­¦ä¹ ç‡å¤ªå¤§ã€‚åœ¨1e-3åˆ°1e-5èŒƒå›´å†…ä¸€èˆ¬ã€‚ 10**uniformï¼ˆ-3,-4ï¼‰ éšæœºæœç´¢&gt;ç½‘æ ¼æœç´¢ æŸå¤±å‡½æ•°åœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°å¥½ï¼Œåœ¨éªŒè¯é›†ä¸Šè¡¨ç°å·®ï¼Œè¯´æ˜è¿‡æ‹Ÿåˆäº†ï¼Œè¦åŠ å¤§æ­£åˆ™åŒ–æŸå¤±ã€‚ 7.æ€»ç»“ Activation Functions (use ReLU) Data Preprocessing (images: subtract mean) Weight Initialization (use Xavier/He init) Batch Normalization (use) Babysitting the Learning process Hyperparameter Optimization(random sample hyperparams, in log space when appropriate)]]></content>
      <categories>
        <category>cs231n</category>
      </categories>
      <tags>
        <tag>cs231n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cs231n å‚æ•°è®¾ç½®æŠ€å·§]]></title>
    <url>%2F2018%2F12%2F20%2Fcs231n-%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE%E6%8A%80%E5%B7%A7.html%2F</url>
    <content type="text"><![CDATA[è®¤ä¸ºæœ‰ç”¨çš„ä¸€äº›æŠ€å·§çŸ¥è¯†1.éªŒè¯é›†ç”¨æ¥ç¡®å®šè¶…å‚æ•°ï¼Œæµ‹è¯•é›†ç”¨æ¥æµ‹è¯•æ€§èƒ½ï¼Œä¸åˆ°æœ€åä¸è¦ä½¿ç”¨æµ‹è¯•é›†ï¼ 2.æ­¥é•¿(å­¦ä¹ ç‡)éœ€è¦ç”¨éªŒè¯é›†æ‰¾åˆ°æœ€ä¼˜è§£ 3.batch_sizeä¸€èˆ¬ç”±GPUå¤§å°å†³å®šï¼Œä½†æ˜¯è®¾ç½®æˆ2çš„æŒ‡æ•°ï¼Œè¿™æ ·ä¼šè¿ç®—å¿«ä¸€ç‚¹ï¼ˆ32,64,128ç­‰ï¼‰ 4.GANä¸åŠ poolingå±‚ï¼Œå¦‚æœè¦ç”¨max poolingæ•ˆæœæ¯”average poolingå¥½ 5.å…¨è¿æ¥å±‚è½¬åŒ–ä¸ºå·ç§¯å±‚ï¼Ÿ 6.å‡ ä¸ªå°æ»¤æ³¢å™¨å·ç§¯å±‚çš„ç»„åˆæ¯”ä¸€ä¸ªå¤§æ»¤æ³¢å™¨å·ç§¯å±‚å¥½ã€‚å åŠ ä½¿ç”¨ä¸‰å±‚3ä¸ª3Ã—3å·ç§¯ï¼Œè€Œä¸æ˜¯ä¸€ä¸ª7Ã—7å·ç§¯ã€‚å‰è€…å¯ä»¥è¡¨è¾¾å‡ºè¾“å…¥æ•°æ®ä¸­æ›´å¤šä¸ªå¼ºåŠ›ç‰¹å¾ï¼Œä½¿ç”¨çš„å‚æ•°ä¹Ÿæ›´å°‘ã€‚å”¯ä¸€çš„ä¸è¶³æ˜¯ï¼Œåœ¨è¿›è¡Œåå‘ä¼ æ’­æ—¶ï¼Œä¸­é—´çš„å·ç§¯å±‚å¯èƒ½ä¼šå¯¼è‡´å ç”¨æ›´å¤šçš„å†…å­˜ æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ æ•°æ®åˆå§‹åŒ–ï¼šæ¨èçš„é¢„å¤„ç†æ“ä½œæ˜¯å¯¹æ•°æ®çš„æ¯ä¸ªç‰¹å¾éƒ½è¿›è¡Œé›¶ä¸­å¿ƒåŒ–ï¼Œç„¶åå°†å…¶æ•°å€¼èŒƒå›´éƒ½å½’ä¸€åŒ–åˆ°[-1,1]èŒƒå›´ä¹‹å†…ã€‚ æƒé‡åˆå§‹åŒ–ï¼šå½“å‰çš„æ¨èæ˜¯ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°ï¼Œå¹¶ä¸”ä½¿ç”¨$w = np.random.randn(n) * sqrt(2.0/n)$æ¥è¿›è¡Œæƒé‡åˆå§‹åŒ–ã€‚ ä½†æ˜¯å¦‚æœä½¿ç”¨æ‰¹é‡å½’ä¸€åŒ–batch normalizationï¼Œå¯ä»¥ä¸ç®¡æƒé‡åˆå§‹åŒ–å’Œæ­£åˆ™åŒ– æŸå¤±å‡½æ•°ä½¿ç”¨ReLUï¼Œå¦‚æœæœ‰å•å…ƒæ­»äº¡é—®é¢˜ï¼Œå°±è¯•è¯•Leaky ReLU/Maxout/ELUã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨tanhä½†æ˜¯è‚¯å®šæ•ˆæœä¸å¦‚ReLUå’ŒMaoutã€‚ä¸€å®šä¸è¦ä½¿ç”¨sigmoidã€‚ è¶…å‚æ•°è®¾ç½®ã€‚æœ€é‡è¦çš„å°±æ˜¯å­¦ä¹ ç‡ã€‚å…ˆæ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„å­¦ä¹ ç‡ï¼Œå…¶ä»–çš„æ¨¡å‹å±‚æ•°ï¼Œæƒé‡å€¼ç­‰ä¹‹åå†è¿›è¡Œå¯»æ‰¾ã€‚ä½¿ç”¨éšæœºæœç´¢ï¼ˆä¸è¦ç”¨ç½‘æ ¼æœç´¢ï¼‰æ¥æœç´¢æœ€ä¼˜çš„è¶…å‚æ•°ã€‚åˆ†é˜¶æ®µä»ç²—ï¼ˆæ¯”è¾ƒå®½çš„è¶…å‚æ•°èŒƒå›´è®­ç»ƒ1-5ä¸ªå‘¨æœŸï¼‰åˆ°ç»†ï¼ˆçª„èŒƒå›´è®­ç»ƒå¾ˆå¤šä¸ªå‘¨æœŸï¼‰åœ°æ¥æœç´¢ã€‚ éšç€è®­ç»ƒè¿›è¡Œå­¦ä¹ ç‡è¡°å‡ã€‚æ¯”å¦‚ï¼Œåœ¨å›ºå®šå¤šå°‘ä¸ªå‘¨æœŸåè®©å­¦ä¹ ç‡å‡åŠï¼Œæˆ–è€…å½“éªŒè¯é›†å‡†ç¡®ç‡ä¸‹é™çš„æ—¶å€™ã€‚ è¿›è¡Œåˆç†æ€§æ£€æŸ¥ï¼Œç¡®è®¤åˆå§‹æŸå¤±å‡½æ•°å€¼æ˜¯åˆç†çš„ï¼Œåœ¨å°æ•°æ®é›†ä¸Šèƒ½å¾—åˆ°100%çš„å‡†ç¡®ç‡ï¼ˆè¿‡æ‹Ÿåˆè¿™ä¸ªæ•°æ®é›†ï¼‰ã€‚ åœ¨è®­ç»ƒæ—¶ï¼Œè·Ÿè¸ªæŸå¤±å‡½æ•°å€¼ï¼ŒæŸå¤±å‡½æ•°4ä¸­ä¸åŒçš„ä¸‹é™é€Ÿç‡ï¼Œå¯ä»¥è§‚å¯Ÿå‡ºå­¦ä¹ ç‡æ˜¯å¦åˆç†ã€‚ æ¯”è¾ƒè®­ç»ƒé›†å’ŒéªŒè¯é›†å‡†ç¡®ç‡ï¼Œç›¸å·®è¾ƒå¤šçš„è¯ï¼Œè¯´æ˜æ¨¡å‹è¿‡æ‹Ÿåˆäº†ï¼Œè¿™ç§æƒ…å†µåº”è¯¥åŠ å¤§æ­£åˆ™é¡¹æˆ–è€…æ”¶é›†æ›´å¤šçš„æ•°æ®ã€‚å¦ä¸€ç§å¯èƒ½å°±æ˜¯éªŒè¯é›†æ›²çº¿å’Œè®­ç»ƒé›†æ›²çº¿å¦‚å½±éšå½¢ï¼Œè¿™ç§æƒ…å†µè¯´æ˜ä½ çš„æ¨¡å‹å®¹é‡è¿˜ä¸å¤Ÿå¤§ï¼šåº”è¯¥é€šè¿‡å¢åŠ å‚æ•°æ•°é‡è®©æ¨¡å‹å®¹é‡æ›´å¤§äº›ã€‚ è¿˜å¯ä»¥è·Ÿè¸ªæ›´æ–°çš„å‚æ•°é‡ç›¸å¯¹äºæ€»å‚æ•°é‡çš„æ¯”ä¾‹ã€‚ä¸€ä¸ªç»éªŒæ€§çš„ç»“è®ºæ˜¯è¿™ä¸ªæ¯”ä¾‹åº”è¯¥åœ¨1e-3å·¦å³ã€‚å¦‚æœæ›´ä½ï¼Œè¯´æ˜å­¦ä¹ ç‡å¯èƒ½å¤ªå°ï¼Œå¦‚æœæ›´é«˜ï¼Œè¯´æ˜å­¦ä¹ ç‡å¯èƒ½å¤ªé«˜ã€‚ æ¯å±‚çš„æ¿€æ´»æ•°æ®åŠæ¢¯åº¦åˆ†å¸ƒã€‚ä¸€ä¸ªä¸æ­£ç¡®çš„åˆå§‹åŒ–å¯èƒ½è®©å­¦ä¹ è¿‡ç¨‹å˜æ…¢ï¼Œç”šè‡³å½»åº•åœæ­¢ï¼Œè¾“å‡ºç½‘ç»œä¸­æ‰€æœ‰å±‚çš„æ¿€æ´»æ•°æ®å’Œæ¢¯åº¦åˆ†å¸ƒçš„æŸ±çŠ¶å›¾ï¼Œä¸è¦å‡ºç°å¥‡æ€ªçš„åˆ†å¸ƒã€‚æ¯”å¦‚ï¼Œå¯¹äºä½¿ç”¨tanhçš„ç¥ç»å…ƒï¼Œæˆ‘ä»¬åº”è¯¥çœ‹åˆ°æ¿€æ´»æ•°æ®çš„å€¼åœ¨æ•´ä¸ª[-1,1]åŒºé—´ä¸­éƒ½æœ‰åˆ†å¸ƒã€‚å¦‚æœçœ‹åˆ°ç¥ç»å…ƒçš„è¾“å‡ºå…¨éƒ¨æ˜¯0ï¼Œæˆ–è€…å…¨éƒ½é¥±å’Œäº†å¾€-1å’Œ1ä¸Šè·‘ï¼Œé‚£è‚¯å®šå°±æ˜¯æœ‰é—®é¢˜äº†ã€‚ ç„¶åå¦‚æœæ˜¯å¯¹äºå·ç§¯ç¥ç»ç½‘ç»œï¼Œå¯ä»¥å°†ç¬¬ä¸€å±‚çš„æƒé‡å¯è§†åŒ–ã€‚]]></content>
      <categories>
        <category>cs231n</category>
      </categories>
      <tags>
        <tag>cs231n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cs231n Lecture5 Convolutional Neural Networks]]></title>
    <url>%2F2018%2F12%2F20%2Fcs231n-Lecture5-Convolutional-Neural-Networks.html%2F</url>
    <content type="text"><![CDATA[å·ç§¯æ ¸æ± åŒ– å…¨è¿æ¥å±‚è½¬å˜ä¸ºå·ç§¯å±‚ å‡ ä¸ªå°æ»¤æ³¢å™¨å·ç§¯å±‚çš„ç»„åˆæ¯”ä¸€ä¸ªå¤§æ»¤æ³¢å™¨å±‚æ›´å¥½ è¯¾ç¨‹ç¬”è®° 1.å·ç§¯ è¾“å…¥ä¸º32Ã—32Ã—3çš„å›¾åƒ ç»è¿‡6ä¸ª5Ã—5Ã—3çš„å·ç§¯æ ¸ï¼Œ3æ˜¯è¾“å…¥å›¾åƒçš„æ·±åº¦ï¼ˆchannelï¼‰ å¾—åˆ°28Ã—28Ã—6 ç»è¿‡10ä¸ª5Ã—5Ã—6çš„å·ç§¯æ ¸ å¾—åˆ°24Ã—24Ã—10 2.è®¡ç®—ç»è¿‡å·ç§¯ä¹‹åçš„è¾“å‡ºç‰¹å¾çš„å®½å’Œé«˜è¾“å…¥å°ºå¯¸ä¸º$W_{1}Ã—H_{1}Ã—D_{1}$ æ»¤æ³¢å™¨çš„æ•°é‡Kæ»¤æ³¢å™¨çš„ç©ºé—´å°ºå¯¸Fæ­¥é•¿Sé›¶å¡«å……æ•°é‡P è¾“å‡ºå°ºå¯¸ä¸º$W_{2}Ã—H_{2}Ã—D_{2}$ $H_2 = W_2=(W_1-F+2P)/S+1$ $D_2=k$ 3.å·ç§¯è®¡ç®—è¿‡ç¨‹ å¦‚å›¾ï¼Œè¾“å…¥æ•°æ®ä½“æ˜¯è“è‰²ï¼Œæƒé‡æ•°æ®ä½“æ˜¯çº¢è‰²ï¼Œè¾“å‡ºæ•°æ®ä½“æ˜¯ç»¿è‰²ã€‚è¾“å…¥æ•°æ®ä½“çš„å°ºå¯¸æ˜¯$W_1=5$,$H_1=5$,$D_1=3$ï¼Œå·ç§¯å±‚å‚æ•°$K=2,F=3,S=2,P=1$ã€‚å°±æ˜¯è¯´ï¼Œæœ‰2ä¸ªæ»¤æ³¢å™¨ï¼Œæ»¤æ³¢å™¨çš„å°ºå¯¸æ˜¯$3\cdot 3$ï¼Œå®ƒä»¬çš„æ­¥é•¿æ˜¯2.å› æ­¤ï¼Œè¾“å‡ºæ•°æ®ä½“çš„ç©ºé—´å°ºå¯¸æ˜¯(5-3+2)/2+1=3ã€‚æ³¨æ„è¾“å…¥æ•°æ®ä½“ä½¿ç”¨äº†é›¶å¡«å……P=1ï¼Œæ‰€ä»¥è¾“å…¥æ•°æ®ä½“å¤–è¾¹ç¼˜ä¸€åœˆéƒ½æ˜¯0ã€‚ è¾“å‡ºçš„æ¯ä¸ªå…ƒç´ ï¼Œéƒ½æ˜¯é€šè¿‡è“è‰²è¾“å…¥çš„å±€éƒ¨åŒºåŸŸï¼Œä¸çº¢è‰²å·ç§¯æ ¸é€å…ƒç´ ç›¸ä¹˜ï¼Œç„¶åæ±‚å…¶å’Œï¼Œå†åŠ ä¸Šåå·®ï¼ˆbiasï¼‰å¾—æ¥çš„ã€‚ 4.æ± åŒ–å±‚poolingå±‚é™ä½ç©ºé—´å°ºå¯¸ï¼Œå‡å°‘å‚æ•°ï¼Œå…¶å®å°±æ˜¯ä¸‹é‡‡æ · ä¸€èˆ¬ä½¿ç”¨max pooling æ¯”ä½¿ç”¨average poolingå¯ä»¥å¾—åˆ°æ›´å¥½çš„æ•ˆæœ ä¸å¯ä»¥åŠ å¤ªå¤špoolingå±‚ï¼Œä¸¢æ‰äº†å¾ˆå¤šä¿¡æ¯ã€‚ ç½‘ç»œå±‚çš„æ’åˆ—è§„å¾‹å‚è€ƒï¼š INPUT -&gt; [CONV -&gt; RELU -&gt; CONV -&gt; RELU -&gt; POOL]3 -&gt; [FC -&gt; RELU]2 -&gt; FC è®­ç»ƒè‰¯å¥½çš„ç”Ÿæˆæ¨¡å‹éƒ½ä¸ç”¨poolingå±‚ï¼Œå¦‚VAEä½•GAN 5.å…¨è¿æ¥å±‚è½¬åŒ–ä¸ºå·ç§¯å±‚å…¨è¿æ¥å±‚å’Œå·ç§¯å±‚ä¹‹é—´å”¯ä¸€çš„ä¸åŒå°±æ˜¯å·ç§¯å±‚ä¸­çš„ç¥ç»å…ƒåªä¸è¾“å…¥æ•°æ®ä¸­çš„ä¸€ä¸ªå±€éƒ¨åŒºåŸŸè¿æ¥ï¼Œå¹¶ä¸”åœ¨å·ç§¯åˆ—ä¸­çš„ç¥ç»å…ƒå…±äº«å‚æ•°ã€‚ç„¶è€Œåœ¨ä¸¤ç±»å±‚ä¸­ï¼Œç¥ç»å…ƒéƒ½æ˜¯è®¡ç®—ç‚¹ç§¯ï¼Œæ‰€ä»¥å®ƒä»¬çš„å‡½æ•°å½¢å¼æ˜¯ä¸€æ ·çš„ã€‚å› æ­¤ï¼Œå°†æ­¤ä¸¤è€…ç›¸äº’è½¬åŒ–æ˜¯å¯èƒ½çš„ï¼š å¯¹äºä»»ä¸€ä¸ªå·ç§¯å±‚ï¼Œéƒ½å­˜åœ¨ä¸€ä¸ªèƒ½å®ç°å’Œå®ƒä¸€æ ·çš„å‰å‘ä¼ æ’­å‡½æ•°çš„å…¨è¿æ¥å±‚ã€‚æƒé‡çŸ©é˜µæ˜¯ä¸€ä¸ªå·¨å¤§çš„çŸ©é˜µï¼Œé™¤äº†æŸäº›ç‰¹å®šå—ï¼ˆè¿™æ˜¯å› ä¸ºæœ‰å±€éƒ¨è¿æ¥ï¼‰ï¼Œå…¶ä½™éƒ¨åˆ†éƒ½æ˜¯é›¶ã€‚è€Œåœ¨å…¶ä¸­å¤§éƒ¨åˆ†å—ä¸­ï¼Œå…ƒç´ éƒ½æ˜¯ç›¸ç­‰çš„ï¼ˆå› ä¸ºå‚æ•°å…±äº«ï¼‰ã€‚ç›¸åï¼Œä»»ä½•å…¨è¿æ¥å±‚éƒ½å¯ä»¥è¢«è½¬åŒ–ä¸ºå·ç§¯å±‚ã€‚æ¯”å¦‚ï¼Œä¸€ä¸ªK=4096çš„å…¨è¿æ¥å±‚ï¼Œè¾“å…¥æ•°æ®ä½“çš„å°ºå¯¸æ˜¯7\times 7\times 512ï¼Œè¿™ä¸ªå…¨è¿æ¥å±‚å¯ä»¥è¢«ç­‰æ•ˆåœ°çœ‹åšä¸€ä¸ªF=7,P=0,S=1,K=4096çš„å·ç§¯å±‚ã€‚æ¢å¥è¯è¯´ï¼Œå°±æ˜¯å°†æ»¤æ³¢å™¨çš„å°ºå¯¸è®¾ç½®ä¸ºå’Œè¾“å…¥æ•°æ®ä½“çš„å°ºå¯¸ä¸€è‡´äº†ã€‚å› ä¸ºåªæœ‰ä¸€ä¸ªå•ç‹¬çš„æ·±åº¦åˆ—è¦†ç›–å¹¶æ»‘è¿‡è¾“å…¥æ•°æ®ä½“ï¼Œæ‰€ä»¥è¾“å‡ºå°†å˜æˆ1\times 1\times 4096ï¼Œè¿™ä¸ªç»“æœå°±å’Œä½¿ç”¨åˆå§‹çš„é‚£ä¸ªå…¨è¿æ¥å±‚ä¸€æ ·äº†ã€‚ å…¨è¿æ¥å±‚è½¬åŒ–ä¸ºå·ç§¯å±‚ï¼šåœ¨ä¸¤ç§å˜æ¢ä¸­ï¼Œå°†å…¨è¿æ¥å±‚è½¬åŒ–ä¸ºå·ç§¯å±‚åœ¨å®é™…è¿ç”¨ä¸­æ›´åŠ æœ‰ç”¨ã€‚å‡è®¾ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œçš„è¾“å…¥æ˜¯224x224x3çš„å›¾åƒï¼Œä¸€ç³»åˆ—çš„å·ç§¯å±‚å’Œæ±‡èšå±‚å°†å›¾åƒæ•°æ®å˜ä¸ºå°ºå¯¸ä¸º7x7x512çš„æ¿€æ´»æ•°æ®ä½“ï¼ˆåœ¨AlexNetä¸­å°±æ˜¯è¿™æ ·ï¼Œé€šè¿‡ä½¿ç”¨5ä¸ªæ±‡èšå±‚æ¥å¯¹è¾“å…¥æ•°æ®è¿›è¡Œç©ºé—´ä¸Šçš„é™é‡‡æ ·ï¼Œæ¯æ¬¡å°ºå¯¸ä¸‹é™ä¸€åŠï¼Œæ‰€ä»¥æœ€ç»ˆç©ºé—´å°ºå¯¸ä¸º224/2/2/2/2/2=7ï¼‰ã€‚ä»è¿™é‡Œå¯ä»¥çœ‹åˆ°ï¼ŒAlexNetä½¿ç”¨äº†ä¸¤ä¸ªå°ºå¯¸ä¸º4096çš„å…¨è¿æ¥å±‚ï¼Œæœ€åä¸€ä¸ªæœ‰1000ä¸ªç¥ç»å…ƒçš„å…¨è¿æ¥å±‚ç”¨äºè®¡ç®—åˆ†ç±»è¯„åˆ†ã€‚æˆ‘ä»¬å¯ä»¥å°†è¿™3ä¸ªå…¨è¿æ¥å±‚ä¸­çš„ä»»æ„ä¸€ä¸ªè½¬åŒ–ä¸ºå·ç§¯å±‚ï¼š é’ˆå¯¹ç¬¬ä¸€ä¸ªè¿æ¥åŒºåŸŸæ˜¯[7x7x512]çš„å…¨è¿æ¥å±‚ï¼Œä»¤å…¶æ»¤æ³¢å™¨å°ºå¯¸ä¸ºF=7ï¼Œè¿™æ ·è¾“å‡ºæ•°æ®ä½“å°±ä¸º[1x1x4096]äº†ã€‚é’ˆå¯¹ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ï¼Œä»¤å…¶æ»¤æ³¢å™¨å°ºå¯¸ä¸ºF=1ï¼Œè¿™æ ·è¾“å‡ºæ•°æ®ä½“ä¸º[1x1x4096]ã€‚å¯¹æœ€åä¸€ä¸ªå…¨è¿æ¥å±‚ä¹Ÿåšç±»ä¼¼çš„ï¼Œä»¤å…¶F=1ï¼Œæœ€ç»ˆè¾“å‡ºä¸º[1x1x1000]å®é™…æ“ä½œä¸­ï¼Œæ¯æ¬¡è¿™æ ·çš„å˜æ¢éƒ½éœ€è¦æŠŠå…¨è¿æ¥å±‚çš„æƒé‡Wé‡å¡‘æˆå·ç§¯å±‚çš„æ»¤æ³¢å™¨ã€‚é‚£ä¹ˆè¿™æ ·çš„è½¬åŒ–æœ‰ä»€ä¹ˆä½œç”¨å‘¢ï¼Ÿå®ƒåœ¨ä¸‹é¢çš„æƒ…å†µä¸‹å¯ä»¥æ›´é«˜æ•ˆï¼šè®©å·ç§¯ç½‘ç»œåœ¨ä¸€å¼ æ›´å¤§çš„è¾“å…¥å›¾ç‰‡ä¸Šæ»‘åŠ¨ï¼ˆè¯‘è€…æ³¨ï¼šå³æŠŠä¸€å¼ æ›´å¤§çš„å›¾ç‰‡çš„ä¸åŒåŒºåŸŸéƒ½åˆ†åˆ«å¸¦å…¥åˆ°å·ç§¯ç½‘ç»œï¼Œå¾—åˆ°æ¯ä¸ªåŒºåŸŸçš„å¾—åˆ†ï¼‰ï¼Œå¾—åˆ°å¤šä¸ªè¾“å‡ºï¼Œè¿™æ ·çš„è½¬åŒ–å¯ä»¥è®©æˆ‘ä»¬åœ¨å•ä¸ªå‘å‰ä¼ æ’­çš„è¿‡ç¨‹ä¸­å®Œæˆä¸Šè¿°çš„æ“ä½œã€‚ ä¸¾ä¸ªä¾‹å­ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è®©224x224å°ºå¯¸çš„æµ®çª—ï¼Œä»¥æ­¥é•¿ä¸º32åœ¨384x384çš„å›¾ç‰‡ä¸Šæ»‘åŠ¨ï¼ŒæŠŠæ¯ä¸ªç»åœçš„ä½ç½®éƒ½å¸¦å…¥å·ç§¯ç½‘ç»œï¼Œæœ€åå¾—åˆ°6x6ä¸ªä½ç½®çš„ç±»åˆ«å¾—åˆ†ã€‚ä¸Šè¿°çš„æŠŠå…¨è¿æ¥å±‚è½¬æ¢æˆå·ç§¯å±‚çš„åšæ³•ä¼šæ›´ç®€ä¾¿ã€‚å¦‚æœ224x224çš„è¾“å…¥å›¾ç‰‡ç»è¿‡å·ç§¯å±‚å’Œæ±‡èšå±‚ä¹‹åå¾—åˆ°äº†[7x7x512]çš„æ•°ç»„ï¼Œé‚£ä¹ˆï¼Œ384x384çš„å¤§å›¾ç‰‡ç›´æ¥ç»è¿‡åŒæ ·çš„å·ç§¯å±‚å’Œæ±‡èšå±‚ä¹‹åä¼šå¾—åˆ°[12x12x512]çš„æ•°ç»„ï¼ˆå› ä¸ºé€”å¾„5ä¸ªæ±‡èšå±‚ï¼Œå°ºå¯¸å˜ä¸º384/2/2/2/2/2 = 12ï¼‰ã€‚ç„¶åå†ç»è¿‡ä¸Šé¢ç”±3ä¸ªå…¨è¿æ¥å±‚è½¬åŒ–å¾—åˆ°çš„3ä¸ªå·ç§¯å±‚ï¼Œæœ€ç»ˆå¾—åˆ°[6x6x1000]çš„è¾“å‡ºï¼ˆå› ä¸º(12 - 7)/1 + 1 = 6ï¼‰ã€‚è¿™ä¸ªç»“æœæ­£æ˜¯æµ®çª—åœ¨åŸå›¾ç»åœçš„6x6ä¸ªä½ç½®çš„å¾—åˆ†ï¼ï¼ˆè¯‘è€…æ³¨ï¼šè¿™ä¸€æ®µçš„ç¿»è¯‘ä¸åŸæ–‡ä¸åŒï¼Œç»è¿‡äº†è¯‘è€…è¾ƒå¤šçš„ä¿®æ”¹ï¼Œä½¿æ›´å®¹æ˜“ç†è§£ï¼‰ é¢å¯¹384x384çš„å›¾åƒï¼Œè®©ï¼ˆå«å…¨è¿æ¥å±‚ï¼‰çš„åˆå§‹å·ç§¯ç¥ç»ç½‘ç»œä»¥32åƒç´ çš„æ­¥é•¿ç‹¬ç«‹å¯¹å›¾åƒä¸­çš„224x224å—è¿›è¡Œå¤šæ¬¡è¯„ä»·ï¼Œå…¶æ•ˆæœå’Œä½¿ç”¨æŠŠå…¨è¿æ¥å±‚å˜æ¢ä¸ºå·ç§¯å±‚åçš„å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­æ˜¯ä¸€æ ·çš„ã€‚è‡ªç„¶ï¼Œç›¸è¾ƒäºä½¿ç”¨è¢«è½¬åŒ–å‰çš„åŸå§‹å·ç§¯ç¥ç»ç½‘ç»œå¯¹æ‰€æœ‰36ä¸ªä½ç½®è¿›è¡Œè¿­ä»£è®¡ç®—ï¼Œä½¿ç”¨è½¬åŒ–åçš„å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­è®¡ç®—è¦é«˜æ•ˆå¾—å¤šï¼Œå› ä¸º36æ¬¡è®¡ç®—éƒ½åœ¨å…±äº«è®¡ç®—èµ„æºã€‚è¿™ä¸€æŠ€å·§åœ¨å®è·µä¸­ç»å¸¸ä½¿ç”¨ï¼Œä¸€æ¬¡æ¥è·å¾—æ›´å¥½çš„ç»“æœã€‚æ¯”å¦‚ï¼Œé€šå¸¸å°†ä¸€å¼ å›¾åƒå°ºå¯¸å˜å¾—æ›´å¤§ï¼Œç„¶åä½¿ç”¨å˜æ¢åçš„å·ç§¯ç¥ç»ç½‘ç»œæ¥å¯¹ç©ºé—´ä¸Šå¾ˆå¤šä¸åŒä½ç½®è¿›è¡Œè¯„ä»·å¾—åˆ°åˆ†ç±»è¯„åˆ†ï¼Œç„¶ååœ¨æ±‚è¿™äº›åˆ†å€¼çš„å¹³å‡å€¼ã€‚ æœ€åï¼Œå¦‚æœæˆ‘ä»¬æƒ³ç”¨æ­¥é•¿å°äº32çš„æµ®çª—æ€ä¹ˆåŠï¼Ÿç”¨å¤šæ¬¡çš„å‘å‰ä¼ æ’­å°±å¯ä»¥è§£å†³ã€‚æ¯”å¦‚æˆ‘ä»¬æƒ³ç”¨æ­¥é•¿ä¸º16çš„æµ®çª—ã€‚é‚£ä¹ˆå…ˆä½¿ç”¨åŸå›¾åœ¨è½¬åŒ–åçš„å·ç§¯ç½‘ç»œæ‰§è¡Œå‘å‰ä¼ æ’­ï¼Œç„¶ååˆ†åˆ«æ²¿å®½åº¦ï¼Œæ²¿é«˜åº¦ï¼Œæœ€ååŒæ—¶æ²¿å®½åº¦å’Œé«˜åº¦ï¼ŒæŠŠåŸå§‹å›¾ç‰‡åˆ†åˆ«å¹³ç§»16ä¸ªåƒç´ ï¼Œç„¶åæŠŠè¿™äº›å¹³ç§»ä¹‹åçš„å›¾åˆ†åˆ«å¸¦å…¥å·ç§¯ç½‘ç»œã€‚ï¼ˆè¯‘è€…æ³¨ï¼šè¿™ä¸€æ®µçš„ç¿»è¯‘ä¸åŸæ–‡ä¸åŒï¼Œç»è¿‡äº†è¯‘è€…è¾ƒå¤šçš„ä¿®æ”¹ï¼Œä½¿æ›´å®¹æ˜“ç†è§£ï¼‰ 6.å‡ ä¸ªå°æ»¤æ³¢å™¨å·ç§¯å±‚çš„ç»„åˆæ¯”ä¸€ä¸ªå¤§æ»¤æ³¢å™¨å·ç§¯å±‚å¥½å‡ ä¸ªå°æ»¤æ³¢å™¨å·ç§¯å±‚çš„ç»„åˆæ¯”ä¸€ä¸ªå¤§æ»¤æ³¢å™¨å·ç§¯å±‚å¥½ï¼šå‡è®¾ä½ ä¸€å±‚ä¸€å±‚åœ°é‡å äº†3ä¸ª3x3çš„å·ç§¯å±‚ï¼ˆå±‚ä¸å±‚ä¹‹é—´æœ‰éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼‰ã€‚åœ¨è¿™ä¸ªæ’åˆ—ä¸‹ï¼Œç¬¬ä¸€ä¸ªå·ç§¯å±‚ä¸­çš„æ¯ä¸ªç¥ç»å…ƒéƒ½å¯¹è¾“å…¥æ•°æ®ä½“æœ‰ä¸€ä¸ª3x3çš„è§†é‡ã€‚ç¬¬äºŒä¸ªå·ç§¯å±‚ä¸Šçš„ç¥ç»å…ƒå¯¹ç¬¬ä¸€ä¸ªå·ç§¯å±‚æœ‰ä¸€ä¸ª3x3çš„è§†é‡ï¼Œä¹Ÿå°±æ˜¯å¯¹è¾“å…¥æ•°æ®ä½“æœ‰5x5çš„è§†é‡ã€‚åŒæ ·ï¼Œåœ¨ç¬¬ä¸‰ä¸ªå·ç§¯å±‚ä¸Šçš„ç¥ç»å…ƒå¯¹ç¬¬äºŒä¸ªå·ç§¯å±‚æœ‰3x3çš„è§†é‡ï¼Œä¹Ÿå°±æ˜¯å¯¹è¾“å…¥æ•°æ®ä½“æœ‰7x7çš„è§†é‡ã€‚å‡è®¾ä¸é‡‡ç”¨è¿™3ä¸ª3x3çš„å·ç§¯å±‚ï¼ŒäºŒæ˜¯ä½¿ç”¨ä¸€ä¸ªå•ç‹¬çš„æœ‰7x7çš„æ„Ÿå—é‡çš„å·ç§¯å±‚ï¼Œé‚£ä¹ˆæ‰€æœ‰ç¥ç»å…ƒçš„æ„Ÿå—é‡ä¹Ÿæ˜¯7x7ï¼Œä½†æ˜¯å°±æœ‰ä¸€äº›ç¼ºç‚¹ã€‚é¦–å…ˆï¼Œå¤šä¸ªå·ç§¯å±‚ä¸éçº¿æ€§çš„æ¿€æ´»å±‚äº¤æ›¿çš„ç»“æ„ï¼Œæ¯”å•ä¸€å·ç§¯å±‚çš„ç»“æ„æ›´èƒ½æå–å‡ºæ·±å±‚çš„æ›´å¥½çš„ç‰¹å¾ã€‚å…¶æ¬¡ï¼Œå‡è®¾æ‰€æœ‰çš„æ•°æ®æœ‰Cä¸ªé€šé“ï¼Œé‚£ä¹ˆå•ç‹¬çš„7x7å·ç§¯å±‚å°†ä¼šåŒ…å«$C\times (7\times 7\times C)=49C^2$ä¸ªå‚æ•°ï¼Œè€Œ3ä¸ª3x3çš„å·ç§¯å±‚çš„ç»„åˆä»…æœ‰$3\times (C\times (3\times 3\times C))=27C^2$ä¸ªå‚æ•°ã€‚ç›´è§‚è¯´æ¥ï¼Œæœ€å¥½é€‰æ‹©å¸¦æœ‰å°æ»¤æ³¢å™¨çš„å·ç§¯å±‚ç»„åˆï¼Œè€Œä¸æ˜¯ç”¨ä¸€ä¸ªå¸¦æœ‰å¤§çš„æ»¤æ³¢å™¨çš„å·ç§¯å±‚ã€‚å‰è€…å¯ä»¥è¡¨è¾¾å‡ºè¾“å…¥æ•°æ®ä¸­æ›´å¤šä¸ªå¼ºåŠ›ç‰¹å¾ï¼Œä½¿ç”¨çš„å‚æ•°ä¹Ÿæ›´å°‘ã€‚å”¯ä¸€çš„ä¸è¶³æ˜¯ï¼Œåœ¨è¿›è¡Œåå‘ä¼ æ’­æ—¶ï¼Œä¸­é—´çš„å·ç§¯å±‚å¯èƒ½ä¼šå¯¼è‡´å ç”¨æ›´å¤šçš„å†…å­˜ã€‚]]></content>
      <categories>
        <category>cs231n</category>
      </categories>
      <tags>
        <tag>cs231n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BeautyGAN: Instance-level Facial Makeup Transfer with Deep]]></title>
    <url>%2F2018%2F11%2F14%2FBeautyGAN-Instance-level-Facial-Makeup-Transfer-with-Deep.html%2F</url>
    <content type="text"><![CDATA[BeautyGAN åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„å®ä¾‹çº§é¢éƒ¨åŒ–å¦†è½¬ç§» ECCV2018 åˆ˜æ€ç»„ä¸€ä¸ªå­¦ç”Ÿåšçš„ ä¼ ç»Ÿçš„åŒ–å¦†è½¬æ¢ï¼Œéœ€è¦ç”¨æˆ·äº‹å®çš„äº¤äº’ï¼Œåªæœ‰å›ºå®šçš„å‡ ä¸ªå¦†å®¹ï¼Œä½†æ˜¯å¦‚æœæ˜æ˜Ÿæœ‰ä¸€ä¸ªå¾ˆå¥½çœ‹çš„å¦†å®¹ï¼Œæƒ³è¯•è¯•æ€ä¹ˆåŠï¼Œè¿™ç¯‡æ–‡ç« å°±åšçš„åœ¨éå¯¹ç§°ç½‘ç»œä¸Šï¼Œå®ç°å®ä¾‹çº§çš„åŒ–å¦†è½¬æ¢ï¼Œè¾“å…¥ä¸€ä¸ªç´ é¢œ+ç›®æ ‡åŒ–å¦†ç…§ç‰‡ï¼Œè¾“å‡ºåŒ–å¦†åçš„ç»“æœå›¾ç‰‡ã€‚ è´¡çŒ®1ï¼‰æˆ‘ä»¬é€šè¿‡åŒé‡è¾“å…¥/è¾“å‡ºç”Ÿæˆå¯¹æŠ—ç½‘ç»œå®ç°è‡ªåŠ¨åŒ–å¦†è½¬ç§»ã€‚ å®éªŒè¡¨æ˜äº†è½¬ç§»ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸”ç”Ÿæˆçš„ç»“æœæ¯”æœ€å…ˆè¿›çš„æ–¹æ³•å…·æœ‰æ›´é«˜çš„è´¨é‡ã€‚ï¼ˆ2ï¼‰æˆ‘ä»¬é€šè¿‡åœ¨å±€éƒ¨åŒºåŸŸæˆåŠŸåº”ç”¨åƒç´ çº§ç›´æ–¹å›¾æŸå¤±æ¥å®ç°å®ä¾‹çº§æ ·å¼è½¬æ¢ã€‚ è¿™ç§å®ä¾‹çº§è½¬ç§»æ–¹æ³•å¯ä»¥å¾ˆå®¹æ˜“åœ°æ¨å¹¿åˆ°å…¶ä»–å›¾åƒè½¬æ¢ä»»åŠ¡ï¼Œä¾‹å¦‚ç”¨äºå¤´åƒè‚–åƒçš„æ ·å¼è½¬ç§»ï¼Œå›¾åƒå±æ€§è½¬ç§»ç­‰ã€‚ï¼ˆ3ï¼‰å»ºç«‹äº†ä¸€ä¸ªåŒ…å«3834å¼ å›¾åƒçš„æ–°åŒ–å¦†æ•°æ®é›† ç»“æ„ å¦‚å›¾æ‰€ç¤º ç½‘ç»œç”±ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œä¸¤ä¸ªé‰´åˆ«å™¨æ„æˆ $I_{src}$è¡¨ç¤ºsource imageï¼Œæ˜¯ç´ é¢œå›¾ç‰‡ï¼Œæˆ–è€…ä¸ºAå›¾ç‰‡ $I_{ref}$è¡¨ç¤ºreference imageï¼Œæ˜¯ç›®æ ‡å¦†å®¹å›¾ç‰‡ï¼Œæˆ–è€…ä¸ºBå›¾ç‰‡ ä¸¤å¼ å›¾ç‰‡ä¸€èµ·è¾“å…¥ç”Ÿæˆå™¨ï¼Œå…ˆç»è¿‡å•ç‹¬çš„å‡ å±‚CNNç½‘ç»œï¼Œç„¶åç»è¿‡å…±ç”¨çš„æ·±åº¦æ®‹å·®ç½‘ç»œï¼Œæœ€åå†åˆ†åˆ«ç»è¿‡åå·ç§¯è¾“å‡ºä¸¤å¼ å›¾ç‰‡ $I_{src}^{B}$è¡¨ç¤ºåŒ–äº† Bå›¾ç‰‡å¦†çš„Aå›¾ç‰‡ $I_{ref}^{A}$è¡¨ç¤ºå»æ‰äº†å¦†ï¼Œå˜æˆç´ é¢œçš„Bå›¾ç‰‡ ç„¶å$I_{src}^{B}$å’Œ$I_{ref}$æ˜¯åŒ–äº†ç›¸åŒå¦†çš„å›¾ç‰‡ï¼Œæ”¾å…¥é‰´åˆ«å™¨$D_{B}$ä¸­è¿›è¡Œè®­ç»ƒ $I_{ref}^{A}$å’Œ$I_{src}$éƒ½æ˜¯ç´ é¢œå›¾ç‰‡ï¼Œæ”¾å…¥é‰´åˆ«å™¨$D_{A}$ä¸­è¿›è¡Œè®­ç»ƒ æŸå¤±å‡½æ•°1.é‰´åˆ«å™¨$D_{B}$å’Œé‰´åˆ«å™¨$D_{A}$å¤„æ˜¯ä¸¤ä¸ªä¼ ç»Ÿçš„GANæŸå¤±å‡½æ•° 2.ç”Ÿæˆå™¨æŸå¤±å‡½æ•°ç”±å››é¡¹æ„æˆ $L_{G} = Î±L_{adv} + Î²L_{cyc} +Î³L_{per} + L_{makeup}$ $L_{cyc}$å’Œ$L_{per}$ä¿è¯ç»è¿‡åŒ–å¦†ï¼Œè¿˜æ˜¯åŸæ¥çš„äººè„¸æ¨¡æ ·ï¼ŒåŒæ—¶å›¾ç‰‡èƒŒæ™¯ä¸å˜ $L_{makeup}$æŸå¤±ä¿è¯å¦†å®¹è½¬ç§» $L_{adv}$ç¬¬ä¸€é¡¹æ˜¯é‰´åˆ«å™¨å¯¹åº”çš„ç”Ÿæˆå™¨æŸå¤±ï¼Œä½¿ç”Ÿæˆçš„å›¾ç‰‡é€¼çœŸï¼Œé‰´åˆ«å™¨æ— æ³•é‰´åˆ« $L_{cyc}$æ˜¯å¾ªç¯é‡æ„æŸå¤±ï¼Œç±»ä¼¼cycleGANï¼Œ$I_{src}^{B}$å’Œ$I_{ref}^{A}$å†æ¬¡è¾“å…¥ç”Ÿæˆå™¨ï¼Œå¾—åˆ°$I_{src}^{rec}$å’Œ$I_{ref}^{rec}$ï¼Œå’ŒåŸè¾“å…¥å›¾ç‰‡ç®—é‡æ„æŸå¤±ï¼ŒL1æˆ–è€…L2ã€‚ $L_{per}$æ˜¯perceptual lossï¼Œå…¶å®å°±æ˜¯æé£é£é£æ ¼è½¬æ¢é‚£ç¯‡æ–‡ç« ä¸­æåˆ°çš„å†…å®¹æŸå¤±content lossï¼Œæå–VGG16ç½‘ç»œä¸­çš„relu_4_1å±‚ $L_{makeup}$æ˜¯ç›´æ–¹å›¾æŸå¤±Histogram lossï¼Œä¸èƒ½åœ¨å…¨å±€ç®—è¿™ä¸ªæŸå¤±ï¼Œå› ä¸ºå¦†å®¹åªåŒ…æ‹¬ çœ¼å½±ï¼Œå”‡è†ï¼Œç²‰åº•ã€‚è·Ÿå¤´å‘èƒŒæ™¯ç­‰æ— å…³ã€‚æ‰€ä»¥ç”¨åˆ«äººé¢„è®­ç»ƒå¥½çš„ç½‘ç»œï¼Œè¾“å…¥äººè„¸å›¾ç‰‡ï¼Œç›´æ¥å¾—åˆ°çœ¼ï¼Œå˜´ï¼Œçš®è‚¤ä¸‰ä¸ªä½ç½®çš„maskï¼Œåˆ†åˆ«è®¡ç®—ä¸‰ä¸ªä½ç½®çš„ç›´æ–¹å›¾æŸå¤±ï¼Œç„¶åæƒ³åŠ å°±æ˜¯æ€»ç›´æ–¹å›¾æŸå¤±ï¼Œå¦‚ç»“æ„å›¾æ‰€ç¤ºã€‚ åŒ–å¦†åœ¨å›¾åƒä¸Šå…¶å®å¯ä»¥çœ‹åšæ˜¯é¢œè‰²çš„æ·±æµ…ç­‰çš„å˜åŒ–ï¼Œæ‰€ä»¥ç”¨ç›´æ–¹å›¾æŸå¤±ï¼Œç›´æ–¹å›¾åŒ¹é…å°±æ˜¯ï¼Œæœ‰æ—¶éœ€è¦å˜æ¢ç›´æ–¹å›¾ä½¿ä¹‹æˆä¸ºæŸä¸ªç‰¹å®šçš„å½¢çŠ¶,ä»è€Œæœ‰é€‰æ‹©åœ°å¢å¼ºæŸä¸ªç°åº¦å€¼èŒƒå›´å†…çš„å¯¹æ¯”åº¦ ç›´æ–¹å›¾æŸå¤±çš„ç†è®ºç†è§£å‚è€ƒï¼šhttps://blog.csdn.net/majinlei121/article/details/46482615]]></content>
      <categories>
        <category>ç™¾ç¯‡è®ºæ–‡é˜…è¯»è®¡åˆ’</category>
      </categories>
      <tags>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cs231n Lecture3 Loss Functions and Optimization]]></title>
    <url>%2F2018%2F11%2F10%2Fcs231n-Lecture3-Loss-Functions-and-Optimization.html%2F</url>
    <content type="text"><![CDATA[æŸå¤±å‡½æ•°(softmaxå’ŒSVM) æœ€ä¼˜åŒ–ï¼ˆmini batchï¼‰ 1.æŸå¤±å‡½æ•°å¤šç±»æ”¯æŒå‘é‡æœºæŸå¤± Multiclass Support Vector Machine LossSVMçš„æŸå¤±å‡½æ•°æƒ³è¦SVMåœ¨æ­£ç¡®åˆ†ç±»ä¸Šçš„å¾—åˆ†å§‹ç»ˆæ¯”ä¸æ­£ç¡®åˆ†ç±»ä¸Šçš„å¾—åˆ†é«˜ï¼Œè€Œä¸”è¦è‡³å°‘é«˜å‡º$\Delta$ï¼Œå¦‚æœä¸æ»¡è¶³è¿™ç‚¹ï¼Œå°±å¼€å§‹è®¡ç®—æŸå¤±å€¼ã€‚ æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰ èƒ½å¤Ÿæ»¡è¶³æ­£ç¡®åˆ†ç±»çš„æƒé‡Wä¸æ˜¯å”¯ä¸€çš„ã€‚æ¯”å¦‚Wä¹˜ä»¥å¸¸æ•°ï¼Œæ‰€ä»¥åŠ ä¸Šæƒé‡æ­£åˆ™åŒ–æƒ©ç½šï¼ˆL2ï¼‰ã€‚åŒæ—¶å¯¹å¤§æ•°å€¼æƒé‡è¿›è¡Œæƒ©ç½šï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ï¼Œé¿å…è¿‡æ‹Ÿåˆã€‚ svmçš„æŸå¤±å‡½æ•° $L=\frac{1}{N}\sum_i\sum_{j\not=y_i}[max(0,f(x_i;W)_j-f(x_i;W)_{y_i}+\Delta)]+\lambda \sum_k \sum_l W^2_{k,l}$ Softmaxåˆ†ç±»å™¨SVMå’Œsoftmaxæ˜¯æœ€å¸¸ç”¨çš„ä¸¤ä¸ªåˆ†ç±»å™¨ã€‚ åœ¨Softmaxåˆ†ç±»å™¨ä¸­ï¼Œå‡½æ•°æ˜ å°„$f(x_i;W)=Wx_i$ä¿æŒä¸å˜ï¼Œä½†å°†è¿™äº›è¯„åˆ†å€¼è§†ä¸ºæ¯ä¸ªåˆ†ç±»çš„æœªå½’ä¸€åŒ–çš„å¯¹æ•°æ¦‚ç‡ï¼Œä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼ˆcross-entropy lossï¼‰ã€‚å…¬å¼å¦‚ä¸‹ï¼š $$\displaystyle Li=-log(\frac{e^{f_{y_i}}}{\sum_je^{f_j}})$$ $f_j(z)=\frac{e^{z_j}}{\sum_ke^{z_k}}$è¢«ç§°ä½œsoftmax å‡½æ•° é’ˆå¯¹ä¸€ä¸ªæ•°æ®ç‚¹ï¼ŒSVMå’ŒSoftmaxåˆ†ç±»å™¨çš„ä¸åŒå¤„ç†æ–¹å¼çš„ä¾‹å­ã€‚ä¸¤ä¸ªåˆ†ç±»å™¨éƒ½è®¡ç®—äº†åŒæ ·çš„åˆ†å€¼å‘é‡fï¼ˆæœ¬èŠ‚ä¸­æ˜¯é€šè¿‡çŸ©é˜µä¹˜æ¥å®ç°ï¼‰ã€‚ä¸åŒä¹‹å¤„åœ¨äºå¯¹fä¸­åˆ†å€¼çš„è§£é‡Šï¼šSVMåˆ†ç±»å™¨å°†å®ƒä»¬çœ‹åšæ˜¯åˆ†ç±»è¯„åˆ†ï¼Œå®ƒçš„æŸå¤±å‡½æ•°é¼“åŠ±æ­£ç¡®çš„åˆ†ç±»ï¼ˆæœ¬ä¾‹ä¸­æ˜¯è“è‰²çš„ç±»åˆ«2ï¼‰çš„åˆ†å€¼æ¯”å…¶ä»–åˆ†ç±»çš„åˆ†å€¼é«˜å‡ºè‡³å°‘ä¸€ä¸ªè¾¹ç•Œå€¼ã€‚Softmaxåˆ†ç±»å™¨å°†è¿™äº›æ•°å€¼çœ‹åšæ˜¯æ¯ä¸ªåˆ†ç±»æ²¡æœ‰å½’ä¸€åŒ–çš„å¯¹æ•°æ¦‚ç‡ï¼Œé¼“åŠ±æ­£ç¡®åˆ†ç±»çš„å½’ä¸€åŒ–çš„å¯¹æ•°æ¦‚ç‡å˜é«˜ï¼Œå…¶ä½™çš„å˜ä½ã€‚SVMçš„æœ€ç»ˆçš„æŸå¤±å€¼æ˜¯1.58ï¼ŒSoftmaxçš„æœ€ç»ˆçš„æŸå¤±å€¼æ˜¯0.452ï¼Œä½†è¦æ³¨æ„è¿™ä¸¤ä¸ªæ•°å€¼æ²¡æœ‰å¯æ¯”æ€§ã€‚åªåœ¨ç»™å®šåŒæ ·æ•°æ®ï¼Œåœ¨åŒæ ·çš„åˆ†ç±»å™¨çš„æŸå¤±å€¼è®¡ç®—ä¸­ï¼Œå®ƒä»¬æ‰æœ‰æ„ä¹‰ã€‚ 2.æœ€ä¼˜åŒ–æœ€ä¼˜åŒ– Optimization æŸå¤±å‡½æ•°å¯ä»¥é‡åŒ–æŸä¸ªå…·ä½“æƒé‡é›†Wçš„è´¨é‡ã€‚è€Œæœ€ä¼˜åŒ–çš„ç›®æ ‡å°±æ˜¯æ‰¾åˆ°èƒ½å¤Ÿæœ€å°åŒ–æŸå¤±å‡½æ•°å€¼çš„W ç­–ç•¥#1ï¼šä¸€ä¸ªå·®åŠ²çš„åˆå§‹æ–¹æ¡ˆï¼šéšæœºæœç´¢ ç­–ç•¥#2ï¼šéšæœºæœ¬åœ°æœç´¢ ç­–ç•¥#3ï¼šè·Ÿéšæ¢¯åº¦ åœ¨æ¢¯åº¦è´Ÿæ–¹å‘ä¸Šæ›´æ–°ï¼Œè¿™æ˜¯å› ä¸ºæˆ‘ä»¬å¸Œæœ›æŸå¤±å‡½æ•°å€¼æ˜¯é™ä½è€Œä¸æ˜¯å‡é«˜ å°æ‰¹é‡æ•°æ®æ¢¯åº¦ä¸‹é™ï¼ˆMini-batch gradient descentï¼‰å°æ‰¹é‡æ•°æ®ç­–ç•¥æœ‰ä¸ªæç«¯æƒ…å†µï¼Œé‚£å°±æ˜¯æ¯ä¸ªæ‰¹é‡ä¸­åªæœ‰1ä¸ªæ•°æ®æ ·æœ¬ï¼Œè¿™ç§ç­–ç•¥è¢«ç§°ä¸ºéšæœºæ¢¯åº¦ä¸‹é™ï¼ˆStochastic Gradient Descent ç®€ç§°SGDï¼‰ï¼Œæœ‰æ—¶å€™ä¹Ÿè¢«ç§°ä¸ºåœ¨çº¿æ¢¯åº¦ä¸‹é™ã€‚è¿™ç§ç­–ç•¥åœ¨å®é™…æƒ…å†µä¸­ç›¸å¯¹å°‘è§ï¼Œå› ä¸ºå‘é‡åŒ–æ“ä½œçš„ä»£ç ä¸€æ¬¡è®¡ç®—100ä¸ªæ•°æ® æ¯”100æ¬¡è®¡ç®—1ä¸ªæ•°æ®è¦é«˜æ•ˆå¾ˆå¤šã€‚å³ä½¿SGDåœ¨æŠ€æœ¯ä¸Šæ˜¯æŒ‡æ¯æ¬¡ä½¿ç”¨1ä¸ªæ•°æ®æ¥è®¡ç®—æ¢¯åº¦ï¼Œä½ è¿˜æ˜¯ä¼šå¬åˆ°äººä»¬ä½¿ç”¨SGDæ¥æŒ‡ä»£å°æ‰¹é‡æ•°æ®æ¢¯åº¦ä¸‹é™ï¼ˆæˆ–è€…ç”¨MGDæ¥æŒ‡ä»£å°æ‰¹é‡æ•°æ®æ¢¯åº¦ä¸‹é™ï¼Œè€ŒBGDæ¥æŒ‡ä»£åˆ™ç›¸å¯¹å°‘è§ï¼‰ã€‚å°æ‰¹é‡æ•°æ®çš„å¤§å°æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œä½†æ˜¯ä¸€èˆ¬å¹¶ä¸éœ€è¦é€šè¿‡äº¤å‰éªŒè¯æ¥è°ƒå‚ã€‚å®ƒä¸€èˆ¬ç”±å­˜å‚¨å™¨çš„é™åˆ¶æ¥å†³å®šçš„ï¼Œæˆ–è€…å¹²è„†è®¾ç½®ä¸ºåŒæ ·å¤§å°ï¼Œæ¯”å¦‚32ï¼Œ64ï¼Œ128ç­‰ã€‚ä¹‹æ‰€ä»¥ä½¿ç”¨2çš„æŒ‡æ•°ï¼Œæ˜¯å› ä¸ºåœ¨å®é™…ä¸­è®¸å¤šå‘é‡åŒ–æ“ä½œå®ç°çš„æ—¶å€™ï¼Œå¦‚æœè¾“å…¥æ•°æ®é‡æ˜¯2çš„å€æ•°ï¼Œé‚£ä¹ˆè¿ç®—æ›´å¿«ã€‚ æ€»ç»“ï¼š æ­¥é•¿(å­¦ä¹ ç‡)éœ€è¦ç”¨éªŒè¯é›†æ‰¾åˆ°æœ€ä¼˜è§£ batch_sizeä¸€èˆ¬ç”±GPUå¤§å°å†³å®šï¼Œä½†æ˜¯è®¾ç½®æˆ2çš„æŒ‡æ•°ï¼Œè¿™æ ·ä¼šè¿ç®—å¿«ä¸€ç‚¹]]></content>
      <categories>
        <category>cs231n</category>
      </categories>
      <tags>
        <tag>cs231n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cs231n Lecture2 Image Classification]]></title>
    <url>%2F2018%2F11%2F07%2Fcs231n-Lecture2-Image-Classification.html%2F</url>
    <content type="text"><![CDATA[1.æ•°æ®é©±åŠ¨ï¼šå›¾åƒåˆ†ç±»é¢å¯¹çš„å›°éš¾æŒ‘æˆ˜æ˜¯è§†è§’å˜åŒ–ï¼Œå¤§å°å˜åŒ–ï¼Œå½¢å˜ï¼Œé®æŒ¡ï¼Œå…‰ç…§æ¡ä»¶ï¼ŒèƒŒæ™¯å¹²æ‰°ï¼Œç±»å†…å·®å¼‚ã€‚ Nearest Neighboråˆ†ç±»å™¨åœ¨CIFAR-10æ•°æ®é›†ä¸Šï¼Œæ€»å…±6Wå¼ å›¾ç‰‡ï¼Œæœ‰10ç±»ã€‚32Ã—32Ã—3 5Wåšè®­ç»ƒé›†ï¼Œ1Wåšæµ‹è¯•é›†ã€‚æ¯å¼ æµ‹è¯•å›¾ç‰‡å±äºå“ªä¸€ç±»ï¼Œå°±æ˜¯ç›´æ¥è®¡ç®—ä¸¤å¼ å›¾ç‰‡çš„æ‰€æœ‰åƒç´ çš„å·®å€¼ï¼Œä¸€ä¸ªæµ‹è¯•å›¾ç‰‡å’Œ5Wä¸ªè®­ç»ƒé›†å›¾ç‰‡åˆ†åˆ«æ¯”è¾ƒï¼Œæœ€åå“ªä¸ªå·®å€¼å°å°±æ˜¯å’Œè¿™ä¸ªå›¾ç‰‡ä¸€ç±»ã€‚ L1 (Manhattan)distance L2 (Euclidean)distance ä½ ä¼šå‘ç°å‡†ç¡®ç‡èƒ½è¾¾åˆ°38.6%ã€‚è¿™æ¯”éšæœºçŒœæµ‹çš„10%è¦å¥½ï¼Œä½†æ˜¯æ¯”äººç±»è¯†åˆ«çš„æ°´å¹³ï¼ˆæ®ç ”ç©¶æ¨æµ‹æ˜¯94%ï¼‰å’Œå·ç§¯ç¥ç»ç½‘ç»œèƒ½è¾¾åˆ°çš„95%è¿˜æ˜¯å·®å¤šäº† k - Nearest Neighbor Classifier(KNN)ä¸æ‰¾æœ€è¿‘çš„ä¸€ä¸ªå›¾ç‰‡çš„æ ‡ç­¾ä½œä¸ºè®°è¿‡ï¼Œæ‰¾Kä¸ªå›¾ç‰‡ï¼Œç„¶åæŠ•ç¥¨å†³å®šå›¾ç‰‡æ ‡ç­¾ ç”¨äºè¶…å‚æ•°è°ƒä¼˜çš„éªŒè¯é›† è¿™é‡Œæœ‰Kå’Œwhich distance ä¸¤ä¸ªè¶…å‚æ•°éœ€è¦ç¡®å®šï¼Œä¸è¦ç”¨ä½ çš„test dataæ¥è°ƒä¼˜æ‰¾åˆ°è¶…å‚æ•° åœ¨è®­ç»ƒé›†ä¸­ï¼Œä½¿ç”¨äº¤å‰å¾ªç¯éªŒè¯ï¼Œåˆ†æˆ5ä»½ï¼Œç”¨4ä»½åšè®­ç»ƒé›†ï¼Œä¸€ä»½åšéªŒè¯é›† ä¸€æ—¦æ‰¾åˆ°æœ€ä¼˜çš„è¶…å‚æ•°ï¼Œå°±è®©ç®—æ³•ä»¥è¯¥å‚æ•°åœ¨æµ‹è¯•é›†è·‘ä¸”åªè·‘ä¸€æ¬¡ï¼Œå¹¶æ ¹æ®æµ‹è¯•ç»“æœè¯„ä»·ç®—æ³•ã€‚ å¯¹æœ€ä¼˜çš„è¶…å‚æ•°åšè®°å½•ã€‚è®°å½•æœ€ä¼˜å‚æ•°åï¼Œæ˜¯å¦åº”è¯¥è®©ä½¿ç”¨æœ€ä¼˜å‚æ•°çš„ç®—æ³•åœ¨å®Œæ•´çš„è®­ç»ƒé›†ä¸Šè¿è¡Œå¹¶å†æ¬¡è®­ç»ƒå‘¢ï¼Ÿå› ä¸ºå¦‚æœæŠŠéªŒè¯é›†é‡æ–°æ”¾å›åˆ°è®­ç»ƒé›†ä¸­ï¼ˆè‡ªç„¶è®­ç»ƒé›†çš„æ•°æ®é‡å°±åˆå˜å¤§äº†ï¼‰ï¼Œæœ‰å¯èƒ½æœ€ä¼˜å‚æ•°åˆä¼šæœ‰æ‰€å˜åŒ–ã€‚åœ¨å®è·µä¸­ï¼Œä¸è¦è¿™æ ·åšã€‚åƒä¸‡ä¸è¦åœ¨æœ€ç»ˆçš„åˆ†ç±»å™¨ä¸­ä½¿ç”¨éªŒè¯é›†æ•°æ®ï¼Œè¿™æ ·åšä¼šç ´åå¯¹äºæœ€ä¼˜å‚æ•°çš„ä¼°è®¡ã€‚ç›´æ¥ä½¿ç”¨æµ‹è¯•é›†æ¥æµ‹è¯•ç”¨æœ€ä¼˜å‚æ•°è®¾ç½®å¥½çš„æœ€ä¼˜æ¨¡å‹ï¼Œå¾—åˆ°æµ‹è¯•é›†æ•°æ®çš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œå¹¶ä»¥æ­¤ä½œä¸ºä½ çš„kNNåˆ†ç±»å™¨åœ¨è¯¥æ•°æ®ä¸Šçš„æ€§èƒ½è¡¨ç°ã€‚ Nearest Neighboråˆ†ç±»å™¨çš„ä¼˜åŠ£è€—æ—¶ï¼Œå›¾åƒæ˜¯é«˜ç»´çš„ã€‚ä¸”ç”¨L1å’ŒL2å¹¶ä¸å‡†ç¡®ã€‚ ä»…ä»…ä½¿ç”¨L1å’ŒL2èŒƒæ•°æ¥è¿›è¡Œåƒç´ æ¯”è¾ƒæ˜¯ä¸å¤Ÿçš„ï¼Œå›¾åƒæ›´å¤šçš„æ˜¯æŒ‰ç…§èƒŒæ™¯å’Œé¢œè‰²è¢«åˆ†ç±»ï¼Œè€Œä¸æ˜¯è¯­ä¹‰ä¸»ä½“åˆ†èº«ã€‚ 2.å‚æ•°æ–¹æ³•ï¼šçº¿æ€§åˆ†ç±»y = wx +b è¿˜æ˜¯åœ¨CIFAR-10è®­ç»ƒé›†ä¸Šï¼Œä¸€ä¸ªå•ç‹¬çš„çŸ©é˜µä¹˜æ³•Wxå°±å¯ä»¥é«˜æ•ˆåœ°å¹¶è¡Œè¯„ä¼°10ä¸ªä¸åŒçš„åˆ†ç±»å™¨ã€‚ ä»ä¸Šé¢å¯ä»¥çœ‹åˆ°ï¼ŒWçš„æ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªåˆ†ç±»ç±»åˆ«çš„åˆ†ç±»å™¨ã€‚å¯¹äºè¿™äº›æ•°å­—çš„å‡ ä½•è§£é‡Šæ˜¯ï¼šå¦‚æœæ”¹å˜å…¶ä¸­ä¸€è¡Œçš„æ•°å­—ï¼Œä¼šçœ‹è§åˆ†ç±»å™¨åœ¨ç©ºé—´ä¸­å¯¹åº”çš„ç›´çº¿å¼€å§‹å‘ç€ä¸åŒæ–¹å‘æ—‹è½¬ã€‚è€Œåå·®bï¼Œåˆ™å…è®¸åˆ†ç±»å™¨å¯¹åº”çš„ç›´çº¿å¹³ç§»ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¦‚æœæ²¡æœ‰åå·®ï¼Œæ— è®ºæƒé‡å¦‚ä½•ï¼Œåœ¨x_i=0æ—¶åˆ†ç±»åˆ†å€¼å§‹ç»ˆä¸º0ã€‚è¿™æ ·æ‰€æœ‰åˆ†ç±»å™¨çš„çº¿éƒ½ä¸å¾—ä¸ç©¿è¿‡åŸç‚¹ã€‚ å°†çº¿æ€§åˆ†ç±»å™¨çœ‹åšæ¨¡æ¿åŒ¹é…ï¼šå…³äºæƒé‡Wçš„å¦ä¸€ä¸ªè§£é‡Šæ˜¯å®ƒçš„æ¯ä¸€è¡Œå¯¹åº”ç€ä¸€ä¸ªåˆ†ç±»çš„æ¨¡æ¿ï¼ˆæœ‰æ—¶å€™ä¹Ÿå«ä½œåŸå‹ï¼‰ã€‚ä¸€å¼ å›¾åƒå¯¹åº”ä¸åŒåˆ†ç±»çš„å¾—åˆ†ï¼Œæ˜¯é€šè¿‡ä½¿ç”¨å†…ç§¯ï¼ˆä¹Ÿå«ç‚¹ç§¯ï¼‰æ¥æ¯”è¾ƒå›¾åƒå’Œæ¨¡æ¿ï¼Œç„¶åæ‰¾åˆ°å’Œå“ªä¸ªæ¨¡æ¿æœ€ç›¸ä¼¼ã€‚ä»è¿™ä¸ªè§’åº¦æ¥çœ‹ï¼Œçº¿æ€§åˆ†ç±»å™¨å°±æ˜¯åœ¨åˆ©ç”¨å­¦ä¹ åˆ°çš„æ¨¡æ¿ï¼Œé’ˆå¯¹å›¾åƒåšæ¨¡æ¿åŒ¹é…ã€‚ä»å¦ä¸€ä¸ªè§’åº¦æ¥çœ‹ï¼Œå¯ä»¥è®¤ä¸ºè¿˜æ˜¯åœ¨é«˜æ•ˆåœ°ä½¿ç”¨k-NNï¼Œä¸åŒçš„æ˜¯æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨æ‰€æœ‰çš„è®­ç»ƒé›†çš„å›¾åƒæ¥æ¯”è¾ƒï¼Œè€Œæ˜¯æ¯ä¸ªç±»åˆ«åªç”¨äº†ä¸€å¼ å›¾ç‰‡ï¼ˆè¿™å¼ å›¾ç‰‡æ˜¯æˆ‘ä»¬å­¦ä¹ åˆ°çš„ï¼Œè€Œä¸æ˜¯è®­ç»ƒé›†ä¸­çš„æŸä¸€å¼ ï¼‰ï¼Œè€Œä¸”æˆ‘ä»¬ä¼šä½¿ç”¨ï¼ˆè´Ÿï¼‰å†…ç§¯æ¥è®¡ç®—å‘é‡é—´çš„è·ç¦»ï¼Œè€Œä¸æ˜¯ä½¿ç”¨L1æˆ–è€…L2è·ç¦»ã€‚ å¯¹CIFAR-10çš„10ä¸ªç±»åˆ«çš„æƒé‡æ•°å€¼å¯è§†åŒ–ï¼Œå¯ä»¥çœ‹åˆ°å¦‚å›¾æ‰€ç¤ºã€‚ å¯ä»¥çœ‹åˆ°é©¬çš„æ¨¡æ¿çœ‹èµ·æ¥ä¼¼ä¹æ˜¯ä¸¤ä¸ªå¤´çš„é©¬ï¼Œè¿™æ˜¯å› ä¸ºè®­ç»ƒé›†ä¸­çš„é©¬çš„å›¾åƒä¸­é©¬å¤´æœå‘å„æœ‰å·¦å³é€ æˆçš„ã€‚çº¿æ€§åˆ†ç±»å™¨å°†è¿™ä¸¤ç§æƒ…å†µèåˆåˆ°ä¸€èµ·äº†ã€‚ç±»ä¼¼çš„ï¼Œæ±½è½¦çš„æ¨¡æ¿çœ‹èµ·æ¥ä¹Ÿæ˜¯å°†å‡ ä¸ªä¸åŒçš„æ¨¡å‹èåˆåˆ°äº†ä¸€ä¸ªæ¨¡æ¿ä¸­ï¼Œå¹¶ä»¥æ­¤æ¥åˆ†è¾¨ä¸åŒæ–¹å‘ä¸åŒé¢œè‰²çš„æ±½è½¦ã€‚è¿™ä¸ªæ¨¡æ¿ä¸Šçš„è½¦æ˜¯çº¢è‰²çš„ï¼Œè¿™æ˜¯å› ä¸ºCIFAR-10ä¸­è®­ç»ƒé›†çš„è½¦å¤§å¤šæ˜¯çº¢è‰²çš„ã€‚çº¿æ€§åˆ†ç±»å™¨åªæ‹Ÿåˆäº†ä¸€ä¸ªæ¨¡æ¿ï¼Œæ±‚äº†æ‰€æœ‰ç›¸å…³å›¾åƒç‰¹å¾çš„å‡å€¼ã€‚çº¿æ€§åˆ†ç±»å™¨å¯¹äºä¸åŒé¢œè‰²çš„è½¦çš„åˆ†ç±»èƒ½åŠ›æ˜¯å¾ˆå¼±çš„ï¼Œä½†æ˜¯åé¢å¯ä»¥çœ‹åˆ°ç¥ç»ç½‘ç»œæ˜¯å¯ä»¥å®Œæˆè¿™ä¸€ä»»åŠ¡çš„ã€‚ç¥ç»ç½‘ç»œå¯ä»¥åœ¨å®ƒçš„éšè—å±‚ä¸­å®ç°ä¸­é—´ç¥ç»å…ƒæ¥æ¢æµ‹ä¸åŒç§ç±»çš„è½¦ï¼ˆæ¯”å¦‚ç»¿è‰²è½¦å¤´å‘å·¦ï¼Œè“è‰²è½¦å¤´å‘å‰ç­‰ï¼‰ã€‚è€Œä¸‹ä¸€å±‚çš„ç¥ç»å…ƒé€šè¿‡è®¡ç®—ä¸åŒçš„æ±½è½¦æ¢æµ‹å™¨çš„æƒé‡å’Œï¼Œå°†è¿™äº›åˆå¹¶ä¸ºä¸€ä¸ªæ›´ç²¾ç¡®çš„æ±½è½¦åˆ†ç±»åˆ†å€¼ã€‚ 2017é›·é”‹ç½‘ http://ai.yanxishe.com/page/search 2016ç½‘æ˜“äº‘è§†é¢‘ï¼š https://study.163.com/course/courseLearn.htm?courseId=1003223001#/learn/video?lessonId=1003705493&amp;courseId=1003223001 è¯¾ä»¶åŸæ–‡ï¼šhttp://cs231n.github.io/classification/ è¯¾ä»¶ç¿»è¯‘ï¼šhttps://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit]]></content>
      <categories>
        <category>cs231n</category>
      </categories>
      <tags>
        <tag>cs231n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[é£æ ¼è½¬æ¢(äºŒ)ï¼šPerceptual Losses for Real-Time Style Transfer and Super-Resolution]]></title>
    <url>%2F2018%2F10%2F31%2F%E9%A3%8E%E6%A0%BC%E8%BD%AC%E6%8D%A2-%E4%BA%8C-%EF%BC%9APerceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution.html%2F</url>
    <content type="text"><![CDATA[åŸºäºæ„ŸçŸ¥æŸå¤±å‡½æ•°çš„å®æ—¶é£æ ¼è½¬æ¢å’Œè¶…åˆ†è¾¨ç‡é‡å»ºè®ºæ–‡åœ°å€ï¼š[1603.08155] Perceptual Losses for Real-Time Style Transfer and Super-Resolutionæœ¬æ–‡æ˜¯æé£é£åœ¨2016å¹´ECCVä¸Šå‘è¡¨çš„å®æ—¶é£æ ¼è½¬æ¢è®ºæ–‡ã€‚æå‡ºäº†perceptual lossï¼Œé£æ ¼è½¬æ¢åˆ†ä¸ºå•ä¸€å›¾ç‰‡å•ä¸€é£æ ¼ï¼Œå¤šå›¾ç‰‡å•ä¸€é£æ ¼ï¼Œå¤šå›¾ç‰‡å¤šé£æ ¼ï¼Œä»»æ„å›¾ç‰‡ä»»æ„é£æ ¼ã€‚A Neural Algorithm of Artistic Style è¿™ç¯‡æ–‡ç« æ¯æ¬¡éƒ½è¦é‡æ–°è®­ç»ƒå›¾ç‰‡ï¼Œå±äºå•ä¸€å›¾ç‰‡å•ä¸€é£æ ¼ã€‚è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œæ¯æ¬¡è¾“å…¥å›¾ç‰‡å®æ—¶çš„ç”Ÿæˆé£æ ¼å›¾ç‰‡ï¼Œä¹Ÿå°±æ˜¯æœ¬ç¯‡æ–‡ç« ï¼Œä¸ºå¤šå›¾ç‰‡å•ä¸€é£æ ¼ã€‚ 1. ç¿»è¯‘æ–‡ç« æ‘˜è¦æˆ‘ä»¬è€ƒè™‘çš„å›¾åƒè½¬æ¢çš„é—®é¢˜ï¼Œå³å°†ä¸€ä¸ªè¾“å…¥å›¾åƒå˜æ¢æˆä¸€ä¸ªè¾“å‡ºå›¾åƒã€‚æœ€è¿‘çƒ­é—¨çš„å›¾åƒè½¬æ¢çš„æ–¹æ³•é€šå¸¸æ˜¯è®­ç»ƒå‰é¦ˆå·ç§¯ç¥ç»ç½‘ç»œï¼Œå°†è¾“å‡ºå›¾åƒä¸åŸæœ¬å›¾åƒçš„é€åƒç´ å·®è·ä½œä¸ºæŸå¤±å‡½æ•°ã€‚å¹¶è¡Œçš„å·¥ä½œè¡¨æ˜ï¼Œé«˜è´¨é‡çš„å›¾åƒå¯ä»¥é€šè¿‡ç”¨é¢„è®­ç»ƒå¥½çš„ç½‘ç»œæå–é«˜çº§ç‰¹å¾ã€å®šä¹‰å¹¶ä¼˜åŒ–æ„ŸçŸ¥æŸå¤±å‡½æ•°æ¥äº§ç”Ÿã€‚æˆ‘ä»¬ç»„åˆäº†ä¸€ä¸‹è¿™ä¸¤ç§æ–¹æ³•å„è‡ªçš„ä¼˜åŠ¿ï¼Œæå‡ºé‡‡ç”¨æ„ŸçŸ¥æŸå¤±å‡½æ•°è®­ç»ƒå‰é¦ˆç½‘ç»œè¿›è¡Œå›¾åƒè½¬æ¢çš„ä»»åŠ¡ã€‚æœ¬æ–‡ç»™å‡ºäº†å›¾åƒé£æ ¼åŒ–çš„ç»“æœï¼Œè®­ç»ƒä¸€ä¸ªå‰é¦ˆç½‘ç»œå»è§£å†³å®æ—¶ä¼˜åŒ–é—®é¢˜ï¼ˆGatysç­‰äººæå‡ºçš„ï¼‰ï¼Œå’ŒåŸºäºæœ‰ä¼˜åŒ–çš„æ–¹æ³•å¯¹æ¯”ï¼Œæˆ‘ä»¬çš„ç½‘ç»œäº§ç”Ÿè´¨é‡ç›¸å½“çš„ç»“æœï¼Œå´èƒ½åšåˆ°ä¸‰ä¸ªæ•°é‡çº§çš„æé€Ÿã€‚æˆ‘ä»¬è¿˜å®éªŒäº†å•å›¾çš„è¶…åˆ†è¾¨ç‡é‡å»ºï¼ŒåŒæ ·é‡‡ç”¨æ„ŸçŸ¥æŸå¤±å‡½æ•°æ¥ä»£æ›¿æ±‚é€åƒç´ å·®è·çš„æŸå¤±å‡½æ•°. 2. æ¦‚è¿°å¦‚å›¾ï¼Œæå‡ºä¸€ä¸ªImage Transform Netï¼Œè¾“å…¥ä¸º $x$ è¾“å‡ºä¸ºé£æ ¼å›¾ç‰‡ï¼Œè¾“å‡ºä¸º $\widehat{y}$ç»“æœå›¾ç‰‡ï¼Œåé¢ç´§è·Ÿä¸€ä¸ªä¸è®­ç»ƒå¥½çš„VGG-16ç½‘ç»œä½œä¸ºLoss Networkï¼Œè¾“å…¥ä¸ºé£æ ¼å›¾ç‰‡$ y_{s}$ (ä¸å˜)å’Œå†…å®¹å›¾ç‰‡$ y_{c}$ (è®­ç»ƒé›†ä¸­è¯»ä¸ªå†…å®¹å›¾ç‰‡)ï¼Œä½¿ç”¨å†…å®¹æŸå¤±å’Œé£æ ¼æŸå¤±çš„æƒé‡å’Œä½œä¸ºæ€»ä½“æŸå¤±ï¼Œä¿æŒLoss Networkå‚æ•°ä¸å˜ï¼Œæ›´æ–°Image Transform Netç½‘ç»œçš„å‚æ•°ã€‚ æœ€ç»ˆè®­ç»ƒæˆåŠŸåï¼Œå–å‡ºImage Transform Netï¼Œè¾“å…¥ä»»æ„å†…å®¹å›¾ç‰‡ï¼Œè¾“å‡ºå°±æ˜¯é£æ ¼è½¬æ¢åçš„ç»“æœã€‚å¤šå›¾ç‰‡å•ä¸€é£æ ¼ã€‚ 3. Image Transform Netâ€‹ Image Transform Netçš„è¾“å…¥æ˜¯è¦è½¬æ¢çš„å›¾åƒï¼Œè¾“å‡ºæ˜¯è½¬æ¢å¥½çš„å›¾åƒï¼Œåœ¨æ¨¡å‹è®­ç»ƒå¥½ä¹‹åï¼Œç”¨äºç”Ÿæˆé£æ ¼è¿ç§»çš„åªæ˜¯è¿™éƒ¨åˆ†çš„ç½‘ç»œã€‚å…·ä½“è¿™éƒ¨åˆ†çš„ç½‘ç»œæ¨¡å‹å›¾å¦‚ä¸‹ã€‚ â€‹ å›¾åƒå˜æ¢ç½‘ç»œæ€»ä½“ä¹Ÿå±äºä¸€ä¸ªæ®‹å·®ç½‘ç»œã€‚ä¸€å…±æ˜¯ç”±3ä¸ªå·ç§¯å±‚ã€5ä¸ªæ®‹å·®å—ã€3ä¸ªå·ç§¯å±‚æ„æˆã€‚è¿™é‡Œæ²¡æœ‰ç”¨åˆ°æ± åŒ–ç­‰æ“ä½œè¿›è¡Œé‡‡ç”¨ï¼Œåœ¨å¼€å§‹å·ç§¯å±‚ä¸­ï¼ˆç¬¬äºŒå±‚ã€ç¬¬ä¸‰å±‚ï¼‰è¿›è¡Œäº†ä¸‹é‡‡æ ·ï¼Œåœ¨æœ€åçš„3ä¸ªå·ç§¯å±‚ä¸­è¿›è¡Œäº†ä¸Šé‡‡æ ·ï¼Œè¿™æ ·æœ€ç›´æ¥çš„å°±æ˜¯å‡å°‘äº†è®¡ç®—å¤æ‚åº¦ï¼Œå¦å¤–è¿˜æœ‰ä¸€ä¸ªå¥½å¤„æ˜¯æœ‰æ•ˆå—åŒºåŸŸå˜å¤§ï¼Œå·ç§¯ä¸‹é‡‡æ ·éƒ½ä¼šå¢å¤§æœ‰æ•ˆåŒºåŸŸã€‚5ä¸ªæ®‹å·®å—éƒ½æ˜¯ä½¿ç”¨ç›¸åŒä¸ªæ•°çš„ï¼ˆ128ï¼‰æ»¤é•œæ ¸ï¼Œæ¯ä¸ªæ®‹å·®å—ä¸­éƒ½æœ‰2ä¸ªå·ç§¯å±‚ï¼ˆ3*3æ ¸ï¼‰ï¼Œè¿™é‡Œçš„å·ç§¯å±‚ä¸­æ²¡æœ‰è¿›è¡Œæ ‡å‡†çš„0å¡«å……ï¼ˆpaddingï¼‰ï¼Œå› ä¸ºä½¿ç”¨0å¡«å……ä¼šä½¿ç”Ÿæˆå‡ºçš„å›¾åƒçš„è¾¹ç•Œå‡ºç°ä¸¥é‡ä¼ªå½±ã€‚ä¸ºäº†ä¿è¯è¾“å…¥è¾“å‡ºå›¾åƒå¤§å°ä¸æ”¹å˜ï¼Œåœ¨å›¾åƒåˆå§‹è¾“å…¥éƒ¨åˆ†åŠ å…¥äº†åå°„å¡«å……ã€‚ â€‹ è¿™é‡Œçš„æ®‹å·®ç½‘ç»œä¸æ˜¯ä½¿ç”¨ä½•å‡¯æ˜çš„æ®‹å·®ç½‘ç»œï¼ˆå·ç§¯ä¹‹åæ²¡æœ‰Reluï¼‰ï¼Œè€Œæ˜¯ä½¿ç”¨äº†Gross and Wilberçš„æ®‹å·®ç½‘ç»œ ã€‚åé¢è¿™ç§æ–¹æ³•éªŒè¯åœ¨å›¾åƒåˆ†ç±»ç®—æ³•ä¸Šé¢æ•ˆæœæ¯”è¾ƒå¥½ã€‚ 4. Perceptual Loss(1)Feature Reconstruction Loss ä½¿ç”¨ $\phi $æ¥è¡¨ç¤ºVGGç½‘ç»œ $j $è¡¨ç¤ºç½‘ç»œçš„ç¬¬jå±‚ã€‚ $C_{j}H_{j}W_{j} $è¡¨ç¤ºç¬¬$j$å±‚çš„feature_mapçš„size å°±æ˜¯VGGç½‘ç»œæŸä¸€å±‚çš„è¾“å‡ºï¼Œç»“æœå›¾ç‰‡å’Œå†…å®¹å›¾ç‰‡æ‰€æœ‰çš„featureç›¸å‡æ±‚å¹³æ–¹ï¼Œç„¶åæ±‚ä¸ªå¹³å‡ ï¼ˆ2ï¼‰Style Reconstruction Loss åŒGatysï¼Œå…ˆæ±‚GramçŸ©é˜µï¼Œå°±æ˜¯æŠŠ$\phi_{j}$reshpeä¸º$C_{j} \times H_{j}W_{j}$çš„çŸ©é˜µ$ \psi$ ï¼Œç„¶åå¾—åˆ° ä¹Ÿå°±æ˜¯è¯¥å±‚ç‰¹å¾çš„æœªé›¶å‡å€¼åŒ–çš„åæ–¹å·®ï¼Œè‹¥æ ·æœ¬å‡æ ‡å‡†åŒ–ä¸ºå‡å€¼ä¸º0ï¼Œé‚£ä¹ˆå†…ç§¯=åæ–¹å·®ã€‚è¿™å°†è·å¾—å“ªäº›featureå€¾å‘äºä¸€èµ·æ¿€æ´»(ç›¸å…³æ€§). åœ¨lossç½‘ç»œçš„æ¯ä¸€å±‚éƒ½æ±‚å‡ºGramçŸ©é˜µï¼Œç„¶åå¯¹åº”å±‚ä¹‹é—´è®¡ç®—æ¬§å¼è·ç¦»ï¼Œæœ€åå°†ä¸åŒå±‚çš„æ¬§æ°è·ç¦»ç›¸åŠ ï¼Œå¾—åˆ°æœ€åçš„é£æ ¼æŸå¤±ã€‚ å½“ç”Ÿæˆçš„å›¾ç‰‡å’Œé£æ ¼å›¾ç‰‡å°ºå¯¸ä¸ä¸€è‡´ï¼Œä¹Ÿèƒ½è®¡ç®—é£æ ¼æŸå¤±ï¼Œå› ä¸ºGramçŸ©é˜µå¤§å°ä¸€æ · (3)Total Variation Regularizationä¿è¯è¾“å‡ºå›¾åƒçš„ç©ºé—´å¹³æ»‘æ€§ï¼Œé¿å…é«˜é¢‘å™ªå£° $l_{TV} $ï¼Œè¯¥æŸå¤±å¤šç”¨äºå»å™ªå’Œå›¾ç‰‡é«˜æ¸…åŒ–ã€‚è¿™ä¸ªæŸå¤±çš„ç›¸å…³è§£é‡Šå¯ä»¥å‚è€ƒTotal variation denoising wikiè§£é‡ŠTotal Variation Denosing ä¸€ä¸ªåšå®¢ä¸­æ–‡çš„æ ¹æ®wikiçš„è‡ªå·±ç†è§£ 5.å®éªŒç»“æœ å›¾åƒé£æ ¼è½¬æ¢ä»»åŠ¡ä¸Šï¼Œé’ˆå¯¹ä¸åŒåˆ†è¾¨ç‡çš„å›¾åƒï¼ŒLosså€¼åœ¨Perceptual Loss(ours)å’ŒGatysçš„å¯¹æ¯”ã€‚å¯ä»¥çœ‹åˆ°ï¼Œä½¿ç”¨Perceptual Lossç›¸å½“äºåŸå§‹ç®—æ³•è¿­ä»£50åˆ°100æ¬¡ã€‚ å¯ä»¥çœ‹åˆ°é€Ÿåº¦å¯ä»¥æå‡å‡ ç™¾å€ 6. æ€»ç»“æ„Ÿè§‰æœ€å¤§è´¡çŒ®å°±æ˜¯å›¾åƒé£æ ¼è½¬æ¢çš„å®ç”¨åŒ–ï¼Œé€Ÿåº¦æå‡äº†å¾ˆå¤šä¸ªé‡çº§ã€‚ç„¶åè¿™ä¸ªæ¨¡å‹å¯ä»¥åšsuper-resolutionï¼Œç®€å•è¯´æ¥å°±æ˜¯ï¼Œè¾“å…¥$x$ ä¸ºæ¨¡ç³Šå›¾ç‰‡ï¼Œ$y_{c}$ä¸ºground-truthé«˜æ¸…å›¾ç‰‡ï¼Œ$y_{s}â€‹$ä¸ä½¿ç”¨ï¼Œlossè¦åŠ ä¸€ä¸ªPixel Lossï¼Œå°±æ˜¯è¾“å…¥è¾“å‡ºå›¾ç‰‡çš„æ¬§å‡ é‡Œå¾—è·ç¦»ï¼Œå…¶ä½™åŒç†è®­ç»ƒã€‚ å‚è€ƒ Perceptual Losses for Real-Time Style Transfer and Super-Resolution è®ºæ–‡ ç†è§£ [è¯‘] Perceptual Losses for Real-Time Style Transfer and Super-Resolutionï¼ˆStanford University æ„ŸçŸ¥æŸå¤±(Perceptual Losses)]]></content>
      <categories>
        <category>ç™¾ç¯‡è®ºæ–‡é˜…è¯»è®¡åˆ’</category>
      </categories>
      <tags>
        <tag>å›¾åƒé£æ ¼è½¬æ¢</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å›¾åƒé£æ ¼è½¬æ¢(ä¸€):A Neural Algorithm of Artistic Style]]></title>
    <url>%2F2018%2F10%2F30%2F%E9%A3%8E%E6%A0%BC%E8%BD%AC%E6%8D%A2-%E4%B8%80-%EF%BC%9AA-Neural-Algorithm-of-Artistic-Style.html%2F</url>
    <content type="text"><![CDATA[è®ºæ–‡åœ°å€ï¼šA Neural Algorithm of Artistic Styletensorflowä»£ç å®ç°ï¼šwoodrush/neural-art-tfæœ¬æ–‡ä»‹ç»Leon Gatysåœ¨2016å¹´åˆå¤§çƒ­çš„Style Transferç®—æ³•ï¼Œå‘è¡¨äºCVPR16 1. æ¦‚è¿°é¦–æ¬¡æå‡ºï¼Œä½¿ç”¨é¢„è®­ç»ƒå¥½çš„VGG19ç½‘ç»œï¼Œæå–å›¾åƒä¸åŒå±‚çº§çš„ç‰¹å¾ï¼Œåˆ†åˆ«ä½œä¸ºå›¾åƒçš„é£æ ¼ç‰¹å¾å’Œå†…å®¹ç‰¹å¾ï¼Œä»¥é«˜æ–¯å™ªå£°ä¸ºåˆå§‹è¾“å…¥å›¾åƒï¼Œå¤šæ¬¡æ‰§è¡Œå‰å‘/åå‘è¿­ä»£ä½¿ç”¨L-BFGSæ–¹æ³•ä¼˜åŒ–ï¼Œä¿æŒCNNçš„å‚æ•°ä¸å˜ï¼Œæ ¹æ®é£æ ¼æŸå¤±å’Œå†…å®¹æŸå¤±ï¼Œåå‘ä¼ æ’­æ›´æ–°å›¾ç‰‡ã€‚ä¿ç•™å†…å®¹å›¾ç‰‡çš„å†…å®¹å’Œå…¨å±€å¸ƒå±€çš„åŒæ—¶ï¼Œç”±é£æ ¼å›¾ç‰‡æä¾›é¢œè‰²å’Œå±€éƒ¨ç»“æ„ä¿¡æ¯ã€‚ 2. VGG19 å¦‚å›¾æ‰€ç¤ºä¸ºVGG19çš„ç½‘ç»œç»“æ„ï¼Œ16ä¸ªconvolutionalå’Œ5ä¸ªpooling layerï¼Œæœ¬æ–‡ä¸ä½¿ç”¨åé¢çš„å…¨è¿æ¥å±‚ã€‚ä½¿ç”¨average poolingä»£æ›¿max poolingï¼Œå¾—åˆ°æ›´å¥½çš„è§†è§‰æ•ˆæœã€‚å¦‚å›¾æ‰€ç¤ºï¼Œè¾“å…¥å†…å®¹å›¾ç‰‡å’Œé£æ ¼å›¾ç‰‡ï¼Œåœ¨abcdeäº”å±‚å¤„åˆ†åˆ«é‡æ„é£æ ¼å›¾ç‰‡å’Œå†…å®¹å›¾ç‰‡ã€‚å†…å®¹é‡æ„(a)conv1_1ï¼Œ(b) conv2_1ï¼Œ(c)conv3_1ï¼Œ(d)conv4_1ï¼Œ(e)conv5_1å¯ä»¥çœ‹å‡ºï¼Œåœ¨é«˜å±‚(dï¼Œe)ï¼Œç»†èŠ‚åƒç´ ä¿¡æ¯ä¸¢å¤±ï¼Œä½†å†…å®¹ä¿ç•™ï¼Œæ‰€ä»¥å†…å®¹ç‰¹å¾ä¸€èˆ¬ç”¨é«˜å±‚ã€‚ é£æ ¼é‡æ„(a)conv1_1ï¼Œ(b)conv1_1ï¼Œ conv2_1ï¼Œ(c)conv1_1ï¼Œ conv2_1ï¼Œconv3_1ï¼Œ(d)conv1_1ï¼Œ conv2_1ï¼Œconv3_1ï¼Œconv4_1ï¼Œ(e)conv1_1ï¼Œ conv2_1ï¼Œconv3_1ï¼Œconv4_1ï¼Œconv5_1æ„Ÿå—é‡å¤§å°å’Œç‰¹å¾å¤æ‚ç¨‹åº¦éšç€ç½‘ç»œå±‚çº§å¢å¤§ï¼Œå½“é£æ ¼è¡¨ç¤ºåŒ¹é…åˆ°ç½‘ç»œçš„æ›´é«˜å±‚æ—¶ï¼Œå±€éƒ¨å›¾åƒç»“æ„åœ¨è¶Šæ¥è¶Šå¤§çš„èŒƒå›´å†…åŒ¹é…ï¼Œä»è€Œå¯¼è‡´æ›´å¹³æ»‘å’Œæ›´è¿æ¥çš„è§†è§‰æ•ˆæœæ‰€ä»¥åœ¨æœ€ç»ˆçš„å®éªŒé‡Œå†…å®¹å±‚ - conv4_2é£æ ¼å±‚ - conv1_1, conv2_1, conv3_1, conv4_1, conv5_1 3. å†…å®¹æŸå¤±è¾“å…¥$x$ï¼Œåœ¨ç½‘ç»œä¸­æŸä¸€å±‚çš„è¾“å‡ºä¸ºï¼Œshapeå¯ä»¥è¡¨ç¤ºä¸º $$ N_{l}\times H \times W $$ ï¼Œreshapeä¸º $N_{l}\times M_{l}$ï¼Œå†™ä½œçŸ©é˜µ$F^{l}$ã€‚å…¶ä¸­$N_{l} $è¡¨ç¤ºè¯¥å±‚å·ç§¯æ ¸çš„ä¸ªæ•°ï¼Œ$ M_{l}$ æ˜¯è¯¥å±‚featureçš„é•¿åº¦ $H $å’Œå®½åº¦ $W$ çš„ä¹˜ç§¯ã€‚$ F_{ij}^{l} $è¡¨ç¤º$ l $å±‚ç¬¬$ i $ä¸ªfilterçš„ä½ç½®$ j$ ã€‚å†…å®¹æŸå¤±å°±æ˜¯åŸå§‹å›¾åƒå’Œç”Ÿæˆå›¾ç‰‡ï¼Œç»è¿‡VGG19ç½‘ç»œï¼Œåœ¨è¿™ä¸€å±‚çš„featureçš„SSE(å’Œæ–¹å·®ï¼Œè¯¯å·®å¹³æ–¹å’Œ)$$L_{content} = \frac{1}{2} \sum_{i,j}({F_{ij}^{l}-P_{ij}^{l}})^{2}$$ 4. é£æ ¼æŸå¤±å…ˆå¼•å…¥Gram matrix $G^{l}\in R^{ N_{l} \times N_{l}}$,ç”±çŸ©é˜µ$F^{l}$å’Œä»–è½¬ç½®çŸ©é˜µçš„ç›¸ä¹˜å¾—åˆ°ã€‚$ G_{ij}^{l}$ æ˜¯ç¬¬$ l $å±‚çš„feature$ i $å‘é‡å’Œfeature$ j $å‘é‡çš„å†…ç§¯ã€‚å¯ä»¥è®¤ä¸ºæ˜¯ä¸€ä¸ªæœªé›¶å‡å€¼åŒ–çš„åæ–¹å·®çŸ©é˜µï¼Œæ•è·çš„æ˜¯å“ªäº›featureæ˜¯è¶‹äºä¸€èµ·æ¿€æ´»çš„ä¿¡æ¯(å¦‚æœæ— æ³•ç†è§£ä¸ºä»€ä¹ˆå†…ç§¯=åæ–¹å·®ï¼Œå¯ä»¥çœ‹å‚è€ƒé‡Œçš„2å’Œ3ä¸¤ç¯‡åšæ–‡)ã€‚ $$E_{l} = \frac{1}{4N_{l}^{2}m_{l}^{2}}\sum_{i,j}{(G_{ij}^{l}-F_{ij}^{l})^{2}}$$ $$L_{style} = \sum_{l=0}^{L}{w_{l}E_{l}}$$ 5å±‚çš„æŸå¤±ç›¸åŠ ï¼Œä¹˜ä»¥å¯¹åº”æƒé‡ï¼Œé€šå¸¸ä¸º$ \frac{1}{5} $ å½“é£æ ¼å›¾ç‰‡å’Œå†…å®¹å›¾ç‰‡sizeä¸ä¸€æ ·ï¼Œè¿™ä¸ªé£æ ¼æŸå¤±å‡½æ•°ä¹Ÿå¯ä»¥ç”¨ï¼Œå› ä¸ºGramçŸ©é˜µshapeä¸€æ · 5. æ€»æŸå¤±$$L_{total} = \alpha L_{content} + \beta L_{style}$$ $\alpha$å’Œ$\beta$ è¡¨ç¤ºæƒé‡ï¼Œä¸å¯èƒ½å†…å®¹å’Œé£æ ¼å®Œç¾åŒ¹é…ï¼Œéœ€è¦è°ƒèŠ‚ã€‚æ–‡ç« ä¸­ä½¿ç”¨ $\frac{\alpha}{\beta} = 10^{-3}$ (B,C,D)æ›´åŠ æ³¨é‡åŸå›¾ï¼Œæˆ–è€…$10^{-4} $(E,F)ï¼Œæ›´åŠ è‰ºæœ¯åŒ–ã€‚ å‚è€ƒ ã€æ·±åº¦å­¦ä¹ ã€‘A neural algorithm of artistic styleç®—æ³•è¯¦è§£ ã€ç»Ÿè®¡å­¦ä¹ 1ã€‘æ–¹å·®ã€åæ–¹å·®ã€ç›¸å…³ç³»æ•°ä¸å‘é‡å†…ç§¯ - CSDNåšå®¢ CodingLabs - PCAçš„æ•°å­¦åŸç† åè®°æœ€è¿‘å¯¹é£æ ¼è½¬æ¢çš„æ–‡ç« æ¯”è¾ƒæ„Ÿå…´è¶£ï¼Œçœ‹äº†ä¸€ç¯‡NVIDAæœ€æ–°çš„ï¼Œç„¶åæœ‰äº›åœ°æ–¹ä¸æ˜ç™½ï¼Œå°±å¾ªç€å‚è€ƒæ–‡çŒ®çœ‹è¿‡æ¥ï¼Œè¿™ç‰‡æ˜¯æœ€ç»å…¸æœ€æ—©çš„ä¸€ç¯‡ï¼Œåç»­çœ‹å®Œå…¶ä»–å‡ ç¯‡ï¼Œä¹Ÿä¼šåšä¸ªç¬”è®°ï¼ŒåšæŒæ¯å‘¨è‡³å°‘ç²¾è¯»ä¸€ç¯‡æ–‡ç« å¹¶åšä¸ªç¬”è®°ã€‚]]></content>
      <categories>
        <category>ç™¾ç¯‡è®ºæ–‡é˜…è¯»è®¡åˆ’</category>
      </categories>
      <tags>
        <tag>å›¾åƒé£æ ¼è½¬æ¢</tag>
      </tags>
  </entry>
</search>
