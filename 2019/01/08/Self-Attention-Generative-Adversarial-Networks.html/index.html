<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="tiantianwahaha's blogs"><title>Self-Attention Generative Adversarial Networks | tiantianwahaha</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-132074008-1','auto');ga('send','pageview');
</script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Self-Attention Generative Adversarial Networks</h1><a id="logo" href="/.">tiantianwahaha</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Self-Attention Generative Adversarial Networks</h1><div class="post-meta">Jan 8, 2019<span> | </span><span class="category"><a href="/categories/百篇论文阅读计划/">百篇论文阅读计划</a></span></div><a class="disqus-comment-count" href="/2019/01/08/Self-Attention-Generative-Adversarial-Networks.html/#vcomment"><span class="valine-comment-count" data-xid="/2019/01/08/Self-Attention-Generative-Adversarial-Networks.html/"></span><span> Comment</span></a><div class="post-content"><p>自注意力生成对抗网络，首次把自注意力引入生成对抗网络图像生成中，结合使用谱归一化，得到了更好的图像质量。</p>
<p>Self-Attention Generative Adversarial Network(SAGAN)是一个注意力驱动，长范围，关联模型(attention-driven, long-range dependency modeling )。</p>
<h2 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h2><p>利用GAN进行图像合成，对于含有较少结构约束的类别（比如海洋、天空和地面等重纹理不重结构的）比较成功，而对于含有几何或结构模式的则容易失败，比如合成的狗的图像具有真实的毛但是很难认出脚。<br>可能的原因：CNN的卷积层具有感受野，因此利用CNN建模必须具有足够的深度才能在较大空间范围内建立图像不同区域的相关性，但这会导致更大的计算代价。 因此本文提出Self-attention GAN以平衡long range dependency modeling和计算代价的问题。</p>
<p>传统gan的问题:</p>
<ul>
<li>使用小的卷积核很难发现图像中的依赖关系</li>
<li>使用大的卷积核就丧失了卷积网络参数与计算的效率</li>
</ul>
<p>传统的GAN在生成高分辨率的细节时，是基于低分辨率的feature map中的某一个小部分的(卷积网络的特性)。而SAGAN是基于所有的特征点(all feature locations). 让每个像素点跟全局的所有像素点都有关系。</p>
<h2 id="注意力模型"><a href="#注意力模型" class="headerlink" title="注意力模型"></a>注意力模型</h2><p><img src="/2019/01/08/Self-Attention-Generative-Adversarial-Networks.html/self attention.png" alt=""></p>
<p><img src="/2019/01/08/Self-Attention-Generative-Adversarial-Networks.html/note.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hw_flatten</span><span class="params">(x)</span> :</span></span><br><span class="line">    <span class="keyword">return</span> tf.reshape(x, shape=[x.shape[<span class="number">0</span>], <span class="number">-1</span>, x.shape[<span class="number">-1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention</span><span class="params">(self, x, ch, sn=False, scope=<span class="string">'attention'</span>, reuse=False)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope, reuse=reuse):</span><br><span class="line">        f = conv(x, ch // <span class="number">8</span>, kernel=<span class="number">1</span>, stride=<span class="number">1</span>, sn=sn, scope=<span class="string">'f_conv'</span>) <span class="comment"># [bs, h, w, c']</span></span><br><span class="line">        g = conv(x, ch // <span class="number">8</span>, kernel=<span class="number">1</span>, stride=<span class="number">1</span>, sn=sn, scope=<span class="string">'g_conv'</span>) <span class="comment"># [bs, h, w, c']</span></span><br><span class="line">        h = conv(x, ch, kernel=<span class="number">1</span>, stride=<span class="number">1</span>, sn=sn, scope=<span class="string">'h_conv'</span>) <span class="comment"># [bs, h, w, c]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># N = h * w</span></span><br><span class="line">        s = tf.matmul(hw_flatten(g), hw_flatten(f), transpose_b=<span class="keyword">True</span>) <span class="comment"># # [bs, N, N]</span></span><br><span class="line"></span><br><span class="line">        beta = tf.nn.softmax(s, axis=<span class="number">-1</span>)  <span class="comment"># attention map</span></span><br><span class="line"></span><br><span class="line">        o = tf.matmul(beta, hw_flatten(h)) <span class="comment"># [bs, N, C]</span></span><br><span class="line">        gamma = tf.get_variable(<span class="string">"gamma"</span>, [<span class="number">1</span>], initializer=tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line"></span><br><span class="line">        o = tf.reshape(o, shape=x.shape) <span class="comment"># [bs, h, w, C]</span></span><br><span class="line">        x = gamma * o + x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>文章在生成器和鉴别器中都使用了这个attention module，同时讨论得出结论，在一些中层次或者高层次特征中使用attention层能够得到更好的效果。</p>
<p>文章使用了谱归一化和hinge loss来提升效果性能</p>
<p>效果与ACGAN和SNGAN做比较</p>
<p><img src="/2019/01/08/Self-Attention-Generative-Adversarial-Networks.html/table.png" alt=""></p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>Author: </strong>whiup</li><li class="post-copyright-link"><strong>Blog Link: </strong><a href="/2019/01/08/Self-Attention-Generative-Adversarial-Networks.html/">https://tiantianwahaha.github.io/2019/01/08/Self-Attention-Generative-Adversarial-Networks.html/</a></li><li class="post-copyright-license"><strong>Copyright Declaration: </strong>The author owns the copyright, please indicate the source reproduced.</li></ul></div><br><div class="tags"><a href="/tags/GAN/">GAN</a></div><div class="post-nav"><a class="pre" href="/2019/01/09/Spectral-Normalization-for-Generative-Adversarial-Networks.html/">Spectral Normalization for Generative Adversarial Networks</a><a class="next" href="/2019/01/07/cs231n-lecture11-Detection-and-Segmentation.html/">cs231n lecture11 Detection and Segmentation</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'true' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'ghsTdcg2fkGJS6ezqnysCLhl-gzGzoHsz',
  appKey:'TFWzwUO0GPWYSIzO5rlINGID',
  placeholder:'Just so so',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs231n/">cs231n</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/百篇论文阅读计划/">百篇论文阅读计划</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/image-caption/" style="font-size: 15px;">image caption</a> <a href="/tags/cs231n/" style="font-size: 15px;">cs231n</a> <a href="/tags/图像风格转换/" style="font-size: 15px;">图像风格转换</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/01/09/Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention.html/">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/09/Spectral-Normalization-for-Generative-Adversarial-Networks.html/">Spectral Normalization for Generative Adversarial Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/08/Self-Attention-Generative-Adversarial-Networks.html/">Self-Attention Generative Adversarial Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/07/cs231n-lecture11-Detection-and-Segmentation.html/">cs231n lecture11 Detection and Segmentation</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/03/Super-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS.html/">Super-FAN:Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with GANS</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/24/cs231n-Lecture-10-Recurrent-Neural-Networks.html/">cs231n Lecture 10 Recurrent Neural Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/22/cs231n-Lecture-9-CNN-Architectures.html/">cs231n Lecture 9 CNN Architectures</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/22/cs231n-Lecture-7-Training-Neural-Networks-part-2.html/">cs231n Lecture 7 Training Neural Networks part 2</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/21/cs231n-Lecture-6-Training-Neural-Networks-part-I.html/">cs231n Lecture 6 Training Neural Networks, part I</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/20/cs231n-参数设置技巧.html/">cs231n 参数设置技巧</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/tiantianwahaha" title="github" target="_blank">github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">tiantianwahaha.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>