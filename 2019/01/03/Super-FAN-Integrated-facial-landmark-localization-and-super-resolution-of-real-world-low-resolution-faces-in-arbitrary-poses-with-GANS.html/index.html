<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="tiantianwahaha's blogs"><title>Super-FAN:Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with GANS | tiantianwahaha</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-132074008-1','auto');ga('send','pageview');
</script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Super-FAN:Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with GANS</h1><a id="logo" href="/.">tiantianwahaha</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Super-FAN:Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with GANS</h1><div class="post-meta">Jan 3, 2019<span> | </span><span class="category"><a href="/categories/百篇论文阅读计划/">百篇论文阅读计划</a></span></div><a class="disqus-comment-count" href="/2019/01/03/Super-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS.html/#vcomment"><span class="valine-comment-count" data-xid="/2019/01/03/Super-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS.html/"></span><span> Comment</span></a><div class="post-content"><p>使用GAN将现实世界中任意姿态下低分辨率人脸的人脸关键点定位和超分辨率结合起来。</p>
<p>CVPR2018 spotlignt</p>
<p><a href="https://www.adrianbulat.com/" target="_blank" rel="noopener">作者主页</a></p>
<p><img src="/2019/01/03/Super-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS.html/result.png" alt=""></p>
<h2 id="1-文章5点贡献"><a href="#1-文章5点贡献" class="headerlink" title="1.文章5点贡献"></a>1.文章5点贡献</h2><p>1.提出Super-FAN：一个同时提高人脸分辨率并进行人脸对齐的端到端系统，主要通过热图回归(Heatmap Regression)整合子网络进行人脸关键点定位，然后进入基于GAN的超分辨率处理网络，并将其并入到一个新的热图损失中。<br>2.展示了联合训练两个网络在处理任意人脸姿势的生成图像（以前只能正面人脸图像）以及真实世界的低分辨率图像上（合成的低清图片）的优势<br>3.提出了一个改进的残差网络结构来得到较好的超分辨率图像<br>4.首次提交了处理LS3D-W数据集各种人脸姿势的结果，并在超分辨率和人脸对齐方面做出了领先的结果。</p>
<p>5.首次在真实世界的低分辨率人脸图像(WiderFace数据集)上做到了良好的视觉效果</p>
<h2 id="2-整体模型架构"><a href="#2-整体模型架构" class="headerlink" title="2.整体模型架构"></a>2.整体模型架构</h2><p><img src="/2019/01/03/Super-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS.html/model structure.png" alt=""></p>
<p>生成器对应的是-超分辨率网络</p>
<p>FAN是-人脸对齐网络</p>
<p>鉴别器就是传统的鉴别器</p>
<h2 id="3-超分辨率网络-Super-resolution-network"><a href="#3-超分辨率网络-Super-resolution-network" class="headerlink" title="3.超分辨率网络(Super-resolution network)"></a>3.超分辨率网络(Super-resolution network)</h2><p><img src="/2019/01/03/Super-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS.html/Super-resolution network.png" alt=""></p>
<p>在<a href="https://arxiv.org/pdf/1609.04802.pdf" target="_blank" rel="noopener">Photo-realistic single image super-resolution using a generative adversarial</a>的基础上，改进了网络机构。</p>
<p>如图右侧是SRGAN，从上到下为网络顺序，输入为16×16，输出为64×64. SRGAN的残差块由conv-batchnorm-prelu-conv-batchnorm-prelu组成。先经过16个这样的残差块作用在16×16分辨率上，再经过1个deconv-pixel shuffle-prelu作用在32×32上，一个deconv-pixel shuffle-prelu作用在64×64上。记该结构为16-1-1.</p>
<p>本文的改进为，把prelu改成relu，因为他实验证明prelu对结果没有明显的提升作用。去除了长连接，因为对整体效益没有什么特别影响。同时把网络结构改为12-3-2，因为作者希望通过增加残差块来处理较高维特征，从而增强高分辨率图像上的细节，尤其是处理场景复杂的图像。</p>
<h2 id="4-人脸对齐网络-Face-Alignment-Network-和Heapmap-loss"><a href="#4-人脸对齐网络-Face-Alignment-Network-和Heapmap-loss" class="headerlink" title="4.人脸对齐网络(Face Alignment Network)和Heapmap loss"></a>4.人脸对齐网络(Face Alignment Network)和Heapmap loss</h2><p>为了获得更好的细节，作者通过热图回归(heatmap regression)将人脸关键点定位(facial landmark localization)集成到超分辨率过程并且优化一个适当的热图损失，从而增强超分辨率图像和原始图像的结构一致性。</p>
<p>使用的是FAN with 2 Hourglass modules模型。</p>
<p>FAN是作者的上一篇文章中提出的结构，用来做2D人脸对齐，输入一张图片，输出一个63*2的向量，表示(x,y)的坐标，就是人脸关键点。用的是两层hourglass modules，不过在此基础上把bottleneck block改成了多层次平行的多规模块。具体介绍见<a href="https://blog.csdn.net/shenxiaolu1984/article/details/51428392" target="_blank" rel="noopener">此博客</a>。</p>
<p>在本文中，FAN不再回归一个x，y的坐标，而是使用热图回归的内容定位人脸。用预先训练好的两个FAN网络，一个输入生成器生成的高清图片，一个输入ground true高清图片，得到的结果做均方误差(逐像素相减的平方求平均)</p>
<p>$l_{heatmap}=\frac{1}{N}\sum_{n=1}^N\sum_{ij}(\widetilde M_{i,j}^n-\widehat M_{i,j}^n)$</p>
<p>另一个关于热图损失的关键特征是它的优化不需要访问标记好的真实数据，而只需要预训练好的FAN。这就允许以弱监督方式训练整个超分辨率网络。</p>
<h2 id="5-整体损失函数"><a href="#5-整体损失函数" class="headerlink" title="5.整体损失函数"></a>5.整体损失函数</h2><p>$l^{SR}=\alpha l_{pixel}+\beta l_{feature} + \gamma l_{heatmap} + \zeta l_{WGAN}$</p>
<p>生成器的整体损失函数</p>
<p>pixel loss是生成的高清图和ground true的均方误差MSE(就是逐元素相减，然后平方，然后求均值)</p>
<p>perceptual loss是李飞飞风格转换里突出的损失函数，这里用的vgg_19的layer5_4</p>
<p>heatmap损失上面提到了</p>
<p>wgan损失，这篇文章用的wgan-gp</p>
<p>整体的训练过程，大致是先训练了60epoch的FAN</p>
<p>GAN模型是基于之前的训练模型，微调5epoch</p>
<p>然后把所有模型合并在一起，训练5epoch</p>
<p>整合了多个数据集，自己构造了训练集和测试集，包括300W-LP, AFLW, Celeb-A，LS3D-W balanced.</p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>Author: </strong>tiantianwahaha</li><li class="post-copyright-link"><strong>Blog Link: </strong><a href="/2019/01/03/Super-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS.html/">https://tiantianwahaha.github.io/2019/01/03/Super-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS.html/</a></li><li class="post-copyright-license"><strong>Copyright Declaration: </strong>The author owns the copyright, please indicate the source reproduced.</li></ul></div><br><div class="tags"><a href="/tags/GAN/">GAN</a></div><div class="post-nav"><a class="pre" href="/2019/01/07/cs231n-lecture11-Detection-and-Segmentation.html/">cs231n lecture11 Detection and Segmentation</a><a class="next" href="/2018/12/24/cs231n-Lecture-10-Recurrent-Neural-Networks.html/">cs231n Lecture 10 Recurrent Neural Networks</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'true' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'ghsTdcg2fkGJS6ezqnysCLhl-gzGzoHsz',
  appKey:'TFWzwUO0GPWYSIzO5rlINGID',
  placeholder:'Just so so',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs231n/">cs231n</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/百篇论文阅读计划/">百篇论文阅读计划</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/deep-learning/" style="font-size: 15px;">deep learning</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/image-caption/" style="font-size: 15px;">image caption</a> <a href="/tags/cs231n/" style="font-size: 15px;">cs231n</a> <a href="/tags/图像风格转换/" style="font-size: 15px;">图像风格转换</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/01/12/Fully-Convolutional-Network-FCN.html/">Fully Convolutional Network (FCN)</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/12/inception-network.html/">inception network</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/09/Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention.html/">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/09/Spectral-Normalization-for-Generative-Adversarial-Networks.html/">Spectral Normalization for Generative Adversarial Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/08/Self-Attention-Generative-Adversarial-Networks.html/">Self-Attention Generative Adversarial Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/07/cs231n-lecture11-Detection-and-Segmentation.html/">cs231n lecture11 Detection and Segmentation</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/03/Super-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS.html/">Super-FAN:Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with GANS</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/24/cs231n-Lecture-10-Recurrent-Neural-Networks.html/">cs231n Lecture 10 Recurrent Neural Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/22/cs231n-Lecture-9-CNN-Architectures.html/">cs231n Lecture 9 CNN Architectures</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/22/cs231n-Lecture-7-Training-Neural-Networks-part-2.html/">cs231n Lecture 7 Training Neural Networks part 2</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/tiantianwahaha" title="github" target="_blank">github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">tiantianwahaha.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>