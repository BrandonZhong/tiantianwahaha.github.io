<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention | Voila</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</h1><a id="logo" href="/.">Voila</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</h1><div class="post-meta">Jan 9, 2019<span> | </span><span class="category"><a href="/categories/百篇论文阅读计划/">百篇论文阅读计划</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a class="disqus-comment-count" href="/Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention.html#vcomment"><span class="valine-comment-count" data-xid="/Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention.html"></span><span> Comment</span></a><div class="post-content"><p>本文是2015年的一篇根据图片生成文字描述的文章。</p>
<p>主要是因为文章里用了soft attention和hard attention</p>
<p><strong>详细内容可以参考<a href="http://www.cosmosshadow.com/ml/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2016/03/08/Attention.html" target="_blank" rel="noopener">博客</a>!!(需要翻墙！)</strong></p>
<hr>
<p>图片先经过一个VGG网络，学习到一个对图片的特征图向量表示。然后输入到后面的LSTM中学习得到对应的文字。</p>
<p>这个特征图要均匀的划分L个区域，每个区域有大小为14×14，D=196</p>
<p>$a={a_1,…,a_L}, a_i∈R^D$</p>
<p>预测输出的一句话表示为，C是句子长度，K是字典大小(单词个数)</p>
<p>$y={y_1,…,y_C},y_i∈R^K$</p>
<p>文字结果跟图片有关系，LSTM与传统的相比，在每个位置除了输入$x_t$,$h_{t-1}$，还需要输入对应的图像表达信息$z_t$，但是这个单词不可能跟全局的图像信息有关，所以要加上attention机制。也就是传统的LSTM4个门的计算只跟输入文字x，上一状态h有关系，在image caption任务中还要加入z。</p>
<p>z是怎么求的呢。</p>
<p>$z_t=∑\alpha_ia_i$</p>
<p>hard attention: 只有一个alpha为1，其他的全为0，注意力一个时刻只关注一个区域。不可微，近似一个下界，略</p>
<p>soft attention:每个区域都有一定的权重，和为1。连续可微的。</p>
<p>用多层感知器输入a和h来求alpha，具体没看，略</p>
<p><img src="/example.png" alt=""></p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>Author: </strong>whiup</li><li class="post-copyright-link"><strong>Blog Link: </strong><a href="/Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention.html">https://tiantianwahaha.github.io/Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention.html</a></li><li class="post-copyright-license"><strong>Copyright Declaration: </strong>The author owns the copyright, please indicate the source reproduced.</li></ul></div><br><div class="tags"><a href="/tags/image-caption/">image caption</a></div><div class="post-nav"><a class="next" href="/Spectral-Normalization-for-Generative-Adversarial-Networks.html">Spectral Normalization for Generative Adversarial Networks</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'true' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'ghsTdcg2fkGJS6ezqnysCLhl-gzGzoHsz',
  appKey:'TFWzwUO0GPWYSIzO5rlINGID',
  placeholder:'Just so so',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs231n/">cs231n</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/百篇论文阅读计划/">百篇论文阅读计划</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/image-caption/" style="font-size: 15px;">image caption</a> <a href="/tags/cs231n/" style="font-size: 15px;">cs231n</a> <a href="/tags/图像风格转换/" style="font-size: 15px;">图像风格转换</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention.html">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></li><li class="post-list-item"><a class="post-list-link" href="/Spectral-Normalization-for-Generative-Adversarial-Networks.html">Spectral Normalization for Generative Adversarial Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/Self-Attention-Generative-Adversarial-Networks.html">Self-Attention Generative Adversarial Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/cs231n-lecture11-Detection-and-Segmentation.html">cs231n lecture11 Detection and Segmentation</a></li><li class="post-list-item"><a class="post-list-link" href="/Super-FAN-Integrated-facial-landmark-localization-and-super-resolution-of-real-world-low-resolution-faces-in-arbitrary-poses-with-GANS.html">Super-FAN:Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with GANS</a></li><li class="post-list-item"><a class="post-list-link" href="/cs231n-Lecture-10-Recurrent-Neural-Networks.html">cs231n Lecture 10 Recurrent Neural Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/cs231n-Lecture-9-CNN-Architectures.html">cs231n Lecture 9 CNN Architectures</a></li><li class="post-list-item"><a class="post-list-link" href="/cs231n-Lecture-7-Training-Neural-Networks-part-2.html">cs231n Lecture 7 Training Neural Networks part 2</a></li><li class="post-list-item"><a class="post-list-link" href="/cs231n-Lecture-6-Training-Neural-Networks-part-I.html">cs231n Lecture 6 Training Neural Networks, part I</a></li><li class="post-list-item"><a class="post-list-link" href="/cs231n-参数设置技巧.html">cs231n 参数设置技巧</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/tiantianwahaha" title="github" target="_blank">github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Voila.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>